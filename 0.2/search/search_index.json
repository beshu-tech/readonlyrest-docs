{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"README Documentation for ReadonlyREST plugins \ud83d\udcd6 Docs for Elasticsearch plugin \ud83d\udcd6 Docs for Kibana plugin The documentation of an open source product should also be open source! Found a problem? Edit the file directly from GitHub! Getting started \ud83d\ude80 Kibana Multi-User with ROR PRO \ud83d\ude80 Kibana Multi-Tenancy with ROR Enterprise \u2b05\ufe0f Elasticsearch plugin project (Github)","title":"README"},{"location":"#readme","text":"","title":"README"},{"location":"#documentation-for-readonlyrest-plugins","text":"\ud83d\udcd6 Docs for Elasticsearch plugin \ud83d\udcd6 Docs for Kibana plugin The documentation of an open source product should also be open source! Found a problem? Edit the file directly from GitHub!","title":"Documentation for ReadonlyREST plugins"},{"location":"#getting-started","text":"\ud83d\ude80 Kibana Multi-User with ROR PRO \ud83d\ude80 Kibana Multi-Tenancy with ROR Enterprise \u2b05\ufe0f Elasticsearch plugin project (Github)","title":"Getting started"},{"location":"SUMMARY/","text":"Table of contents README For Elasticsearch External to local groups mapping FIPS mode FLS engine indices rule - Index not found scenario indices rule - ES Templates handling For Kibana Impersonation Kibana 7.8.x and older Examples Multi-tenancy Elastic Stack Multi-user Elastic Stack SAML SSO Keycloak Microsoft Azure AD Microsoft ADFS Duo Security MFA OpenID Connect (OIDC) Keycloak Contribution License Agreement Commercial Licenses Changelog","title":"Table of contents"},{"location":"SUMMARY/#table-of-contents","text":"README For Elasticsearch External to local groups mapping FIPS mode FLS engine indices rule - Index not found scenario indices rule - ES Templates handling For Kibana Impersonation Kibana 7.8.x and older Examples Multi-tenancy Elastic Stack Multi-user Elastic Stack SAML SSO Keycloak Microsoft Azure AD Microsoft ADFS Duo Security MFA OpenID Connect (OIDC) Keycloak Contribution License Agreement Commercial Licenses Changelog","title":"Table of contents"},{"location":"changelog/","text":"Changelog (2022-07-25) What's new in ROR 1.42.0 \ud83d\ude80New (KBN|ES) 8.3.3, 8.3.2, 8.3.1, 8.3.0, 7.15.5 support \ud83e\uddd0Enhancement (KBN) Search box in tenancy switcher (when #tenancies > 5) \ud83e\uddd0Enhancement (ES) added configuration warnings in the Impersonation Feature \ud83d\udc1eFix (KBN) Logout didn\u2019t delete the SAML session on the IdP \ud83d\udc1eFix (KBN) 5xx errors from Elasticsearch break Kibana users\u2019 session unrecoverably \ud83d\udc1eFix (ES) ROR node cooperation with X-pack nodes (2022-06-21) What's new in ROR 1.41.0 \ud83d\ude80New (ES) Added groups_and mode to ror_kbn_auth and jwt_auth rules \ud83e\uddd0Enhancement (KBN) Prevent native credentials dialogue to appear in Kibana when ES responds 401 \ud83e\uddd0Enhancement (KBN) Logging in after logout shows the same page you last visited \ud83e\uddd0Enhancement (KBN) x-ror-correlation-id header lets you audit a whole Kibana session \ud83d\udc1eFix (ES|KBN) tenancy selector didn't work well with jwt_auth and ror_kbn_auth rules \ud83d\udc1eFix (KBN) Support for special characters in tenancy names \ud83d\udc1eFix (KBN) OIDC logout flow redirecting to bad request error \ud83d\udc1eFix (KBN) OIDC connector not working in Kibana < 7.12.0 (2022-05-24) What's new in ROR 1.40.0 \ud83d\udea8Security Fix (ES) CVE-2022-25647 & CVE-2022-24823 & CVE-2020-13956 & CVE-2020-36518 & CVE-2020-13956 & CVE-2020-36518 \ud83d\udea8Security Fix (KBN) \u201cSecurity\u201d app not entirely hidden in 8.2.x \ud83d\ude80New (ES) New Support for 8.2.3, 8.2.2, 8.2.1, 7.17.4 \ud83d\ude80New (KBN) New Support for 8.2.2 8.2.1, 7.17.4 \ud83d\ude80New (ES & KBN) The Impersonation feature \ud83d\ude80New (ES) FIPS compliant SSL mode \ud83e\uddd0Enhancement (KBN) SAML cert is now required \ud83e\uddd0Enhancement (KBN) moved OIDC to better library \ud83e\uddd0Enhancement (KBN) OIDC jwksURL is now required \ud83d\udc1eFix (ES) indices: [\"1\"] interpreted as integer and fails to parse \ud83d\udc1eFix (KBN) /login?jwt=xxx authorization now works again \ud83d\udc1eFix (KBN) OIDC/SAML assertion claims were not forwarded to ES \ud83d\udc1eFix (KBN) include whitelisted headers while logging \ud83d\udc1eFix (KBN) basepath handling fixes (too many redirects) \ud83d\udc1eFix (KBN) Make ROR default space the actual default one \ud83d\udc1eFix (KBN) RORDEV-641 Fix oidc connection error (2022-03-19) What's new in ROR 1.39.0 \ud83d\udea8Security Fix (KBN) XSS sanitize path requested \ud83d\udea8Security Fix (ES) CVE-2020-36518 & CVE-2022-21653 \ud83d\ude80New (KBN) New Support for 8.2.0 8.1.3, 8.1.2, 8.1.1, 8.1.0, 8.0.0, 8.0.1, 7.17.3, 7.17.2 \ud83d\ude80New (ES) New Support for 8.2.0, 8.1.3, 8.1.2, 8.1.1, 8.1.0, 8.0.0, 8.0.1 ( required additional patching step ) \ud83d\ude80New (ES) New Support for 7.17.3, 7.17.2 \ud83d\ude80New (ES) New groups_and ACL rule \ud83e\uddd0Enhancement (KBN) Stop inlining whitelisted headers into Authorization header \ud83e\uddd0Enhancement (KBN) Log additional errors and info related to HA \ud83e\uddd0Enhancement (KBN) Misc internal dependencies upgrades \ud83d\udc1eFix (KBN) Mandatory elasticsearch credentials in kibana.yml \ud83d\udc1eFix (KBN) Reporting page redirect on refresh when kibana_hide_apps: [\"Stack Management\"] \ud83d\udc1eFix (KBN) whitelistedPaths: log errors when 404 occurs \ud83d\udc1eFix (KBN) Issue uploading large payload \ud83d\udc1eFix (KBN) elasticsearch.requestHeadersWhitelist should be case insensitive \ud83d\udc1eFix (ES) Issue with handling data streams by indices rule \ud83d\udc1eFix (ES) X-Pack SSL nodes cooperation with ROR SSL nodes \ud83d\udc1eFix (ES) _msearch issue when filter rules was used in matched block (2022-01-17) What's new in ROR 1.38.0 \ud83d\ude80New (ES) New Support for 7.17.0, 7.17.1 \ud83d\ude80New (KBN) New Support for 7.17.0 \ud83d\ude80New (ES) Configuration for custom audit cluster \ud83e\uddd0Enhancement (ES) Separate \"audit\" section for all audit settings \ud83d\udc1eFix (KBN) Editor rendering issue with kibana basePath enabled (2021-12-14) What's new in ROR 1.37.0 \ud83d\udea8Security Fix (ES) CVE-2021-43797 \ud83d\ude80New (ES) New Support for 7.16.3, 7.16.2, 6.8.23, 6.8.22 \ud83d\ude80New (KBN) New Support for 7.16.3, 7.16.2, 7.16.1, 7.16.10, 6.8.23, 6.8.22, 6.8.21 \ud83e\uddd0Enhancement (ES) fields rule handling in the context of x-Pack SQL requests \ud83d\udc1eFix (ES) filter rule handling in the context of x-Pack SQL requests \ud83d\udc1eFix (KBN) POST / bulk cause an 400 error in devtools console \ud83d\udc1eFix (KBN) More robust Kibana patcher + better logs messages (2021-11-21) What's new in ROR 1.36.0 \ud83d\ude80New (ES) New Support for 7.16.1, 7.16.0, 6.8.21 \ud83d\ude80New (KBN) Support Kibana 7.15.2 \ud83d\ude80New (ES) Added support for setting up cluster containing ES with ROR (with disabled XPack security) and ES with XPack security enabled \ud83e\uddd0Enhancement (KBN) kibana_hide_apps: [ror|kibana] to remove kibana mgmt button \ud83d\udc1eFix (ES) /_snapshot/_status should return only running snapshots \ud83d\udc1eFix (ES) Adding policy to index template bug \ud83d\udc1eFix (KBN) Index management tabs result in \"forbidden\" error \ud83d\udc1eFix (KBN) corrupted patch file for Kibana 7.9.x \ud83d\udc1eFix (KBN) YAML editor not working in air-gapped environments \ud83d\udc1eFix (KBN) Devtools not working \ud83d\udc1eFix (KBN) Monitoring not working in multi-tenancy \ud83d\udc1eFix (KBN) Regression in Kibana < 6.8.x front end crash \ud83d\udc1eFix (KBN) Kibana < 7.8.x prevent navigation to hidden apps from home links \ud83d\udc1eFix (KBN) Kibana < 7.8.x implicitly hide kibana:dashboard when kibana:dashboards is hidden (and viceversa) \ud83d\udc1eFix (KBN) Kibana < 7.8.x broken clearSessionOnEvents: [tenancyHop] (2021-10-17) What's new in ROR 1.35.1 \ud83d\udea8Security Fix (ES) CVE-2021-21409 & CVE-2021-27568 \ud83d\ude80New (KBN) Support Kibana 7.15.1 \ud83d\ude80New (ES) New Support for 7.15.2 \ud83e\uddd0Enhancement (KBN) Support \"server.ssl.supportedProtocols\" settings \ud83e\uddd0Enhancement (KBN) Support \"server.ssl.cipherSuites\" \ud83e\uddd0Enhancement (KBN) Always honor SSL cipher order \ud83d\udc1eFix (KBN) Don'thide \"Add/Remove field as column\" in Discover app for RO users \ud83d\udc1eFix (KBN) More alerting fixes (only for main tenancy) (2021-10-12) What's new in ROR 1.35.0 \ud83d\ude80New (KBN) Support Kibana 7.15.0, 7.14.2 \ud83d\ude80New (ES) New Support for 7.15.1, 6.8.19, 6.8.20 \ud83e\uddd0Enhancement (ES) local->external groups detailed mapping for groups rule \ud83e\uddd0Enhancement (ES) when ROR is starting any request is going to end up with HTTP 403 response, instead of HTTP 503 \ud83e\uddd0Enhancement (KBN) \"server.basePath\" kibana option implementation \ud83e\uddd0Enhancement (KBN) Support full regex in kibana_hidden_apps rule \ud83e\uddd0Enhancement Crash if Kibana is not patched \ud83e\uddd0Enhancement (KBN) Honour kibana setting \"logging.dest\" \ud83e\uddd0Enhancement (KBN) Confirm before overwriting audit log dashboard \ud83d\udc1eFix (ES) verbosity: error fix in case of ROR KBN login request \ud83d\udc1eFix (KBN) Make alerting work on primary tenancy \ud83d\udc1eFix (KBN) OIDC fix sameSite / secure cookie options \ud83d\udc1eFix (KBN) Login form is stretched when long error \ud83d\udc1eFix (KBN) Login form is stretched when long error \ud83d\udc1eFix (KBN-PRO) Don't send x-ror-currentgroup in PRO \ud83d\udc1eFix (KBN) Resolve browser console errors on a popover close (2021-09-24) What's new in ROR 1.34.0 \ud83d\ude80New (ES) New Support for 7.15.0, 7.14.2 \ud83d\ude80New (KBN) VS Code style YAML editor \ud83d\ude80New (KBN) Skip rendering hidden app groups entirely \ud83d\ude80New (KBN) Redesigned ROR Menu \ud83d\ude80New (KBN) Dark theme awareness \ud83d\udc1eFix (KBN) Broken Kibana Spaces \ud83d\udc1eFix (KBN) Support Kibana's undocumented \"server.ssl.*\" settings \ud83d\udc1eFix (KBN) cookiePass config parsing broke load balancing (2021-08-14) What's new in ROR 1.33.1 \ud83d\ude80New (ES) New Support for 7.14.1 \ud83d\udc1eFix (KBN) Error in patching for 7.14.0 \ud83d\udc1eFix (KBN) clearSessionOnEvents now works as expected \ud83d\udc1eFix (KBN) login form font loads correctly (2021-08-09) What's new in ROR 1.33.0 \ud83d\udea8Security Fix (KBN) xml-crypto dependency update \ud83d\ude80New (KBN) New Support for 7.14.0, 6.8.18 \ud83e\uddd0Enhancement (KBN) Parse credentials in /api/* requests, no need for valid cookie. Supersedes whitelistedPaths \ud83d\udc1eFix (KBN)Caching issues switching tenancies with dark/light theme \ud83d\udc1eFix (KBN) Newly created Space shows in all tenancies when using default kibana index \ud83d\udc1eFix (KBN < 7.9.x) nextUrl works again with SAML and OIDC (2021-07-25) What's new in ROR 1.32.0 \ud83d\udea8Security Fix (ES) Apache Commons Codec vulnerability \ud83d\udea8Security Fix (KBN) upgraded dependencies due to security fixes \ud83d\udea8Security Fix (KBN) disable x-powered-by to avoid fingerprinting \ud83d\ude80New (ES) Support for ES 7.14.0 & 6.8.18 \ud83d\ude80New (KBN) Support for Kibana 7.13.x series \ud83e\uddd0Enhancement (KBN) honor configurations coming from ENV and CLI options \ud83e\uddd0Enhancement (KBN) when metadata has no username, login must be denied \ud83e\uddd0Enhancement (KBN) audit tab ported to new platform \ud83e\uddd0Enhancement (ES) improved ES resources cleaning when ROR returns FORBIDDEN response \ud83e\uddd0Enhancement (KBN < 7.9.x) auto clean-up dangling SAML/OIDC cookies \ud83d\udc1eFix (ES) incomplete response for request GET */_alias \ud83d\udc1eFix (ES) not allowed aliases should not present in a response for a Get Index API request \ud83d\udc1eFix (KBN) fix dev-tools and import saved object not working \ud83d\udc1eFix (KBN) honor requestHeadersWhitelist in user metadata request (login) \ud83d\udc1eFix (KBN < 7.9.x) do not crash on invalid metadata (2021-06-29) What's new in ROR 1.31.0 \ud83d\udea8Security Fix (KBN) prevent direct navigation to hidden apps \ud83d\ude80New (ES) 7.13.4, 7.13.3, 7.13.2, 6.8.17 support \ud83d\ude80New (KBN) new minimal Kibana Management menu when \"Management\" app is hidden \ud83e\uddd0Enhancement (KBN) logout active Kibana session if key metadata/permissions change in ACL \ud83e\uddd0Enhancement (KBN) better port number validation \ud83e\uddd0Enhancement (ES) improved cluster indices handling \ud83d\udc1eFix (ES) Kibana access rule regression fix \ud83d\udc1eFix (ES) search template API handling with filter and fields rule \ud83d\udc1eFix (ES) multi-tenancy issue when groups_provider_authorization is used \ud83d\udc1eFix (ES) x_forwarded_for rule: wrong handling of / request \ud83d\udc1eFix (ES) Issue with handling ResizeRequest which made it unable to upgrade Kibana to version 7.12.0+ \ud83d\udc1eFix (KBN) some Kibana requests arrive to ES without credentials \ud83d\udc1eFix (KBN) inconsistent read after write in session storage lead to issues with round robin load balancing \ud83d\udc1eFix (KBN) bad multipart POST handling leads to saved object import errors (2021-05-26) What's new in ROR 1.30.1 \ud83d\udea8Security Fix (ES) CVE-2021-27568 \ud83d\ude80New (ES) 7.13.0, 7.13.1 support \ud83d\udc1eFix (ES) Regression in multi-tenancy handling \ud83d\udc1eFix (ES) Proper handling of _snapshot/_status endpoint (2021-05-16) What's new in ROR 1.30.0 \ud83d\ude80New (KBN) 7.12.x compatibility \ud83d\ude80New (ES) LDAP connector circuit breaker \ud83e\uddd0Enhancement (ES) Username with wildcard support in users section and groups mapping \ud83e\uddd0Enhancement (KBN < 7.9.x) OIDC errors visibility \ud83e\uddd0Enhancement (KBN < 7.9.x) Smarter session probe algorithm \ud83d\udc1eFix (KBN >= 7.9.x) Load CertificateAuthorities as an array if not specified as an array \ud83d\udc1eFix (KBN < 7.9.x) Don't hide visualizations list search box in RO mode (2021-04-09) What's new in ROR 1.29.0 \ud83d\udea8Security Fix (ES) Security Fix (ES) CVE-2021-21409 \ud83d\ude80New (KBN) support 7.9.0, 7.9.1, 7.10.0, 7.10.1, 7.10.2, 7.11.0, 7.11.1, 7.11.2 ( with ROR new platform ) \ud83d\ude80New (ES) 7.12.1 support \ud83e\uddd0Enhancement (KBN) logout if the credentials/metadata of the current user change in the ACL (2021-04-01) What's new in ROR 1.28.2 \ud83d\udea8Security Fix (ES) CVE-2021-21295 \ud83d\udc1eFix (KBN) prevent SAML/OIDC initiated Kibana sessions from expiring after session_timeout_minutes despite continued interaction (2021-03-24) What's new in ROR 1.28.1 \ud83d\udc1eFix (ES) Getting index templates issue when no indices rule was used in matched block \ud83d\udc1eFix (ES) NPE on getting template aliases (2021-03-14) What's new in ROR 1.28.0 \ud83d\ude80New (ES) 7.12.0, 7.11.2 support \ud83d\ude80New (ES) full Index and Component Templates API support \ud83e\uddd0Enhancement (ES) Username case sensitivity settings \ud83d\udc1eFix (ES) Kibana logout event storing fix \ud83d\udc1eFix (ES) Fixed remote reindex operation with \"type\" parameter \ud83d\udc1eFix (KBN) Prevent cookie expiration deadlock in browsers when using SAML/OIDC \ud83d\udc1eFix (KBN) When credentials change in the ACL, make it possible to login again \ud83d\udc1eFix (KBN) Kibana management app ID changed from \"kibana:management\" to \"kibana:stack_management\" (2021-02-27) What's new in ROR 1.27.1 \ud83d\udea8Security Fix (ES) CVE-2021-21290 \ud83d\ude80New (ES) 7.11.1 support (2021-02-16) What's new in ROR 1.27.0 \ud83d\ude80New (ES) 7.11.0, 7.10.2, 6.8.14 support \ud83e\uddd0Enhancement (KBN) X-Forwarded-For copied from incoming request (or filled with source IP) before forwarding to ES \ud83e\uddd0Enhancement (KBN) Kibana logout event generates a special audit log entry in ROR audit logs index \ud83e\uddd0Enhancement (KBN) ROR panel shows \"reports\" button if kibana:management app is hidden \ud83d\udc1eFix (ES) blocks containing filter and/or fields won't match internal kibana requests, so kibana_* rules won't have to be placed in such blocks \ud83d\udc1eFix (ES) SQL API - better handling of invalid query (2021-01-11) What's new in ROR 1.26.1 \ud83d\udc1eFix (ES) wrong behaviour of kibana_access rule for ROR actions when ADMIN value is set (2021-01-02) What's new in ROR 1.26.0 \ud83d\udea8Security Fix (ES) CVE-2020-35490 & CVE-2020-35490 (removed Jackson dependency from ROR core) \ud83d\ude80New (ES) New response_fields rule \ud83d\ude80New (ES) Support for LDAP server discovery using _ldaps._tcp SRV record \ud83d\ude80 New (ES) New configuration option allowing to ignore LDAP connectivity problems \ud83e\uddd0Enhancement (ES) Full support for ILM API \ud83e\uddd0Enhancement (KBN) Enforce read-after-write consistency between kibana nodes \ud83e\uddd0Enhancement (KBN ENT) OIDC custom claims incorporated in \"assertion\" claim \ud83e\uddd0Enhancement (KBN ENT) OIDC support for configurable kibanaExternalHost (good for Docker) \ud83e\uddd0Enhancement (KBN ENT) ROR adds \"ror-user_\" class to \"body\" tag for easy per-user CSS/JS \ud83e\uddd0Enhancement (KBN ENT/PRO) ROR adds \"ror-group_\" class to \"body\" tag for easy per-group CSS/JS \ud83d\udc1eFix (ES) ROR authentication endpoint action \ud83d\udc1eFix (ES) \"username\" in audit entry when request is rejected What's new in 1.25.2 \ud83d\udc1eFix (ES) removed verbose logging What's new in 1.25.1 \ud83d\udea8Security Fix (ES) CVE-2020-25649 \ud83d\ude80New (ES) 7.10.1 support What's new in 1.25.0 \ud83d\udea8Security Fix (ES) Common Vulnerabilities and Exposures (CVE) \ud83d\ude80New (ES) 7.10.0 support \ud83d\ude80New (ES) auth_key_pbkdf2 rule \ud83d\ude80New (ES) Introduced configuration property defining FLS engine used by fields rule \ud83e\uddd0Enhancement (ES) Fields rule performance improvement \ud83e\uddd0Enhancement (ES) Resolved index API support \ud83d\udc1eFix (ES) \"username\" in audit entry when user is authenticated via proxy_auth \ud83d\udc1eFix (ES) index resolve action should be treated as readonly action \ud83d\udc1eFix (ES) /_snapshot and /_snapshot/_all should behave the same What's new in 1.24.0 \ud83d\udea8Security Fix (ES) search template handling fix \ud83d\ude80New (ES) 7.9.3 & 6.8.13 support \ud83e\uddd0Enhancement (ES) full support for ES Snapshots and Restore APIs \ud83d\udc1eFix (KBN) fix crash in error handling \ud83d\udc1eFix (ES) don't remove ES response warning headers \ud83d\udc1eFix (ES) issue when entropy of /dev/random could have been exhausted when using JwtToken rule What's new in 1.23.1 \ud83d\ude80New (ES) 7.9.2 support \ud83d\udc1eFix (KBN) fix code 500 error on login in Kibana What's new in 1.23.0 \ud83d\ude80New (ES) introduced must_involve_indices option for indices rule \ud83e\uddd0Enhancement (ES) negation support in headers rules \ud83e\uddd0Enhancement (ES) x-pack rollup API handling \ud83d\udc1eFix (KBN) deep links query parameters are now handled \ud83d\udc1eFix (KBN) make sure default kibana index is always discovered (fixes reporting in 6.x) \ud83d\udc1eFix (ES) settings file permission issue with JDK 1.8.0 25.262-b10 \ud83d\udc1eFix (ES) /_cluster/allocation/explain request should not be forbidden if matched block doesn't have indices rules \ud83d\udc1eFix (ES) remote address extracting issue \ud83d\udc1eFix (ES) fixed TYP audit field for some request types What's new in 1.22.1 \ud83d\udc1eFix (ES) missing handling of aliases API for ES 7.9.0 What's new in 1.22.0 \ud83d\ude80New (ES) 7.9.0 support \ud83e\uddd0Enhancement (ES) aliases API handling \ud83e\uddd0Enhancement (ES) dynamic variables support in fields rule \ud83d\udc1eFix (ES) adding aliases issue \ud83d\udc1eFix (ES) potential memory leak for ES 7.7.x and above \ud83d\udc1eFix (ES) cross cluster search issue fix for X-Pack _async_search action \ud83d\udc1eFix (ES) XFF entry in audit issue \ud83d\udc1eFix (KBN) SAML certificate loading \ud83d\udc1eFix (KBN) SAML loading groups from assertion \ud83d\udc1eFix (KBN) fix reporting in pre-7.7.0 What's new in 1.21.0 \ud83e\uddd0Enhancement (ES) cluster API support improvements \ud83d\udc1eFix (ES) X-Pack _async_search support \ud83d\udc1eFix (ES) _rollover request handling \ud83d\udc1eFix (ES) handling numeric ssl configuration properties \ud83d\udc1eFix (KBN) multitenancy+reporting regression fix (for 7.6.x and earlier) \ud83d\udc1eFix (KBN) \"x-\" headers should be forwarded in /login route when proxy passthrough is enabled \ud83d\udc1eFix (KBN) Logout now redirects to login screen when using proxy \ud83d\udc1eFix (KBN) SAML metadata.xml endpoint not responding \ud83d\udc1eFix (KBN) NAT/reverse proxy support for SAML \ud83d\udc1eFix (KBN) SAML login redirect error \ud83d\udc1eFix (ES) _readonlyrest/metadata/current_user should be always allowed by filter/fields rule What's new in 1.20.0 \ud83d\ude80New 7.7.1, 7.8.0 support \ud83e\uddd0Enhancement (KBN) tidy up audit page \ud83e\uddd0Enhancement (KBN FREE) clearly inform when features are not available \ud83e\uddd0Enhancement (KBN) ship license report of libraries \ud83e\uddd0Enhancement (ES) filter rule performance improvement \ud83d\udc1eFix (KBN) proxy_auth: avoid logout-login loop \ud83d\udc1eFix (KBN) 404 error on font CSS file \ud83d\udc1eFix (ES) wildcard in filter query issue \ud83d\udc1eFix (ES) forbidden /_snapshot issue \ud83d\udc1eFix (ES) /_mget handling by indices rule when no index from a list is found \ud83d\udc1eFix (ES) available groups order in metadata response should match the order in which groups appear in ACL \ud83d\udc1eFix (ES) .readonlyrest and audit index - removed usage of explicit index type \ud83d\udc1eFix (ES) tasks leak bug What's new in 1.19.5 \ud83d\ude80New 7.7.0, 7.6.2, 6.8.9, 6.8.8 support \ud83e\uddd0Enhancement (ES/KBN) kibana_access can be explicitly set to unrestricted \ud83e\uddd0Enhancement (ES) LDAP connection pool improvement \ud83d\udc1eFix (ES) better LDAP request timeout handling \ud83d\udc1eFix (ES) remote indices searching bug \ud83d\udc1eFix (ES) cross cluster search support for _field_caps request \ud83d\udea8Security Fix (ES) create and delete templates handling \ud83d\udc1eFix (KBN) Regression in proxy_auth_passthrough \ud83e\uddd0Enhancement (KBN) whitelistedPaths now accepts basic auth credentials \ud83e\uddd0Enhancement (KBN) Dump logout button, new ROR Panel \ud83e\uddd0Enhancement (KBN) removed ROR from Kibana sidebar. Admins have a link in new panel. \ud83e\uddd0Enhancement (KBN) avoid show login form redirecting from SAML IdP \ud83d\ude80New (KBN) OpenID Connect (OIDC) authentication connector \ud83d\ude80New (KBN) login_title, login_subtitle enable 2 column login page \ud83d\udea8Security Fix (KBN) server-side navigation prevention to hidden apps What's new in 1.19.4 \ud83d\udc1eFix (ES) Interpolating config with environment variables in SSL section \ud83d\udc1eFix (KBN Ent 6.x) Fixed default space creation in \ud83d\udc1eFix (KBN 6.x) Fixed error toast notification not showing \ud83d\udc1eFix (KBN Ent) Fixed missing Axios dependency \ud83d\udc1eFix (KBN Ent) Fixed SAML connector \ud83d\udc1eFix (KBN) Toast notification overlap with logout bar \ud83e\uddd0Enhancement (KBN) Restyled logout bar \ud83e\uddd0Enhancement (KBN) Configurable periodic session checker What's new in 1.19.3 \ud83d\ude80New (ES/KBN) 7.6.1 compatibility \ud83d\ude80New (ES) customizable name of settings index \ud83e\uddd0Enhancement (KBN) configurable ROR cookie name \ud83e\uddd0Enhancement (ES/KBN) handling of encoded ROR headers in Authorization header values \ud83e\uddd0Enhancement (KBN) user feedback on why login failed \ud83d\udc1eFix (ES) support for multiple header values \ud83d\udc1eFix (ES) releasing LDAP connection pool on reloading ROR settings \ud83d\udc1eFix (KBN) multitenancy issue with 7.6.0+ \ud83d\udc1eFix (KBN) creation of default space for new tenant \ud83d\udc1eFix (KBN 6.x) in RO mode, don't hide add/remove over fields in discovery \ud83d\udc1eFix (KBN 6.x) index template & in-index session manager issues What's new in 1.19.2 \ud83d\ude80New (KBN) 7.6.0 support \ud83e\uddd0Enhancement (KBN) less verbose info logging \ud83e\uddd0Enhancement (KBN) start up time semantic check for settings \ud83d\udc1eFix (KBN Free) missing logout button \ud83d\udc1eFix (KBN) error message creating internal proxy \ud83d\udc1eFix (KBN 6.x) add field to filter button invisible in RO mode What's new in 1.19.1 \ud83c\udf81Product (KBN) Launched ReadonlyREST Free for Kibana! \ud83d\ude80New (ES) 7.6.0 support, Kibana support coming soon \ud83d\ude80New (KBN) Audit log dashboard \ud83d\ude80New (KBN) Template index can now be declared per tenant instead of globally \ud83d\ude80New (ES) custom trust store file and password options in ROR settings \ud83e\uddd0Enhancement (ES) When \"prompt_for_basic_auth\" is enabled, ROR is going to return 401 instead of 404 when the index is not found or a user is not allowed to see the index \ud83e\uddd0Enhancement (ES) literal ipv6 with zone Id is acceptable network address \ud83e\uddd0Enhancement (ES) LDAP client cache improvements \ud83d\udc1eFix (ES) /_all/_settings API issue \ud83d\udc1eFix (ES) Index stats API & Index shard stores API issue \ud83d\udc1eFix (ES) readonlyrest.force_load_from_file setting decoding issue \ud83d\udc1eFix (KBN) allowing user to be logged in in two tabs at the same time \ud83d\udc1eFix (KBN) logging with JWT parameter issue \ud83d\udc1eFix (KBN) parsing of sessions fetched from ES index \ud83d\udc1eFix (KBN) logout issue What's new in 1.19.0 \ud83d\ude80New (KBN) Configurable option to delete docs from tenant index when not present in template \ud83e\uddd0Enhancement (ES) Less verbose logging of blocks history \ud83e\uddd0Enhancement (ES) Enriched logs and audit with attempted username \ud83e\uddd0Enhancement (ES) Better settings validation - only one authentication rule can be used in given block \ud83e\uddd0Enhancement (ES/KBN) Plugin versions printing in logs on launch \ud83e\uddd0Enhancement (ES) When user doesn't have access to given index, ROR pretends that the index doesn't exist and return 404 instead of 403 \ud83d\udc1eFix (ES) Searching for nonexistent/forbidden index with wildcard mirrors default ES behaviour instead of returning 403 \ud83d\udc1eFix (KBN) Switching groups bug What's new in 1.18.10 \ud83d\ude80New (ES/KBN) Support v6.8.6, v7.5.0, v7.5.1 \ud83d\ude80New (KBN) Group names can now be mapped to aliases \ud83d\ude80New (ES) New, more robust and simple method of creating custom audit log serializers \ud83d\ude80New (ES) Example projects with custom audit log serializers \ud83d\udc1e Fix (KBN) Prevent index migration after kibana startup \ud83e\uddd0Enhancement (KBN) If default space doesn't exist in kibana index then copy from default one \ud83e\uddd0Enhancement (KBN) Crypto improvements - store init vector with encrypted data as base64 encoded json. \ud83e\uddd0Enhancement (ES) Better settings validation - prevent duplicated keys in readonlyrest.yml What's new in 1.18.9 \ud83d\ude80New (ES/KBN) Support v7.4.1, v7.4.2 \ud83d\ude80New (KBN) Kibana sessions stored in ES index \ud83d\udc1e Fix (ES) issue with in-index settings auto-reloading \ud83d\udc1e Fix (ES) _cat/indices empty response when matched block doesn't contain 'indices' rule What's new in 1.18.8 \ud83d\ude80New (ES/KBN) Support v7.4.0 \ud83d\ude80New (ES) Elasticsearch SQL Support \ud83d\ude80New (ES) Internode ssl support for es5x, es60x, es61x and es62x \ud83d\ude80New (ES) new runtime variable @{acl:current_group} \ud83d\ude80New (ES) namespace for user variable and support for both versions: @{user} and @{acl:user} \ud83d\ude80New (ES) support for multiple values in uri_re rule \ud83e\uddd0Enhancement (ES) more reliable in-index settings loading of ES with ROR startup \ud83e\uddd0Enhancement (ES) less verbose logs in JWT rules \ud83e\uddd0Enhancement (ES) Better response from ROR API when plugin is disabled \ud83e\uddd0Enhancement (ES) Splitting verification ssl property to client_authentication and certificate_verification \ud83d\udc1eFix (ES) issue with backward compatibility of proxy_auth settings \ud83d\udc1eFix (ES) /_render/template request NPE \ud83d\udc1eFix (ES) _cat/indices API bug fixes \ud83d\udc1eFix (ES) _cat/templates API return empty list instead of FORBIDDEN when no indices are found \ud83d\udc1eFix (ES) updated regex for kibana access rule to support 7.3 ES \ud83d\udc1eFix (ES) proper resolving of non-string ENV variables in readonlyrest.yml \ud83d\udc1eFix (ES) lang-mustache search template handling What's new in 1.18.7 \ud83d\ude80New (ES) Field level security (FLS) supports nested JSON fields \ud83d\udc1eSecurity Fix (ES) Authorization headers appeared in clear in logs \ud83e\uddd0Enhancement (KBN) Don't logout users when they are not allowed to search a index-pattern \ud83e\uddd0Enhancement (ES) Headers obfuscation is now case insensitive What's new in 1.18.6 \ud83d\ude80New (ES/KBN) Support v7.3.1, v7.3.2 \ud83d\ude80New (ES) Configurable header names whose value should be obfuscated in logs \ud83d\ude80New (KBN) Dynamic variables from user identity available in custom_logout_link \ud83e\uddd0Enhancement (ES) Richer logs for JWT errors \ud83e\uddd0Enhancement (ENT) nextUrl works also with SAML now \ud83e\uddd0Enhancement (ENT) SAML assertion object available in ACL dynamic variables \ud83e\uddd0Enhancement (KBN) Validate LDAP server(s) before accepting new YAML settings \ud83e\uddd0Enhancement (KBN) Ensure a read-only UX for 'ro' users in older Kibana \ud83d\udc1eFix (ES) Fix memory leak from dependency (snakeYAML) What's new in 1.18.5 \ud83d\udc1eSecurity Fix (ES) indices rule can now properly handle also the templates API \ud83e\uddd0Enhancement (ES) Array dynamic variables are serialized as CSV wrapped in double quotes \ud83e\uddd0Enhancement (ES) Cleaner debug logs (no stacktraces on forbidden requests) \ud83e\uddd0Enhancement (ES) LDAP debug logs fire also when cache is hit \ud83d\ude80New (ES/KBN) Support v7.2.1, v7.3.0 \ud83d\udc1eFix (PRO) PRO plugin crashing for some Kibana versions \ud83d\udc1eFix (ENT) SAML library wrote a too large cookie sometimes \ud83d\udc1eFix (ENT) SAML logout not working \ud83d\udc1eFix (ENT) JWT fix exception \"cannot set requestHeadersWhitelist\" \ud83d\udc1eFix (PRO/ENT) Hide more UI elements for RO users \ud83d\udc1eFix (PRO/ENT) Sometimes not all the available groups appear in tenancy selector \ud83d\udc1eFix (PRO/ENT) Feature \"nextUrl\" broke \ud83d\udc1eFix (PRO/ENT) prevent user kick-out when APM is not configured and you are not an admin \ud83d\ude80New (PRO/ENT) Kibana request path/method now sent to ES (good for policing dev-tools) What's new in 1.18.4 \ud83d\ude80New (ES) User impersonation API \ud83d\ude80New (ES) Support latest 6.x and 5.x versions \ud83d\udc1eSecurity Fix (ES) filter/fields rules leak \ud83d\udc1eFix (KBN/ENT) allow more action for kibana_access, prevent sudden logout \ud83d\udc1eFix (KBN/ENT) temporarily roll back \"support for unlimited tenancies\" What's new in 1.18.3 \ud83d\ude80New Support added for ES/Kibana 6.8.1 \ud83e\uddd0Enhancement (ES) Crash ES on invalid settings instead of stalling forever \ud83e\uddd0Enhancement (ES) Better logging on JWT, JSON-paths, LDAP, YAML errors \ud83e\uddd0Enhancement (ES) Block level settings validation to user with precious hints \ud83e\uddd0Enhancement (ES) If force_load_from_file: true, don't poll index settings \ud83e\uddd0Enhancement (ES) Order now counts declaring LDAP Failover HA servers \ud83d\udc1eFix (ES) \"EsIndexJsonContentProvider\" had a null pointer exception \ud83d\udc1eFix (ES) \"es.set.netty.runtime.available.processors\" exception \ud83e\uddd0Enhancement (KBN) Collapsible logout button \ud83e\uddd0Enhancement (KBN) ROR App now uses a HA http client \ud83e\uddd0Enhancement (KBN) Automatic logout for inactivity \ud83e\uddd0Enhancement (KBN) Support unlimited amount of tenancies \ud83d\udc1eFix (KBN/ENT) concurrent multitenancy bug \ud83d\udc1eFix (KBN) Avoid sporadic errors on Save/Load buttons What's new in 1.18.2 \ud83d\ude80New Support for Elasticsearch & Kibana 7.2.0 \ud83d\udc1eFix (ES) restore indices (\"IDX\") in audit logging \ud83e\uddd0Enhancement (ES) New algorithm of setting evaluation order \ud83d\ude80New (ES) JWT claims as dynamic variables. I.e. \"@{jwt:claim.json.path}\" \ud83d\ude80New (ES) \"explode\" dynamic variables. I.e. indices: [\"@explode{x-indices}\"] \ud83d\udc1eFix (PRO/Enterprise) preserve comments and formatting in YAML editor \ud83d\udc1eFix (PRO/Enterprise) Print error message when session is expired \ud83d\udc1eRegression (PRO/Enterprise) Redirect to original link after login \ud83d\udc1eRegression (PRO/Enterprise) Broken CSV reporting \ud83e\uddd0Enhancement (PRO/Enterprise) Prevent navigating away from YAML editor w/ unsaved changes \ud83d\udc1eFix (Enterprise) Exception when SAML connectors were all disabled \ud83d\udc1eFix (Enterprise) Concurrent tenants could mix up each other kibana index \ud83d\udc1eFix (Enterprise) Cannot inject custom JS if no custom CSS was also declared \ud83d\udc1eFix (Enterprise) Injected JS had no effect on ROR logout button \ud83d\udc1eFix (Enterprise) On narrow screens, the YAML editor showed buttons twice What's new in 1.18.1 \ud83d\udc1eFix (Elasticsearch) Reindex requests failed for a regression in indices extraction \ud83d\udc1eFix (Elasticsearch) Groups rule erratically failed \ud83d\udc1eFix (Elasticsearch) JWT claims can now contain special characters \ud83e\uddd0Enhancement (Elasticsearch) Better ACL History logging \ud83e\uddd0Enhancement (Elasticsearch) QueryLogSerializer and old custom log serializers work again \ud83d\udc1eFix (PRO/Enterprise) ReadonlyREST icon in Kibana was white on white \ud83d\udc1eFix (Enterprise) SAML connectors could not be disabled \ud83d\udc1eFix (Enterprise) SAML connector \"buttonName\" didn't work What's new in 1.18.0 \ud83d\ude80New Support for Elasticsearch & Kibana 7.0.1 \ud83e\uddd0Enhancement (Elasticsearch) empty array values in settings are invalid \ud83d\udc1eSecurity Fix (Elasticsearch) arbitrary x-cluster search referencing local cluster \ud83d\udc1eFix (Elasticsearch) ArrayOutOfBoundException on snapshot operations \ud83e\uddd0Enhancement (PRO/Enterprise) History cleaning can now be disabled (\"clearSessionOnEvents\") What's new in 1.17.7 \ud83d\ude80New Support for Elasticsearch 7.0.0 (Kibana is coming soon) \ud83e\uddd0Enhancement (Elasticsearch) rewritten LDAP connector \ud83e\uddd0Enhancement (Elasticsearch) new core written in Scala is now GA \ud83d\udc1eFix (Enterprise) devtools requests now honor the currently selected tenancy \ud83d\udc1eSecurity Fix (Enterprise/PRO) Fix \"connectorsService\" error in installation What's new in 1.17.5 \ud83d\ude80New Support for Kibana/Elasticsearch 6.7.1 \ud83e\uddd0Enhancement (Enterprise >= Kibana 6.6.0) Multiple SAML identity provider \ud83d\udc1eSecurity Fix (Enterprise/PRO) Don't pass auth headers back to the browser \ud83d\udc1eFix (Enterprise/PRO) Missing null check caused error in reporting (CSV) \ud83d\udc1eFix (Enterprise) Don't reject requests if SAML groups are not configured \ud83d\udc1eFix filter/fields rules not working in msearch (in 6.7.x) \ud83e\uddd0Enhancement Print whole LDAP search query in debug log What's new in 1.17.4 \ud83d\ude80New Support for Kibana/Elasticsearch 6.7.0 \ud83e\uddd0Enhancement (PRO/Enterprise) JWT query param is the preferred credentials provider \ud83e\uddd0Enhancement (PRO/Enterprise) admin users can use indices management \ud83e\uddd0Enhancement (PRO/Enterprise) ro users can dismiss telemetry form \ud83d\udc1eFix Audit logging in 5.1.x now works again \ud83d\udc1eFix unpredictable behaviour of \"filter\" and \"fields\" when using external auth \ud83d\udc1eFix LDAP ConcurrentModificationException \ud83d\udc1eFix Audit logging in 5.1.x now works again \ud83d\udc1eFix (PRO/Enterprise) JWT deep-link works again What's new in 1.17.3 1.17.2 went unreleased, all changes have been merged in 1.17.3 directly \ud83d\udc1eFix (Enterprise) Tenancy selector showing if user belonged to one group \ud83d\udc1eFix (PRO/Enterprise) RW buttons not hiding for RO users in React Kibana apps \ud83d\udc1eFix (Enterprise) Tenancy templating now works much more reliably \ud83d\udc1eFix (Enterprise) Missing tenancy selector icon after switching tenancy \ud83d\udc1eFix (PRO/Enterprise) barring static files requests caused sudden logout \ud83d\udc1eFix Numerous fixes to better support Kibana 6.6.x \ud83d\udc1eFix Critical fixes in new Scala core \ud83d\udc1eFix Exception in reindex requests caused tenancy templating to fail \ud83e\uddd0Enhancement Bypass cross-cluster search logic if single cluster What's new in 1.17.1 \ud83d\udc1eFix (PRO/Enterprise) SAML now works well in 6.6.x \ud83d\udc1eFix (PRO/Enterprise) \"undefined\" authentication error before login \ud83d\udc1eFix (Enterprise) Default space creation failures for new tenants \ud83d\udc1eFix (Enterprise) Icons/titles CSS misalignment in sidebar (Firefox) \ud83e\uddd0Enhancement (Enterprise) UX: Larger tenancy selector \ud83d\udc1eSecurity Fix (Enterprise) Privilege escalation when changing tenancies under monitoring \ud83d\udc1eFix (Elasticsearch) compatibility fixes to support new Kibana features \ud83e\uddd0Enhancements (Elasticsearch) New core and LDAP connector written in Scala is finished, now under QA. What's new in 1.17.0 \ud83d\ude80New Feature Support for Kibana/Elasticsearch 6.6.0, 6.6.1 \ud83d\ude80New Feature Internode SSL (ES 6.3.x onwards) \ud83e\uddd0Enhancement (PRO/Enterprise) UI appearence \ud83e\uddd0Enhancement Made HTTP Connection configurable (PR #410) \ud83d\udc1eFix slow boot due to SecureRandom waiting for sufficient entropy \ud83d\udc1eFix Enable kibana_access:ro to create short urls in es6.3+ (PR #408) What's new in 1.16.34 \ud83e\uddd0Enhancement X-Forwarded-For header in printed es logs (\"XFF\") \ud83e\uddd0Enhancement kibana_index: \".kibana_@{user}\" when user is \"John Doe\" becomes .kibana_john_doe \ud83d\udc1eFix (Enteprise) parse SAML groups from assertion as array of strings \ud83d\udc1eFix (Enteprise) SAMLRequest in location header was URLEncoded twice, broke on some IdP \ud83d\udc1eFix (PRO/Enteprise) \"cookiePass\" works again, no more need for sticky cookies in load balancers! \ud83d\udc1eFix (PRO/Enteprise) fix redirect loop with JWT deep linking when JWT token expires \ud83e\uddd0Enhancement (PRO/Enteprise) fix audit demo page CSS \ud83e\uddd0Enhancement (Enteprise) SAML more configuration parameters available \ud83d\ude80New Feature (PRO/Enteprise) set ROR to debug mode (readonlyrest_kbn.logLevel: \"debug\") What's new in 1.16.33 \ud83d\udc1eFix (PRO/Enteprise) compatibility problems with older Kibana versions \ud83d\udc1eFix (PRO/Enteprise) compatibility problems with OSS Kibana version What's new in 1.16.32 \ud83d\ude80New Feature \"kibanaIndexTemplate\": default dashboards and spaces for new tenants \ud83e\uddd0Enhancement Support for ES/Kibana 6.5.4 \ud83e\uddd0Enhancement Upgraded LDAP library \ud83e\uddd0Enhancement (Enterprise) Now tenants save their CSV exports in their own reporting index \ud83d\udc1eFix (PRO/Enteprise) Support passwords that start and/or end with spaces \ud83d\udc1eFix (PRO/Enterprise) Now reporting works again What's new in 1.16.31 \ud83e\uddd0Enhancement Support for ES/Kibana 6.5.2, 6.5.3 \ud83d\udea7WIP : Laid out the foundation for LDAP HA support What's new in 1.16.29 \ud83e\uddd0Enhancement Support for ES/Kibana 6.4.3 \ud83d\ude80New Feature (PRO/Enterprise) configurable server side session duration \ud83d\ude80New Feature [LDAP] High Availability: Round Robin or Failover What's new in 1.16.28 \ud83e\uddd0Enhancement Support for ES/Kibana 6.4.2 \ud83d\udc1eFix (Enterprise) Multi tenancy: sometimes changing tenancy would not change kibana index \ud83d\udc1eSecurity Fix (Enterprise/PRO) Avoid echoing Base64 encoded credentials in login form error message \ud83e\uddd0Enhancement (Enterprise/PRO) Remove latest search/visualization/dashboard history on logout \ud83e\uddd0Enhancement (Enterprise/PRO) Clear transient authentication cookies on login error to avoid authentication deadlocks \ud83d\udc1eFix : External JWT verification may throw ArrayOutOfBoundException \ud83d\udea7WIP : Laid out the foundation for internode SSL transport (port 9300) What's new in 1.16.27 \ud83d\ude80New Feature [JWT] external validator: it's now possible to avoid storing the private key in settings \ud83e\uddd0Enhancement Support for ES/Kibana 6.4.1 \ud83e\uddd0Enhancement Rewritten big part of ES plugin documentation \ud83e\uddd0Enhancement SAML Single log out flow \ud83d\udc1eFix (Enterprise/PRO) cookiePass works again, but only for Kibana 5.x. Newer Kibana needs sticky sessions in LB. \ud83e\uddd0Enhancement (Enterprise/PRO) much faster logout What's new in 1.16.26 \ud83d\udc1e Fix (PRO/Enterprise) bugs during plugin packaging and installation process What's new in 1.16.25 \ud83d\ude80New Feature Users rule: easily restrict external authentication to a list of users \ud83e\uddd0Enhancement Support for ES 5.6.11 \ud83d\udc1eHot Fix (Enterprise/PRO) Error 404 when logging in with older versions of Kibana What's new in 1.16.24 \ud83d\ude80New Feature (Enterprise) SAML Authentication \ud83d\ude80New Feature Support for Elasticsearch and Kibana 6.4.0 \ud83d\ude80New Feature Headers rule now split in headers_or and headers_and \ud83e\uddd0Enhancement Headers rule now allows wildcards \ud83d\ude80New Feature (Enterprise) Multi-tenancy now works also with JSON groups provider \ud83d\udc1e Fix Multi-tenancy (Enterprise) incoherent initial kibana_index and current group What's new in 1.16.23 \ud83e\uddd0Enhancement Support for Elastic Stack 6.3.1 and 5.6.10 \ud83d\ude80New Feature (Enterprise) Custom CSS injection for Kibana \ud83d\ude80New Feature (Enterprise) Custom Javascript injection for Kibana \ud83d\ude80New Feature (PRO/Enterprise) access paths without need to login (i.e. /api/status) \ud83d\udc1eFix (PRO/Enterprise) Navigating to X-Pack APM caused hidden Kibana apps to reappear What's new in 1.16.22 \ud83d\ude80New Feature: map LDAP groups to local groups (a.k.a. role mapping) \ud83d\udc1e Fix (Elasticsearch) wildcard aliases resolution not working in \"indices\" rule. \ud83e\uddd0Enhancement: it is now possible now to use JDK 9 and 10 \ud83d\udc1e Fix (PRO/Enterprise) wait forever for login request (i.e. slow LDAP servers) \ud83d\udc1e Fix (PRO/Enterprise) add spinner and block UI if login request is being sent \ud83d\udc1e Fix (PRO/Enterprise) if user is logged out because of LDAP cache expiring + slow authentication, redirect to login. \ud83d\udc1e Fix (PRO/Enterprise) let RO users delete/edit search filters What's new in 1.16.21 \ud83d\ude80New Feature: Introducing support for Elasticsearch and Kibana v6.3.0 \ud83d\udc1e Fix (Enterprise) multi tenancy - switching tenancy does not always switch kibana index What's new in 1.16.20 ReadonlyREST PRO/Enterprise for Kibana \ud83e\uddd0 Enhancement : when login, forward \"elasticsearch.requestHeadersWhitelist\" headers. (useful for \"headers\" rule and \"proxy_auth\" to work well.) ReadonlyREST for Elasticsearch \ud83d\ude80New Feature : DLS (with dynamic variables suppoort) Thanks DataSweet ! \ud83d\ude80 New feature : Field level security \ud83d\ude80 New rules : Snapshot, Repositories, Headers \ud83e\uddd0 Enhancement : custom audit serializers: the request content is available \ud83d\udc1e Fix readonlyrest.yml path discovery \ud83d\udc1e Fix: LDAP available groups discovery (tenancy switcher) corner cases \ud83d\udc1e Fix : auth_key_sha1, auth_key_sha256 hashes in settings should be case insensitive \ud83d\udc1e Fix : LDAP authentication didn't work with local group","title":"Changelog"},{"location":"changelog/#changelog","text":"","title":"Changelog"},{"location":"changelog/#2022-07-25-whats-new-in-ror-1420","text":"\ud83d\ude80New (KBN|ES) 8.3.3, 8.3.2, 8.3.1, 8.3.0, 7.15.5 support \ud83e\uddd0Enhancement (KBN) Search box in tenancy switcher (when #tenancies > 5) \ud83e\uddd0Enhancement (ES) added configuration warnings in the Impersonation Feature \ud83d\udc1eFix (KBN) Logout didn\u2019t delete the SAML session on the IdP \ud83d\udc1eFix (KBN) 5xx errors from Elasticsearch break Kibana users\u2019 session unrecoverably \ud83d\udc1eFix (ES) ROR node cooperation with X-pack nodes","title":"(2022-07-25) What's new in ROR 1.42.0"},{"location":"changelog/#2022-06-21-whats-new-in-ror-1410","text":"\ud83d\ude80New (ES) Added groups_and mode to ror_kbn_auth and jwt_auth rules \ud83e\uddd0Enhancement (KBN) Prevent native credentials dialogue to appear in Kibana when ES responds 401 \ud83e\uddd0Enhancement (KBN) Logging in after logout shows the same page you last visited \ud83e\uddd0Enhancement (KBN) x-ror-correlation-id header lets you audit a whole Kibana session \ud83d\udc1eFix (ES|KBN) tenancy selector didn't work well with jwt_auth and ror_kbn_auth rules \ud83d\udc1eFix (KBN) Support for special characters in tenancy names \ud83d\udc1eFix (KBN) OIDC logout flow redirecting to bad request error \ud83d\udc1eFix (KBN) OIDC connector not working in Kibana < 7.12.0","title":"(2022-06-21) What's new in ROR 1.41.0"},{"location":"changelog/#2022-05-24-whats-new-in-ror-1400","text":"\ud83d\udea8Security Fix (ES) CVE-2022-25647 & CVE-2022-24823 & CVE-2020-13956 & CVE-2020-36518 & CVE-2020-13956 & CVE-2020-36518 \ud83d\udea8Security Fix (KBN) \u201cSecurity\u201d app not entirely hidden in 8.2.x \ud83d\ude80New (ES) New Support for 8.2.3, 8.2.2, 8.2.1, 7.17.4 \ud83d\ude80New (KBN) New Support for 8.2.2 8.2.1, 7.17.4 \ud83d\ude80New (ES & KBN) The Impersonation feature \ud83d\ude80New (ES) FIPS compliant SSL mode \ud83e\uddd0Enhancement (KBN) SAML cert is now required \ud83e\uddd0Enhancement (KBN) moved OIDC to better library \ud83e\uddd0Enhancement (KBN) OIDC jwksURL is now required \ud83d\udc1eFix (ES) indices: [\"1\"] interpreted as integer and fails to parse \ud83d\udc1eFix (KBN) /login?jwt=xxx authorization now works again \ud83d\udc1eFix (KBN) OIDC/SAML assertion claims were not forwarded to ES \ud83d\udc1eFix (KBN) include whitelisted headers while logging \ud83d\udc1eFix (KBN) basepath handling fixes (too many redirects) \ud83d\udc1eFix (KBN) Make ROR default space the actual default one \ud83d\udc1eFix (KBN) RORDEV-641 Fix oidc connection error","title":"(2022-05-24) What's new in ROR 1.40.0"},{"location":"changelog/#2022-03-19-whats-new-in-ror-1390","text":"\ud83d\udea8Security Fix (KBN) XSS sanitize path requested \ud83d\udea8Security Fix (ES) CVE-2020-36518 & CVE-2022-21653 \ud83d\ude80New (KBN) New Support for 8.2.0 8.1.3, 8.1.2, 8.1.1, 8.1.0, 8.0.0, 8.0.1, 7.17.3, 7.17.2 \ud83d\ude80New (ES) New Support for 8.2.0, 8.1.3, 8.1.2, 8.1.1, 8.1.0, 8.0.0, 8.0.1 ( required additional patching step ) \ud83d\ude80New (ES) New Support for 7.17.3, 7.17.2 \ud83d\ude80New (ES) New groups_and ACL rule \ud83e\uddd0Enhancement (KBN) Stop inlining whitelisted headers into Authorization header \ud83e\uddd0Enhancement (KBN) Log additional errors and info related to HA \ud83e\uddd0Enhancement (KBN) Misc internal dependencies upgrades \ud83d\udc1eFix (KBN) Mandatory elasticsearch credentials in kibana.yml \ud83d\udc1eFix (KBN) Reporting page redirect on refresh when kibana_hide_apps: [\"Stack Management\"] \ud83d\udc1eFix (KBN) whitelistedPaths: log errors when 404 occurs \ud83d\udc1eFix (KBN) Issue uploading large payload \ud83d\udc1eFix (KBN) elasticsearch.requestHeadersWhitelist should be case insensitive \ud83d\udc1eFix (ES) Issue with handling data streams by indices rule \ud83d\udc1eFix (ES) X-Pack SSL nodes cooperation with ROR SSL nodes \ud83d\udc1eFix (ES) _msearch issue when filter rules was used in matched block","title":"(2022-03-19) What's new in ROR 1.39.0"},{"location":"changelog/#2022-01-17-whats-new-in-ror-1380","text":"\ud83d\ude80New (ES) New Support for 7.17.0, 7.17.1 \ud83d\ude80New (KBN) New Support for 7.17.0 \ud83d\ude80New (ES) Configuration for custom audit cluster \ud83e\uddd0Enhancement (ES) Separate \"audit\" section for all audit settings \ud83d\udc1eFix (KBN) Editor rendering issue with kibana basePath enabled","title":"(2022-01-17) What's new in ROR 1.38.0"},{"location":"changelog/#2021-12-14-whats-new-in-ror-1370","text":"\ud83d\udea8Security Fix (ES) CVE-2021-43797 \ud83d\ude80New (ES) New Support for 7.16.3, 7.16.2, 6.8.23, 6.8.22 \ud83d\ude80New (KBN) New Support for 7.16.3, 7.16.2, 7.16.1, 7.16.10, 6.8.23, 6.8.22, 6.8.21 \ud83e\uddd0Enhancement (ES) fields rule handling in the context of x-Pack SQL requests \ud83d\udc1eFix (ES) filter rule handling in the context of x-Pack SQL requests \ud83d\udc1eFix (KBN) POST / bulk cause an 400 error in devtools console \ud83d\udc1eFix (KBN) More robust Kibana patcher + better logs messages","title":"(2021-12-14) What's new in ROR 1.37.0"},{"location":"changelog/#2021-11-21-whats-new-in-ror-1360","text":"\ud83d\ude80New (ES) New Support for 7.16.1, 7.16.0, 6.8.21 \ud83d\ude80New (KBN) Support Kibana 7.15.2 \ud83d\ude80New (ES) Added support for setting up cluster containing ES with ROR (with disabled XPack security) and ES with XPack security enabled \ud83e\uddd0Enhancement (KBN) kibana_hide_apps: [ror|kibana] to remove kibana mgmt button \ud83d\udc1eFix (ES) /_snapshot/_status should return only running snapshots \ud83d\udc1eFix (ES) Adding policy to index template bug \ud83d\udc1eFix (KBN) Index management tabs result in \"forbidden\" error \ud83d\udc1eFix (KBN) corrupted patch file for Kibana 7.9.x \ud83d\udc1eFix (KBN) YAML editor not working in air-gapped environments \ud83d\udc1eFix (KBN) Devtools not working \ud83d\udc1eFix (KBN) Monitoring not working in multi-tenancy \ud83d\udc1eFix (KBN) Regression in Kibana < 6.8.x front end crash \ud83d\udc1eFix (KBN) Kibana < 7.8.x prevent navigation to hidden apps from home links \ud83d\udc1eFix (KBN) Kibana < 7.8.x implicitly hide kibana:dashboard when kibana:dashboards is hidden (and viceversa) \ud83d\udc1eFix (KBN) Kibana < 7.8.x broken clearSessionOnEvents: [tenancyHop]","title":"(2021-11-21) What's new in ROR 1.36.0"},{"location":"changelog/#2021-10-17-whats-new-in-ror-1351","text":"\ud83d\udea8Security Fix (ES) CVE-2021-21409 & CVE-2021-27568 \ud83d\ude80New (KBN) Support Kibana 7.15.1 \ud83d\ude80New (ES) New Support for 7.15.2 \ud83e\uddd0Enhancement (KBN) Support \"server.ssl.supportedProtocols\" settings \ud83e\uddd0Enhancement (KBN) Support \"server.ssl.cipherSuites\" \ud83e\uddd0Enhancement (KBN) Always honor SSL cipher order \ud83d\udc1eFix (KBN) Don'thide \"Add/Remove field as column\" in Discover app for RO users \ud83d\udc1eFix (KBN) More alerting fixes (only for main tenancy)","title":"(2021-10-17) What's new in ROR 1.35.1"},{"location":"changelog/#2021-10-12-whats-new-in-ror-1350","text":"\ud83d\ude80New (KBN) Support Kibana 7.15.0, 7.14.2 \ud83d\ude80New (ES) New Support for 7.15.1, 6.8.19, 6.8.20 \ud83e\uddd0Enhancement (ES) local->external groups detailed mapping for groups rule \ud83e\uddd0Enhancement (ES) when ROR is starting any request is going to end up with HTTP 403 response, instead of HTTP 503 \ud83e\uddd0Enhancement (KBN) \"server.basePath\" kibana option implementation \ud83e\uddd0Enhancement (KBN) Support full regex in kibana_hidden_apps rule \ud83e\uddd0Enhancement Crash if Kibana is not patched \ud83e\uddd0Enhancement (KBN) Honour kibana setting \"logging.dest\" \ud83e\uddd0Enhancement (KBN) Confirm before overwriting audit log dashboard \ud83d\udc1eFix (ES) verbosity: error fix in case of ROR KBN login request \ud83d\udc1eFix (KBN) Make alerting work on primary tenancy \ud83d\udc1eFix (KBN) OIDC fix sameSite / secure cookie options \ud83d\udc1eFix (KBN) Login form is stretched when long error \ud83d\udc1eFix (KBN) Login form is stretched when long error \ud83d\udc1eFix (KBN-PRO) Don't send x-ror-currentgroup in PRO \ud83d\udc1eFix (KBN) Resolve browser console errors on a popover close","title":"(2021-10-12) What's new in ROR 1.35.0"},{"location":"changelog/#2021-09-24-whats-new-in-ror-1340","text":"\ud83d\ude80New (ES) New Support for 7.15.0, 7.14.2 \ud83d\ude80New (KBN) VS Code style YAML editor \ud83d\ude80New (KBN) Skip rendering hidden app groups entirely \ud83d\ude80New (KBN) Redesigned ROR Menu \ud83d\ude80New (KBN) Dark theme awareness \ud83d\udc1eFix (KBN) Broken Kibana Spaces \ud83d\udc1eFix (KBN) Support Kibana's undocumented \"server.ssl.*\" settings \ud83d\udc1eFix (KBN) cookiePass config parsing broke load balancing","title":"(2021-09-24) What's new in ROR 1.34.0"},{"location":"changelog/#2021-08-14-whats-new-in-ror-1331","text":"\ud83d\ude80New (ES) New Support for 7.14.1 \ud83d\udc1eFix (KBN) Error in patching for 7.14.0 \ud83d\udc1eFix (KBN) clearSessionOnEvents now works as expected \ud83d\udc1eFix (KBN) login form font loads correctly","title":"(2021-08-14) What's new in ROR 1.33.1"},{"location":"changelog/#2021-08-09-whats-new-in-ror-1330","text":"\ud83d\udea8Security Fix (KBN) xml-crypto dependency update \ud83d\ude80New (KBN) New Support for 7.14.0, 6.8.18 \ud83e\uddd0Enhancement (KBN) Parse credentials in /api/* requests, no need for valid cookie. Supersedes whitelistedPaths \ud83d\udc1eFix (KBN)Caching issues switching tenancies with dark/light theme \ud83d\udc1eFix (KBN) Newly created Space shows in all tenancies when using default kibana index \ud83d\udc1eFix (KBN < 7.9.x) nextUrl works again with SAML and OIDC","title":"(2021-08-09) What's new in ROR 1.33.0"},{"location":"changelog/#2021-07-25-whats-new-in-ror-1320","text":"\ud83d\udea8Security Fix (ES) Apache Commons Codec vulnerability \ud83d\udea8Security Fix (KBN) upgraded dependencies due to security fixes \ud83d\udea8Security Fix (KBN) disable x-powered-by to avoid fingerprinting \ud83d\ude80New (ES) Support for ES 7.14.0 & 6.8.18 \ud83d\ude80New (KBN) Support for Kibana 7.13.x series \ud83e\uddd0Enhancement (KBN) honor configurations coming from ENV and CLI options \ud83e\uddd0Enhancement (KBN) when metadata has no username, login must be denied \ud83e\uddd0Enhancement (KBN) audit tab ported to new platform \ud83e\uddd0Enhancement (ES) improved ES resources cleaning when ROR returns FORBIDDEN response \ud83e\uddd0Enhancement (KBN < 7.9.x) auto clean-up dangling SAML/OIDC cookies \ud83d\udc1eFix (ES) incomplete response for request GET */_alias \ud83d\udc1eFix (ES) not allowed aliases should not present in a response for a Get Index API request \ud83d\udc1eFix (KBN) fix dev-tools and import saved object not working \ud83d\udc1eFix (KBN) honor requestHeadersWhitelist in user metadata request (login) \ud83d\udc1eFix (KBN < 7.9.x) do not crash on invalid metadata","title":"(2021-07-25) What's new in ROR 1.32.0"},{"location":"changelog/#2021-06-29-whats-new-in-ror-1310","text":"\ud83d\udea8Security Fix (KBN) prevent direct navigation to hidden apps \ud83d\ude80New (ES) 7.13.4, 7.13.3, 7.13.2, 6.8.17 support \ud83d\ude80New (KBN) new minimal Kibana Management menu when \"Management\" app is hidden \ud83e\uddd0Enhancement (KBN) logout active Kibana session if key metadata/permissions change in ACL \ud83e\uddd0Enhancement (KBN) better port number validation \ud83e\uddd0Enhancement (ES) improved cluster indices handling \ud83d\udc1eFix (ES) Kibana access rule regression fix \ud83d\udc1eFix (ES) search template API handling with filter and fields rule \ud83d\udc1eFix (ES) multi-tenancy issue when groups_provider_authorization is used \ud83d\udc1eFix (ES) x_forwarded_for rule: wrong handling of / request \ud83d\udc1eFix (ES) Issue with handling ResizeRequest which made it unable to upgrade Kibana to version 7.12.0+ \ud83d\udc1eFix (KBN) some Kibana requests arrive to ES without credentials \ud83d\udc1eFix (KBN) inconsistent read after write in session storage lead to issues with round robin load balancing \ud83d\udc1eFix (KBN) bad multipart POST handling leads to saved object import errors","title":"(2021-06-29) What's new in ROR 1.31.0"},{"location":"changelog/#2021-05-26-whats-new-in-ror-1301","text":"\ud83d\udea8Security Fix (ES) CVE-2021-27568 \ud83d\ude80New (ES) 7.13.0, 7.13.1 support \ud83d\udc1eFix (ES) Regression in multi-tenancy handling \ud83d\udc1eFix (ES) Proper handling of _snapshot/_status endpoint","title":"(2021-05-26) What's new in ROR 1.30.1"},{"location":"changelog/#2021-05-16-whats-new-in-ror-1300","text":"\ud83d\ude80New (KBN) 7.12.x compatibility \ud83d\ude80New (ES) LDAP connector circuit breaker \ud83e\uddd0Enhancement (ES) Username with wildcard support in users section and groups mapping \ud83e\uddd0Enhancement (KBN < 7.9.x) OIDC errors visibility \ud83e\uddd0Enhancement (KBN < 7.9.x) Smarter session probe algorithm \ud83d\udc1eFix (KBN >= 7.9.x) Load CertificateAuthorities as an array if not specified as an array \ud83d\udc1eFix (KBN < 7.9.x) Don't hide visualizations list search box in RO mode","title":"(2021-05-16) What's new in ROR 1.30.0"},{"location":"changelog/#2021-04-09-whats-new-in-ror-1290","text":"\ud83d\udea8Security Fix (ES) Security Fix (ES) CVE-2021-21409 \ud83d\ude80New (KBN) support 7.9.0, 7.9.1, 7.10.0, 7.10.1, 7.10.2, 7.11.0, 7.11.1, 7.11.2 ( with ROR new platform ) \ud83d\ude80New (ES) 7.12.1 support \ud83e\uddd0Enhancement (KBN) logout if the credentials/metadata of the current user change in the ACL","title":"(2021-04-09) What's new in ROR 1.29.0"},{"location":"changelog/#2021-04-01-whats-new-in-ror-1282","text":"\ud83d\udea8Security Fix (ES) CVE-2021-21295 \ud83d\udc1eFix (KBN) prevent SAML/OIDC initiated Kibana sessions from expiring after session_timeout_minutes despite continued interaction","title":"(2021-04-01) What's new in ROR 1.28.2"},{"location":"changelog/#2021-03-24-whats-new-in-ror-1281","text":"\ud83d\udc1eFix (ES) Getting index templates issue when no indices rule was used in matched block \ud83d\udc1eFix (ES) NPE on getting template aliases","title":"(2021-03-24) What's new in ROR 1.28.1"},{"location":"changelog/#2021-03-14-whats-new-in-ror-1280","text":"\ud83d\ude80New (ES) 7.12.0, 7.11.2 support \ud83d\ude80New (ES) full Index and Component Templates API support \ud83e\uddd0Enhancement (ES) Username case sensitivity settings \ud83d\udc1eFix (ES) Kibana logout event storing fix \ud83d\udc1eFix (ES) Fixed remote reindex operation with \"type\" parameter \ud83d\udc1eFix (KBN) Prevent cookie expiration deadlock in browsers when using SAML/OIDC \ud83d\udc1eFix (KBN) When credentials change in the ACL, make it possible to login again \ud83d\udc1eFix (KBN) Kibana management app ID changed from \"kibana:management\" to \"kibana:stack_management\"","title":"(2021-03-14) What's new in ROR 1.28.0"},{"location":"changelog/#2021-02-27-whats-new-in-ror-1271","text":"\ud83d\udea8Security Fix (ES) CVE-2021-21290 \ud83d\ude80New (ES) 7.11.1 support","title":"(2021-02-27) What's new in ROR 1.27.1"},{"location":"changelog/#2021-02-16-whats-new-in-ror-1270","text":"\ud83d\ude80New (ES) 7.11.0, 7.10.2, 6.8.14 support \ud83e\uddd0Enhancement (KBN) X-Forwarded-For copied from incoming request (or filled with source IP) before forwarding to ES \ud83e\uddd0Enhancement (KBN) Kibana logout event generates a special audit log entry in ROR audit logs index \ud83e\uddd0Enhancement (KBN) ROR panel shows \"reports\" button if kibana:management app is hidden \ud83d\udc1eFix (ES) blocks containing filter and/or fields won't match internal kibana requests, so kibana_* rules won't have to be placed in such blocks \ud83d\udc1eFix (ES) SQL API - better handling of invalid query","title":"(2021-02-16) What's new in ROR 1.27.0"},{"location":"changelog/#2021-01-11-whats-new-in-ror-1261","text":"\ud83d\udc1eFix (ES) wrong behaviour of kibana_access rule for ROR actions when ADMIN value is set","title":"(2021-01-11) What's new in ROR 1.26.1"},{"location":"changelog/#2021-01-02-whats-new-in-ror-1260","text":"\ud83d\udea8Security Fix (ES) CVE-2020-35490 & CVE-2020-35490 (removed Jackson dependency from ROR core) \ud83d\ude80New (ES) New response_fields rule \ud83d\ude80New (ES) Support for LDAP server discovery using _ldaps._tcp SRV record \ud83d\ude80 New (ES) New configuration option allowing to ignore LDAP connectivity problems \ud83e\uddd0Enhancement (ES) Full support for ILM API \ud83e\uddd0Enhancement (KBN) Enforce read-after-write consistency between kibana nodes \ud83e\uddd0Enhancement (KBN ENT) OIDC custom claims incorporated in \"assertion\" claim \ud83e\uddd0Enhancement (KBN ENT) OIDC support for configurable kibanaExternalHost (good for Docker) \ud83e\uddd0Enhancement (KBN ENT) ROR adds \"ror-user_\" class to \"body\" tag for easy per-user CSS/JS \ud83e\uddd0Enhancement (KBN ENT/PRO) ROR adds \"ror-group_\" class to \"body\" tag for easy per-group CSS/JS \ud83d\udc1eFix (ES) ROR authentication endpoint action \ud83d\udc1eFix (ES) \"username\" in audit entry when request is rejected","title":"(2021-01-02) What's new in ROR 1.26.0"},{"location":"changelog/#whats-new-in-1252","text":"\ud83d\udc1eFix (ES) removed verbose logging","title":"What's new in 1.25.2"},{"location":"changelog/#whats-new-in-1251","text":"\ud83d\udea8Security Fix (ES) CVE-2020-25649 \ud83d\ude80New (ES) 7.10.1 support","title":"What's new in 1.25.1"},{"location":"changelog/#whats-new-in-1250","text":"\ud83d\udea8Security Fix (ES) Common Vulnerabilities and Exposures (CVE) \ud83d\ude80New (ES) 7.10.0 support \ud83d\ude80New (ES) auth_key_pbkdf2 rule \ud83d\ude80New (ES) Introduced configuration property defining FLS engine used by fields rule \ud83e\uddd0Enhancement (ES) Fields rule performance improvement \ud83e\uddd0Enhancement (ES) Resolved index API support \ud83d\udc1eFix (ES) \"username\" in audit entry when user is authenticated via proxy_auth \ud83d\udc1eFix (ES) index resolve action should be treated as readonly action \ud83d\udc1eFix (ES) /_snapshot and /_snapshot/_all should behave the same","title":"What's new in 1.25.0"},{"location":"changelog/#whats-new-in-1240","text":"\ud83d\udea8Security Fix (ES) search template handling fix \ud83d\ude80New (ES) 7.9.3 & 6.8.13 support \ud83e\uddd0Enhancement (ES) full support for ES Snapshots and Restore APIs \ud83d\udc1eFix (KBN) fix crash in error handling \ud83d\udc1eFix (ES) don't remove ES response warning headers \ud83d\udc1eFix (ES) issue when entropy of /dev/random could have been exhausted when using JwtToken rule","title":"What's new in 1.24.0"},{"location":"changelog/#whats-new-in-1231","text":"\ud83d\ude80New (ES) 7.9.2 support \ud83d\udc1eFix (KBN) fix code 500 error on login in Kibana","title":"What's new in 1.23.1"},{"location":"changelog/#whats-new-in-1230","text":"\ud83d\ude80New (ES) introduced must_involve_indices option for indices rule \ud83e\uddd0Enhancement (ES) negation support in headers rules \ud83e\uddd0Enhancement (ES) x-pack rollup API handling \ud83d\udc1eFix (KBN) deep links query parameters are now handled \ud83d\udc1eFix (KBN) make sure default kibana index is always discovered (fixes reporting in 6.x) \ud83d\udc1eFix (ES) settings file permission issue with JDK 1.8.0 25.262-b10 \ud83d\udc1eFix (ES) /_cluster/allocation/explain request should not be forbidden if matched block doesn't have indices rules \ud83d\udc1eFix (ES) remote address extracting issue \ud83d\udc1eFix (ES) fixed TYP audit field for some request types","title":"What's new in 1.23.0"},{"location":"changelog/#whats-new-in-1221","text":"\ud83d\udc1eFix (ES) missing handling of aliases API for ES 7.9.0","title":"What's new in 1.22.1"},{"location":"changelog/#whats-new-in-1220","text":"\ud83d\ude80New (ES) 7.9.0 support \ud83e\uddd0Enhancement (ES) aliases API handling \ud83e\uddd0Enhancement (ES) dynamic variables support in fields rule \ud83d\udc1eFix (ES) adding aliases issue \ud83d\udc1eFix (ES) potential memory leak for ES 7.7.x and above \ud83d\udc1eFix (ES) cross cluster search issue fix for X-Pack _async_search action \ud83d\udc1eFix (ES) XFF entry in audit issue \ud83d\udc1eFix (KBN) SAML certificate loading \ud83d\udc1eFix (KBN) SAML loading groups from assertion \ud83d\udc1eFix (KBN) fix reporting in pre-7.7.0","title":"What's new in 1.22.0"},{"location":"changelog/#whats-new-in-1210","text":"\ud83e\uddd0Enhancement (ES) cluster API support improvements \ud83d\udc1eFix (ES) X-Pack _async_search support \ud83d\udc1eFix (ES) _rollover request handling \ud83d\udc1eFix (ES) handling numeric ssl configuration properties \ud83d\udc1eFix (KBN) multitenancy+reporting regression fix (for 7.6.x and earlier) \ud83d\udc1eFix (KBN) \"x-\" headers should be forwarded in /login route when proxy passthrough is enabled \ud83d\udc1eFix (KBN) Logout now redirects to login screen when using proxy \ud83d\udc1eFix (KBN) SAML metadata.xml endpoint not responding \ud83d\udc1eFix (KBN) NAT/reverse proxy support for SAML \ud83d\udc1eFix (KBN) SAML login redirect error \ud83d\udc1eFix (ES) _readonlyrest/metadata/current_user should be always allowed by filter/fields rule","title":"What's new in 1.21.0"},{"location":"changelog/#whats-new-in-1200","text":"\ud83d\ude80New 7.7.1, 7.8.0 support \ud83e\uddd0Enhancement (KBN) tidy up audit page \ud83e\uddd0Enhancement (KBN FREE) clearly inform when features are not available \ud83e\uddd0Enhancement (KBN) ship license report of libraries \ud83e\uddd0Enhancement (ES) filter rule performance improvement \ud83d\udc1eFix (KBN) proxy_auth: avoid logout-login loop \ud83d\udc1eFix (KBN) 404 error on font CSS file \ud83d\udc1eFix (ES) wildcard in filter query issue \ud83d\udc1eFix (ES) forbidden /_snapshot issue \ud83d\udc1eFix (ES) /_mget handling by indices rule when no index from a list is found \ud83d\udc1eFix (ES) available groups order in metadata response should match the order in which groups appear in ACL \ud83d\udc1eFix (ES) .readonlyrest and audit index - removed usage of explicit index type \ud83d\udc1eFix (ES) tasks leak bug","title":"What's new in 1.20.0"},{"location":"changelog/#whats-new-in-1195","text":"\ud83d\ude80New 7.7.0, 7.6.2, 6.8.9, 6.8.8 support \ud83e\uddd0Enhancement (ES/KBN) kibana_access can be explicitly set to unrestricted \ud83e\uddd0Enhancement (ES) LDAP connection pool improvement \ud83d\udc1eFix (ES) better LDAP request timeout handling \ud83d\udc1eFix (ES) remote indices searching bug \ud83d\udc1eFix (ES) cross cluster search support for _field_caps request \ud83d\udea8Security Fix (ES) create and delete templates handling \ud83d\udc1eFix (KBN) Regression in proxy_auth_passthrough \ud83e\uddd0Enhancement (KBN) whitelistedPaths now accepts basic auth credentials \ud83e\uddd0Enhancement (KBN) Dump logout button, new ROR Panel \ud83e\uddd0Enhancement (KBN) removed ROR from Kibana sidebar. Admins have a link in new panel. \ud83e\uddd0Enhancement (KBN) avoid show login form redirecting from SAML IdP \ud83d\ude80New (KBN) OpenID Connect (OIDC) authentication connector \ud83d\ude80New (KBN) login_title, login_subtitle enable 2 column login page \ud83d\udea8Security Fix (KBN) server-side navigation prevention to hidden apps","title":"What's new in 1.19.5"},{"location":"changelog/#whats-new-in-1194","text":"\ud83d\udc1eFix (ES) Interpolating config with environment variables in SSL section \ud83d\udc1eFix (KBN Ent 6.x) Fixed default space creation in \ud83d\udc1eFix (KBN 6.x) Fixed error toast notification not showing \ud83d\udc1eFix (KBN Ent) Fixed missing Axios dependency \ud83d\udc1eFix (KBN Ent) Fixed SAML connector \ud83d\udc1eFix (KBN) Toast notification overlap with logout bar \ud83e\uddd0Enhancement (KBN) Restyled logout bar \ud83e\uddd0Enhancement (KBN) Configurable periodic session checker","title":"What's new in 1.19.4"},{"location":"changelog/#whats-new-in-1193","text":"\ud83d\ude80New (ES/KBN) 7.6.1 compatibility \ud83d\ude80New (ES) customizable name of settings index \ud83e\uddd0Enhancement (KBN) configurable ROR cookie name \ud83e\uddd0Enhancement (ES/KBN) handling of encoded ROR headers in Authorization header values \ud83e\uddd0Enhancement (KBN) user feedback on why login failed \ud83d\udc1eFix (ES) support for multiple header values \ud83d\udc1eFix (ES) releasing LDAP connection pool on reloading ROR settings \ud83d\udc1eFix (KBN) multitenancy issue with 7.6.0+ \ud83d\udc1eFix (KBN) creation of default space for new tenant \ud83d\udc1eFix (KBN 6.x) in RO mode, don't hide add/remove over fields in discovery \ud83d\udc1eFix (KBN 6.x) index template & in-index session manager issues","title":"What's new in 1.19.3"},{"location":"changelog/#whats-new-in-1192","text":"\ud83d\ude80New (KBN) 7.6.0 support \ud83e\uddd0Enhancement (KBN) less verbose info logging \ud83e\uddd0Enhancement (KBN) start up time semantic check for settings \ud83d\udc1eFix (KBN Free) missing logout button \ud83d\udc1eFix (KBN) error message creating internal proxy \ud83d\udc1eFix (KBN 6.x) add field to filter button invisible in RO mode","title":"What's new in 1.19.2"},{"location":"changelog/#whats-new-in-1191","text":"\ud83c\udf81Product (KBN) Launched ReadonlyREST Free for Kibana! \ud83d\ude80New (ES) 7.6.0 support, Kibana support coming soon \ud83d\ude80New (KBN) Audit log dashboard \ud83d\ude80New (KBN) Template index can now be declared per tenant instead of globally \ud83d\ude80New (ES) custom trust store file and password options in ROR settings \ud83e\uddd0Enhancement (ES) When \"prompt_for_basic_auth\" is enabled, ROR is going to return 401 instead of 404 when the index is not found or a user is not allowed to see the index \ud83e\uddd0Enhancement (ES) literal ipv6 with zone Id is acceptable network address \ud83e\uddd0Enhancement (ES) LDAP client cache improvements \ud83d\udc1eFix (ES) /_all/_settings API issue \ud83d\udc1eFix (ES) Index stats API & Index shard stores API issue \ud83d\udc1eFix (ES) readonlyrest.force_load_from_file setting decoding issue \ud83d\udc1eFix (KBN) allowing user to be logged in in two tabs at the same time \ud83d\udc1eFix (KBN) logging with JWT parameter issue \ud83d\udc1eFix (KBN) parsing of sessions fetched from ES index \ud83d\udc1eFix (KBN) logout issue","title":"What's new in 1.19.1"},{"location":"changelog/#whats-new-in-1190","text":"\ud83d\ude80New (KBN) Configurable option to delete docs from tenant index when not present in template \ud83e\uddd0Enhancement (ES) Less verbose logging of blocks history \ud83e\uddd0Enhancement (ES) Enriched logs and audit with attempted username \ud83e\uddd0Enhancement (ES) Better settings validation - only one authentication rule can be used in given block \ud83e\uddd0Enhancement (ES/KBN) Plugin versions printing in logs on launch \ud83e\uddd0Enhancement (ES) When user doesn't have access to given index, ROR pretends that the index doesn't exist and return 404 instead of 403 \ud83d\udc1eFix (ES) Searching for nonexistent/forbidden index with wildcard mirrors default ES behaviour instead of returning 403 \ud83d\udc1eFix (KBN) Switching groups bug","title":"What's new in 1.19.0"},{"location":"changelog/#whats-new-in-11810","text":"\ud83d\ude80New (ES/KBN) Support v6.8.6, v7.5.0, v7.5.1 \ud83d\ude80New (KBN) Group names can now be mapped to aliases \ud83d\ude80New (ES) New, more robust and simple method of creating custom audit log serializers \ud83d\ude80New (ES) Example projects with custom audit log serializers \ud83d\udc1e Fix (KBN) Prevent index migration after kibana startup \ud83e\uddd0Enhancement (KBN) If default space doesn't exist in kibana index then copy from default one \ud83e\uddd0Enhancement (KBN) Crypto improvements - store init vector with encrypted data as base64 encoded json. \ud83e\uddd0Enhancement (ES) Better settings validation - prevent duplicated keys in readonlyrest.yml","title":"What's new in 1.18.10"},{"location":"changelog/#whats-new-in-1189","text":"\ud83d\ude80New (ES/KBN) Support v7.4.1, v7.4.2 \ud83d\ude80New (KBN) Kibana sessions stored in ES index \ud83d\udc1e Fix (ES) issue with in-index settings auto-reloading \ud83d\udc1e Fix (ES) _cat/indices empty response when matched block doesn't contain 'indices' rule","title":"What's new in 1.18.9"},{"location":"changelog/#whats-new-in-1188","text":"\ud83d\ude80New (ES/KBN) Support v7.4.0 \ud83d\ude80New (ES) Elasticsearch SQL Support \ud83d\ude80New (ES) Internode ssl support for es5x, es60x, es61x and es62x \ud83d\ude80New (ES) new runtime variable @{acl:current_group} \ud83d\ude80New (ES) namespace for user variable and support for both versions: @{user} and @{acl:user} \ud83d\ude80New (ES) support for multiple values in uri_re rule \ud83e\uddd0Enhancement (ES) more reliable in-index settings loading of ES with ROR startup \ud83e\uddd0Enhancement (ES) less verbose logs in JWT rules \ud83e\uddd0Enhancement (ES) Better response from ROR API when plugin is disabled \ud83e\uddd0Enhancement (ES) Splitting verification ssl property to client_authentication and certificate_verification \ud83d\udc1eFix (ES) issue with backward compatibility of proxy_auth settings \ud83d\udc1eFix (ES) /_render/template request NPE \ud83d\udc1eFix (ES) _cat/indices API bug fixes \ud83d\udc1eFix (ES) _cat/templates API return empty list instead of FORBIDDEN when no indices are found \ud83d\udc1eFix (ES) updated regex for kibana access rule to support 7.3 ES \ud83d\udc1eFix (ES) proper resolving of non-string ENV variables in readonlyrest.yml \ud83d\udc1eFix (ES) lang-mustache search template handling","title":"What's new in 1.18.8"},{"location":"changelog/#whats-new-in-1187","text":"\ud83d\ude80New (ES) Field level security (FLS) supports nested JSON fields \ud83d\udc1eSecurity Fix (ES) Authorization headers appeared in clear in logs \ud83e\uddd0Enhancement (KBN) Don't logout users when they are not allowed to search a index-pattern \ud83e\uddd0Enhancement (ES) Headers obfuscation is now case insensitive","title":"What's new in 1.18.7"},{"location":"changelog/#whats-new-in-1186","text":"\ud83d\ude80New (ES/KBN) Support v7.3.1, v7.3.2 \ud83d\ude80New (ES) Configurable header names whose value should be obfuscated in logs \ud83d\ude80New (KBN) Dynamic variables from user identity available in custom_logout_link \ud83e\uddd0Enhancement (ES) Richer logs for JWT errors \ud83e\uddd0Enhancement (ENT) nextUrl works also with SAML now \ud83e\uddd0Enhancement (ENT) SAML assertion object available in ACL dynamic variables \ud83e\uddd0Enhancement (KBN) Validate LDAP server(s) before accepting new YAML settings \ud83e\uddd0Enhancement (KBN) Ensure a read-only UX for 'ro' users in older Kibana \ud83d\udc1eFix (ES) Fix memory leak from dependency (snakeYAML)","title":"What's new in 1.18.6"},{"location":"changelog/#whats-new-in-1185","text":"\ud83d\udc1eSecurity Fix (ES) indices rule can now properly handle also the templates API \ud83e\uddd0Enhancement (ES) Array dynamic variables are serialized as CSV wrapped in double quotes \ud83e\uddd0Enhancement (ES) Cleaner debug logs (no stacktraces on forbidden requests) \ud83e\uddd0Enhancement (ES) LDAP debug logs fire also when cache is hit \ud83d\ude80New (ES/KBN) Support v7.2.1, v7.3.0 \ud83d\udc1eFix (PRO) PRO plugin crashing for some Kibana versions \ud83d\udc1eFix (ENT) SAML library wrote a too large cookie sometimes \ud83d\udc1eFix (ENT) SAML logout not working \ud83d\udc1eFix (ENT) JWT fix exception \"cannot set requestHeadersWhitelist\" \ud83d\udc1eFix (PRO/ENT) Hide more UI elements for RO users \ud83d\udc1eFix (PRO/ENT) Sometimes not all the available groups appear in tenancy selector \ud83d\udc1eFix (PRO/ENT) Feature \"nextUrl\" broke \ud83d\udc1eFix (PRO/ENT) prevent user kick-out when APM is not configured and you are not an admin \ud83d\ude80New (PRO/ENT) Kibana request path/method now sent to ES (good for policing dev-tools)","title":"What's new in 1.18.5"},{"location":"changelog/#whats-new-in-1184","text":"\ud83d\ude80New (ES) User impersonation API \ud83d\ude80New (ES) Support latest 6.x and 5.x versions \ud83d\udc1eSecurity Fix (ES) filter/fields rules leak \ud83d\udc1eFix (KBN/ENT) allow more action for kibana_access, prevent sudden logout \ud83d\udc1eFix (KBN/ENT) temporarily roll back \"support for unlimited tenancies\"","title":"What's new in 1.18.4"},{"location":"changelog/#whats-new-in-1183","text":"\ud83d\ude80New Support added for ES/Kibana 6.8.1 \ud83e\uddd0Enhancement (ES) Crash ES on invalid settings instead of stalling forever \ud83e\uddd0Enhancement (ES) Better logging on JWT, JSON-paths, LDAP, YAML errors \ud83e\uddd0Enhancement (ES) Block level settings validation to user with precious hints \ud83e\uddd0Enhancement (ES) If force_load_from_file: true, don't poll index settings \ud83e\uddd0Enhancement (ES) Order now counts declaring LDAP Failover HA servers \ud83d\udc1eFix (ES) \"EsIndexJsonContentProvider\" had a null pointer exception \ud83d\udc1eFix (ES) \"es.set.netty.runtime.available.processors\" exception \ud83e\uddd0Enhancement (KBN) Collapsible logout button \ud83e\uddd0Enhancement (KBN) ROR App now uses a HA http client \ud83e\uddd0Enhancement (KBN) Automatic logout for inactivity \ud83e\uddd0Enhancement (KBN) Support unlimited amount of tenancies \ud83d\udc1eFix (KBN/ENT) concurrent multitenancy bug \ud83d\udc1eFix (KBN) Avoid sporadic errors on Save/Load buttons","title":"What's new in 1.18.3"},{"location":"changelog/#whats-new-in-1182","text":"\ud83d\ude80New Support for Elasticsearch & Kibana 7.2.0 \ud83d\udc1eFix (ES) restore indices (\"IDX\") in audit logging \ud83e\uddd0Enhancement (ES) New algorithm of setting evaluation order \ud83d\ude80New (ES) JWT claims as dynamic variables. I.e. \"@{jwt:claim.json.path}\" \ud83d\ude80New (ES) \"explode\" dynamic variables. I.e. indices: [\"@explode{x-indices}\"] \ud83d\udc1eFix (PRO/Enterprise) preserve comments and formatting in YAML editor \ud83d\udc1eFix (PRO/Enterprise) Print error message when session is expired \ud83d\udc1eRegression (PRO/Enterprise) Redirect to original link after login \ud83d\udc1eRegression (PRO/Enterprise) Broken CSV reporting \ud83e\uddd0Enhancement (PRO/Enterprise) Prevent navigating away from YAML editor w/ unsaved changes \ud83d\udc1eFix (Enterprise) Exception when SAML connectors were all disabled \ud83d\udc1eFix (Enterprise) Concurrent tenants could mix up each other kibana index \ud83d\udc1eFix (Enterprise) Cannot inject custom JS if no custom CSS was also declared \ud83d\udc1eFix (Enterprise) Injected JS had no effect on ROR logout button \ud83d\udc1eFix (Enterprise) On narrow screens, the YAML editor showed buttons twice","title":"What's new in 1.18.2"},{"location":"changelog/#whats-new-in-1181","text":"\ud83d\udc1eFix (Elasticsearch) Reindex requests failed for a regression in indices extraction \ud83d\udc1eFix (Elasticsearch) Groups rule erratically failed \ud83d\udc1eFix (Elasticsearch) JWT claims can now contain special characters \ud83e\uddd0Enhancement (Elasticsearch) Better ACL History logging \ud83e\uddd0Enhancement (Elasticsearch) QueryLogSerializer and old custom log serializers work again \ud83d\udc1eFix (PRO/Enterprise) ReadonlyREST icon in Kibana was white on white \ud83d\udc1eFix (Enterprise) SAML connectors could not be disabled \ud83d\udc1eFix (Enterprise) SAML connector \"buttonName\" didn't work","title":"What's new in 1.18.1"},{"location":"changelog/#whats-new-in-1180","text":"\ud83d\ude80New Support for Elasticsearch & Kibana 7.0.1 \ud83e\uddd0Enhancement (Elasticsearch) empty array values in settings are invalid \ud83d\udc1eSecurity Fix (Elasticsearch) arbitrary x-cluster search referencing local cluster \ud83d\udc1eFix (Elasticsearch) ArrayOutOfBoundException on snapshot operations \ud83e\uddd0Enhancement (PRO/Enterprise) History cleaning can now be disabled (\"clearSessionOnEvents\")","title":"What's new in 1.18.0"},{"location":"changelog/#whats-new-in-1177","text":"\ud83d\ude80New Support for Elasticsearch 7.0.0 (Kibana is coming soon) \ud83e\uddd0Enhancement (Elasticsearch) rewritten LDAP connector \ud83e\uddd0Enhancement (Elasticsearch) new core written in Scala is now GA \ud83d\udc1eFix (Enterprise) devtools requests now honor the currently selected tenancy \ud83d\udc1eSecurity Fix (Enterprise/PRO) Fix \"connectorsService\" error in installation","title":"What's new in 1.17.7"},{"location":"changelog/#whats-new-in-1175","text":"\ud83d\ude80New Support for Kibana/Elasticsearch 6.7.1 \ud83e\uddd0Enhancement (Enterprise >= Kibana 6.6.0) Multiple SAML identity provider \ud83d\udc1eSecurity Fix (Enterprise/PRO) Don't pass auth headers back to the browser \ud83d\udc1eFix (Enterprise/PRO) Missing null check caused error in reporting (CSV) \ud83d\udc1eFix (Enterprise) Don't reject requests if SAML groups are not configured \ud83d\udc1eFix filter/fields rules not working in msearch (in 6.7.x) \ud83e\uddd0Enhancement Print whole LDAP search query in debug log","title":"What's new in 1.17.5"},{"location":"changelog/#whats-new-in-1174","text":"\ud83d\ude80New Support for Kibana/Elasticsearch 6.7.0 \ud83e\uddd0Enhancement (PRO/Enterprise) JWT query param is the preferred credentials provider \ud83e\uddd0Enhancement (PRO/Enterprise) admin users can use indices management \ud83e\uddd0Enhancement (PRO/Enterprise) ro users can dismiss telemetry form \ud83d\udc1eFix Audit logging in 5.1.x now works again \ud83d\udc1eFix unpredictable behaviour of \"filter\" and \"fields\" when using external auth \ud83d\udc1eFix LDAP ConcurrentModificationException \ud83d\udc1eFix Audit logging in 5.1.x now works again \ud83d\udc1eFix (PRO/Enterprise) JWT deep-link works again","title":"What's new in 1.17.4"},{"location":"changelog/#whats-new-in-1173","text":"1.17.2 went unreleased, all changes have been merged in 1.17.3 directly \ud83d\udc1eFix (Enterprise) Tenancy selector showing if user belonged to one group \ud83d\udc1eFix (PRO/Enterprise) RW buttons not hiding for RO users in React Kibana apps \ud83d\udc1eFix (Enterprise) Tenancy templating now works much more reliably \ud83d\udc1eFix (Enterprise) Missing tenancy selector icon after switching tenancy \ud83d\udc1eFix (PRO/Enterprise) barring static files requests caused sudden logout \ud83d\udc1eFix Numerous fixes to better support Kibana 6.6.x \ud83d\udc1eFix Critical fixes in new Scala core \ud83d\udc1eFix Exception in reindex requests caused tenancy templating to fail \ud83e\uddd0Enhancement Bypass cross-cluster search logic if single cluster","title":"What's new in 1.17.3"},{"location":"changelog/#whats-new-in-1171","text":"\ud83d\udc1eFix (PRO/Enterprise) SAML now works well in 6.6.x \ud83d\udc1eFix (PRO/Enterprise) \"undefined\" authentication error before login \ud83d\udc1eFix (Enterprise) Default space creation failures for new tenants \ud83d\udc1eFix (Enterprise) Icons/titles CSS misalignment in sidebar (Firefox) \ud83e\uddd0Enhancement (Enterprise) UX: Larger tenancy selector \ud83d\udc1eSecurity Fix (Enterprise) Privilege escalation when changing tenancies under monitoring \ud83d\udc1eFix (Elasticsearch) compatibility fixes to support new Kibana features \ud83e\uddd0Enhancements (Elasticsearch) New core and LDAP connector written in Scala is finished, now under QA.","title":"What's new in 1.17.1"},{"location":"changelog/#whats-new-in-1170","text":"\ud83d\ude80New Feature Support for Kibana/Elasticsearch 6.6.0, 6.6.1 \ud83d\ude80New Feature Internode SSL (ES 6.3.x onwards) \ud83e\uddd0Enhancement (PRO/Enterprise) UI appearence \ud83e\uddd0Enhancement Made HTTP Connection configurable (PR #410) \ud83d\udc1eFix slow boot due to SecureRandom waiting for sufficient entropy \ud83d\udc1eFix Enable kibana_access:ro to create short urls in es6.3+ (PR #408)","title":"What's new in 1.17.0"},{"location":"changelog/#whats-new-in-11634","text":"\ud83e\uddd0Enhancement X-Forwarded-For header in printed es logs (\"XFF\") \ud83e\uddd0Enhancement kibana_index: \".kibana_@{user}\" when user is \"John Doe\" becomes .kibana_john_doe \ud83d\udc1eFix (Enteprise) parse SAML groups from assertion as array of strings \ud83d\udc1eFix (Enteprise) SAMLRequest in location header was URLEncoded twice, broke on some IdP \ud83d\udc1eFix (PRO/Enteprise) \"cookiePass\" works again, no more need for sticky cookies in load balancers! \ud83d\udc1eFix (PRO/Enteprise) fix redirect loop with JWT deep linking when JWT token expires \ud83e\uddd0Enhancement (PRO/Enteprise) fix audit demo page CSS \ud83e\uddd0Enhancement (Enteprise) SAML more configuration parameters available \ud83d\ude80New Feature (PRO/Enteprise) set ROR to debug mode (readonlyrest_kbn.logLevel: \"debug\")","title":"What's new in 1.16.34"},{"location":"changelog/#whats-new-in-11633","text":"\ud83d\udc1eFix (PRO/Enteprise) compatibility problems with older Kibana versions \ud83d\udc1eFix (PRO/Enteprise) compatibility problems with OSS Kibana version","title":"What's new in 1.16.33"},{"location":"changelog/#whats-new-in-11632","text":"\ud83d\ude80New Feature \"kibanaIndexTemplate\": default dashboards and spaces for new tenants \ud83e\uddd0Enhancement Support for ES/Kibana 6.5.4 \ud83e\uddd0Enhancement Upgraded LDAP library \ud83e\uddd0Enhancement (Enterprise) Now tenants save their CSV exports in their own reporting index \ud83d\udc1eFix (PRO/Enteprise) Support passwords that start and/or end with spaces \ud83d\udc1eFix (PRO/Enterprise) Now reporting works again","title":"What's new in 1.16.32"},{"location":"changelog/#whats-new-in-11631","text":"\ud83e\uddd0Enhancement Support for ES/Kibana 6.5.2, 6.5.3 \ud83d\udea7WIP : Laid out the foundation for LDAP HA support","title":"What's new in 1.16.31"},{"location":"changelog/#whats-new-in-11629","text":"\ud83e\uddd0Enhancement Support for ES/Kibana 6.4.3 \ud83d\ude80New Feature (PRO/Enterprise) configurable server side session duration \ud83d\ude80New Feature [LDAP] High Availability: Round Robin or Failover","title":"What's new in 1.16.29"},{"location":"changelog/#whats-new-in-11628","text":"\ud83e\uddd0Enhancement Support for ES/Kibana 6.4.2 \ud83d\udc1eFix (Enterprise) Multi tenancy: sometimes changing tenancy would not change kibana index \ud83d\udc1eSecurity Fix (Enterprise/PRO) Avoid echoing Base64 encoded credentials in login form error message \ud83e\uddd0Enhancement (Enterprise/PRO) Remove latest search/visualization/dashboard history on logout \ud83e\uddd0Enhancement (Enterprise/PRO) Clear transient authentication cookies on login error to avoid authentication deadlocks \ud83d\udc1eFix : External JWT verification may throw ArrayOutOfBoundException \ud83d\udea7WIP : Laid out the foundation for internode SSL transport (port 9300)","title":"What's new in 1.16.28"},{"location":"changelog/#whats-new-in-11627","text":"\ud83d\ude80New Feature [JWT] external validator: it's now possible to avoid storing the private key in settings \ud83e\uddd0Enhancement Support for ES/Kibana 6.4.1 \ud83e\uddd0Enhancement Rewritten big part of ES plugin documentation \ud83e\uddd0Enhancement SAML Single log out flow \ud83d\udc1eFix (Enterprise/PRO) cookiePass works again, but only for Kibana 5.x. Newer Kibana needs sticky sessions in LB. \ud83e\uddd0Enhancement (Enterprise/PRO) much faster logout","title":"What's new in 1.16.27"},{"location":"changelog/#whats-new-in-11626","text":"\ud83d\udc1e Fix (PRO/Enterprise) bugs during plugin packaging and installation process","title":"What's new in 1.16.26"},{"location":"changelog/#whats-new-in-11625","text":"\ud83d\ude80New Feature Users rule: easily restrict external authentication to a list of users \ud83e\uddd0Enhancement Support for ES 5.6.11 \ud83d\udc1eHot Fix (Enterprise/PRO) Error 404 when logging in with older versions of Kibana","title":"What's new in 1.16.25"},{"location":"changelog/#whats-new-in-11624","text":"\ud83d\ude80New Feature (Enterprise) SAML Authentication \ud83d\ude80New Feature Support for Elasticsearch and Kibana 6.4.0 \ud83d\ude80New Feature Headers rule now split in headers_or and headers_and \ud83e\uddd0Enhancement Headers rule now allows wildcards \ud83d\ude80New Feature (Enterprise) Multi-tenancy now works also with JSON groups provider \ud83d\udc1e Fix Multi-tenancy (Enterprise) incoherent initial kibana_index and current group","title":"What's new in 1.16.24"},{"location":"changelog/#whats-new-in-11623","text":"\ud83e\uddd0Enhancement Support for Elastic Stack 6.3.1 and 5.6.10 \ud83d\ude80New Feature (Enterprise) Custom CSS injection for Kibana \ud83d\ude80New Feature (Enterprise) Custom Javascript injection for Kibana \ud83d\ude80New Feature (PRO/Enterprise) access paths without need to login (i.e. /api/status) \ud83d\udc1eFix (PRO/Enterprise) Navigating to X-Pack APM caused hidden Kibana apps to reappear","title":"What's new in 1.16.23"},{"location":"changelog/#whats-new-in-11622","text":"\ud83d\ude80New Feature: map LDAP groups to local groups (a.k.a. role mapping) \ud83d\udc1e Fix (Elasticsearch) wildcard aliases resolution not working in \"indices\" rule. \ud83e\uddd0Enhancement: it is now possible now to use JDK 9 and 10 \ud83d\udc1e Fix (PRO/Enterprise) wait forever for login request (i.e. slow LDAP servers) \ud83d\udc1e Fix (PRO/Enterprise) add spinner and block UI if login request is being sent \ud83d\udc1e Fix (PRO/Enterprise) if user is logged out because of LDAP cache expiring + slow authentication, redirect to login. \ud83d\udc1e Fix (PRO/Enterprise) let RO users delete/edit search filters","title":"What's new in 1.16.22"},{"location":"changelog/#whats-new-in-11621","text":"\ud83d\ude80New Feature: Introducing support for Elasticsearch and Kibana v6.3.0 \ud83d\udc1e Fix (Enterprise) multi tenancy - switching tenancy does not always switch kibana index","title":"What's new in 1.16.21"},{"location":"changelog/#whats-new-in-11620","text":"","title":"What's new in 1.16.20"},{"location":"changelog/#readonlyrest-proenterprise-for-kibana","text":"\ud83e\uddd0 Enhancement : when login, forward \"elasticsearch.requestHeadersWhitelist\" headers. (useful for \"headers\" rule and \"proxy_auth\" to work well.)","title":"ReadonlyREST PRO/Enterprise for Kibana"},{"location":"changelog/#readonlyrest-for-elasticsearch","text":"\ud83d\ude80New Feature : DLS (with dynamic variables suppoort) Thanks DataSweet ! \ud83d\ude80 New feature : Field level security \ud83d\ude80 New rules : Snapshot, Repositories, Headers \ud83e\uddd0 Enhancement : custom audit serializers: the request content is available \ud83d\udc1e Fix readonlyrest.yml path discovery \ud83d\udc1e Fix: LDAP available groups discovery (tenancy switcher) corner cases \ud83d\udc1e Fix : auth_key_sha1, auth_key_sha256 hashes in settings should be case insensitive \ud83d\udc1e Fix : LDAP authentication didn't work with local group","title":"ReadonlyREST for Elasticsearch"},{"location":"commercial/","text":"Commercial Licenses ReadonlyREST PRO and ReadonlyREST Enterprise are commercial subscriptions. They both include the license to use a Kibana plugin that can operate exclusively in synergy with our ReadonlyREST Elasticsearch plugin. The Kibana plugin included in the Enterprise offer has more functionality than the one included in the PRO subscription. See readonlyrest.com for the detailed differences. The ReadonlyREST Elasticsearh plugin is released as open source under the GPLv3 license. However, It is possible to request a quote for obtaining a commercial license that enables you to integrate ReadonlyREST for Elasticsearch and/or for Kibana inside your commercial product. What is Priority Support? Priority support is an email based, private support service with the creators of ReadonlyREST, and it covers two (2) incidents per quarter. Email support@readonlyrest.com . We guarantee a max response time of 2 working days (usually less). Please remember that the scope of priority support is limited to the resolution of ReadonlyREST issues, not Elasticsearch or Kibana issues, not your application or infrastructure issues. Any further engagement beyond the above terms requires to either: go through the public forum (outside of SLA terms) be purchased as consultancy days ($700 USD / day) the subscriber to buy a secondary Enterprise subscription for that year, so to double their quarterly priority support slots. Am I eligible of Priority support? Non paying users, must rely only on community support alone. ReadonlyREST PRO comes with 30 days \"onboarding\" dedicated support (on the whole ReadonlyREST stack). ReadonlyREST Enterprise comes with 30 days \"onboarding\" dedicated support (on both plugins) AND one year of priority support via email or forum private messages. In case you have a specific agreement with Beshu Limited (the company behind ReadonlyREST) for a commercial license that allows you to redistribute ReadonlyREST commercially, the priority SLA support does not cover your commercial customers directly. We will accept support requests from you and your staff only, and within the limits stated in the end user license agreement. Join the support forum For enabling priority support: Register immediately to the support forum . Register using the exact email (or same distinctive domain) used in the license registration Ask to be added to the PRO or Enterprise group. When opening the account, make sure you are using the same domain as the original license email or explain your connection to the licensed company. After that, when you actually need support, open a support topic . Don't forget to: Search for similar issues first! Often someone else already reported your issue. Start the topic title with [URGENT] , [HIGH] or [NORMAL] severity followed by a description of the issue. State whether you are a PRO or Enterprise customer State clearly the problem: the input, the desired output and the erroneous output Collect the logs and the configuration to reproduce the bug before opening the support topic. How severe is my issue? URGENT : Production is down, your business has stopped, we need to drop everything now and help you. HIGH : Production is wounded, but still functioning. You aren't sure if it's fatal, we will send help as quickly as possible. NORMAL : Production seems fine, but you have questions (this is usually the default). Is there a trial version? We publish also a \"Free\" simplified version of our Kibana plugin, but we also offer a 30 day trial of the full PRO and Enterprise editions. After 30 days, you will need to either uninstall the plugin, or purchase a license (the software will automatically stop working otherwise). Can I get a discount? You can a discount buying multiple licenses, or signing a contract for 2 or more years in advance (with advance payment). Licensing Every organization running ReadonlyREST PRO or Enterprise must have a license. There's no limit to the number of cluster nodes for each cluster. Any license you buy allows you to use our software only within the scope of your organization . Please read your end user license agreement (EULA) for any clarification. When a subscription lapses Legally, you must have an active subscription to keep ReadonlyREST PRO or Enterprise running. After a one week grace period, the software will refuse to work and you will not be eligible of priority support. Moreover, you won't have access to any more security updates or new features. Can I upgrade to Enterprise? Sure, just ask for a discount coupon before deleting your previous subscription. So you'll only be charged the difference when purchasing an Enterprise license. Please don't forget to mention that you are an existing PRO subscriber. Can I distribute it to my customers? The short answer is YES, but only as long as you have one valid, active Embedded subscription ongoing. You need to make sure your subscription remains active for as long as your product/solution containing ReadonlyREST is being offered for sale. The reason you cannot distribute ReadonlyREST as a Free user or a PRO subscriber is that the ElasticSearch plugin is released under the GPLv3 license; and the only legal way you could bundle it into a commercial product/solution is by also releaseing all your software under a GPL compatible license. We recognise this is rarely possible, that's why we agree to release the ElasticSearch plugin and the Kibana plugin under a commercial license that permits you to redistribute them. For more legal information, please contact us filing an inquiry for ReadonlyREST embed . Can you transfer a license? Licenses are not transferrable to another company. We will transfer the license from a user-specific email to a group email address (e.g. john_smith@acme.com -> tech@acme.com) but only for the same domain . It is strongly recommended that you buy the license using a group email address so the license is not attached to any one employee's email address. Obligations as a subscriber Your purchase gets you access to downloading the PRO and/or Enterprise software. The license agreement requires you to keep this access private. If we find your access credentials are ever publicized: We'll send you a warning email with details. You need to remove the content and change the password. If your access is publicized a second time, we reserve the right to permanently remove access (but won't unless it's really egregious - sloppy contractors happen). Can I get a refund? Yes, up to two weeks after purchase. Let us know the reason and maybe we can help but either way it's not a problem. Email finance@readonlyrest.com . What about payment methods? For new subscriptions or renewals we offer a simplified method where you just receive an invoice, and you pay via credit card or wire transfer, or the full procurement process (quote, purchase order, invoice) at your discretion. For any questions: email finance@readonlyrest.com .","title":"Commercial Licenses"},{"location":"commercial/#commercial-licenses","text":"ReadonlyREST PRO and ReadonlyREST Enterprise are commercial subscriptions. They both include the license to use a Kibana plugin that can operate exclusively in synergy with our ReadonlyREST Elasticsearch plugin. The Kibana plugin included in the Enterprise offer has more functionality than the one included in the PRO subscription. See readonlyrest.com for the detailed differences. The ReadonlyREST Elasticsearh plugin is released as open source under the GPLv3 license. However, It is possible to request a quote for obtaining a commercial license that enables you to integrate ReadonlyREST for Elasticsearch and/or for Kibana inside your commercial product.","title":"Commercial Licenses"},{"location":"commercial/#what-is-priority-support","text":"Priority support is an email based, private support service with the creators of ReadonlyREST, and it covers two (2) incidents per quarter. Email support@readonlyrest.com . We guarantee a max response time of 2 working days (usually less). Please remember that the scope of priority support is limited to the resolution of ReadonlyREST issues, not Elasticsearch or Kibana issues, not your application or infrastructure issues. Any further engagement beyond the above terms requires to either: go through the public forum (outside of SLA terms) be purchased as consultancy days ($700 USD / day) the subscriber to buy a secondary Enterprise subscription for that year, so to double their quarterly priority support slots.","title":"What is Priority Support?"},{"location":"commercial/#am-i-eligible-of-priority-support","text":"Non paying users, must rely only on community support alone. ReadonlyREST PRO comes with 30 days \"onboarding\" dedicated support (on the whole ReadonlyREST stack). ReadonlyREST Enterprise comes with 30 days \"onboarding\" dedicated support (on both plugins) AND one year of priority support via email or forum private messages. In case you have a specific agreement with Beshu Limited (the company behind ReadonlyREST) for a commercial license that allows you to redistribute ReadonlyREST commercially, the priority SLA support does not cover your commercial customers directly. We will accept support requests from you and your staff only, and within the limits stated in the end user license agreement.","title":"Am I eligible of Priority support?"},{"location":"commercial/#join-the-support-forum","text":"For enabling priority support: Register immediately to the support forum . Register using the exact email (or same distinctive domain) used in the license registration Ask to be added to the PRO or Enterprise group. When opening the account, make sure you are using the same domain as the original license email or explain your connection to the licensed company. After that, when you actually need support, open a support topic . Don't forget to: Search for similar issues first! Often someone else already reported your issue. Start the topic title with [URGENT] , [HIGH] or [NORMAL] severity followed by a description of the issue. State whether you are a PRO or Enterprise customer State clearly the problem: the input, the desired output and the erroneous output Collect the logs and the configuration to reproduce the bug before opening the support topic.","title":"Join the support forum"},{"location":"commercial/#how-severe-is-my-issue","text":"URGENT : Production is down, your business has stopped, we need to drop everything now and help you. HIGH : Production is wounded, but still functioning. You aren't sure if it's fatal, we will send help as quickly as possible. NORMAL : Production seems fine, but you have questions (this is usually the default).","title":"How severe is my issue?"},{"location":"commercial/#is-there-a-trial-version","text":"We publish also a \"Free\" simplified version of our Kibana plugin, but we also offer a 30 day trial of the full PRO and Enterprise editions. After 30 days, you will need to either uninstall the plugin, or purchase a license (the software will automatically stop working otherwise).","title":"Is there a trial version?"},{"location":"commercial/#can-i-get-a-discount","text":"You can a discount buying multiple licenses, or signing a contract for 2 or more years in advance (with advance payment).","title":"Can I get a discount?"},{"location":"commercial/#licensing","text":"Every organization running ReadonlyREST PRO or Enterprise must have a license. There's no limit to the number of cluster nodes for each cluster. Any license you buy allows you to use our software only within the scope of your organization . Please read your end user license agreement (EULA) for any clarification.","title":"Licensing"},{"location":"commercial/#when-a-subscription-lapses","text":"Legally, you must have an active subscription to keep ReadonlyREST PRO or Enterprise running. After a one week grace period, the software will refuse to work and you will not be eligible of priority support. Moreover, you won't have access to any more security updates or new features.","title":"When a subscription lapses"},{"location":"commercial/#can-i-upgrade-to-enterprise","text":"Sure, just ask for a discount coupon before deleting your previous subscription. So you'll only be charged the difference when purchasing an Enterprise license. Please don't forget to mention that you are an existing PRO subscriber.","title":"Can I upgrade to Enterprise?"},{"location":"commercial/#can-i-distribute-it-to-my-customers","text":"The short answer is YES, but only as long as you have one valid, active Embedded subscription ongoing. You need to make sure your subscription remains active for as long as your product/solution containing ReadonlyREST is being offered for sale. The reason you cannot distribute ReadonlyREST as a Free user or a PRO subscriber is that the ElasticSearch plugin is released under the GPLv3 license; and the only legal way you could bundle it into a commercial product/solution is by also releaseing all your software under a GPL compatible license. We recognise this is rarely possible, that's why we agree to release the ElasticSearch plugin and the Kibana plugin under a commercial license that permits you to redistribute them. For more legal information, please contact us filing an inquiry for ReadonlyREST embed .","title":"Can I distribute it to my customers?"},{"location":"commercial/#can-you-transfer-a-license","text":"Licenses are not transferrable to another company. We will transfer the license from a user-specific email to a group email address (e.g. john_smith@acme.com -> tech@acme.com) but only for the same domain . It is strongly recommended that you buy the license using a group email address so the license is not attached to any one employee's email address.","title":"Can you transfer a license?"},{"location":"commercial/#obligations-as-a-subscriber","text":"Your purchase gets you access to downloading the PRO and/or Enterprise software. The license agreement requires you to keep this access private. If we find your access credentials are ever publicized: We'll send you a warning email with details. You need to remove the content and change the password. If your access is publicized a second time, we reserve the right to permanently remove access (but won't unless it's really egregious - sloppy contractors happen).","title":"Obligations as a subscriber"},{"location":"commercial/#can-i-get-a-refund","text":"Yes, up to two weeks after purchase. Let us know the reason and maybe we can help but either way it's not a problem. Email finance@readonlyrest.com .","title":"Can I get a refund?"},{"location":"commercial/#what-about-payment-methods","text":"For new subscriptions or renewals we offer a simplified method where you just receive an invoice, and you pay via credit card or wire transfer, or the full procurement process (quote, purchase order, invoice) at your discretion. For any questions: email finance@readonlyrest.com .","title":"What about payment methods?"},{"location":"contributing/","text":"Contribution License Agreement Thank you for your interest in ReadonlyREST documentation (\u201cProduct\u201d), managed by Beshu Limited, a company duly established under the laws of United Kingdom, with registration number No. 10888034, and registered address at Office 32 13-21 Crawford Street, WH1 1PG, the owner the product (\u201cWe\u201d or \u201cUs\u201d). We appreciate all the Contributions, made to our Product. The purpose of this Contribution License Agreement (\u201cCLA\u201d, or \u201cAgreement\u201d) is to clarify the intellectual property rights granted with the Contribution to the Product from any person or entity. This CLA serves as a protection for a Contributor, as well as the protection of Us, our Product and its users. This Agreement does not change your right to use your Contribution for the other purposes. By submitting the present Contribution to Us, you acknowledge that you have read this Contribution License Agreement (a copy of which you can download) and that you will abide and comply to the requirements of the Agreement. 1. Definitions \u201cYou\u201d means an individual, who is a copyright owner of the Contribution, or a legal entity, which is authorized by a copyright owner to make a Contribution to the Product. \u201cContribution\u201d means any original work of authorship, including any modifications or additions to the existing work, in which You own or assert ownership of the Copyright, that is intentionally Submitted by You to Us for inclusion in the Product. \u201cSubmit\u201d means any form of electronic, verbal, or written communication sent to Us, including but not limited to electronic mailing lists, source code control systems, and issue tracking systems that are managed by Us, for the purpose of discussing and improving of our Product, but excluding communications that are conspicuously marked or otherwise designated in writing by You as \u201cNot a Contribution\u201d. \u201cProduct\u201d means OSS ReadonlyREST Plugin for Elasticsearch (specified on the following web-site: http://readonlyrest.com/download.html ), which is managed by BeShu Tech, which owns the Product. 2. Grant of Copyright License By signing this Agreement, being a subject to the terms and conditions of it, You hereby grant to Us a perpetual, worldwide, non-exclusive, no-charge, royalty-free, transferable, irrevocable copyright license with the right to sublicense such rights through multiple number of sublicensees, to reproduce, prepare derivative works, modify, publicly display, publicly perform and distribute Your Contributions as a part of the Product. 3. Grant of Patent License By signing this Agreement, You hereby grant to Us a perpetual, worldwide, non-exclusive, no-charge, royalty-free, transferable, irrevocable patent license with the right to sublicense these rights to multiple number of sublicensees, to make, have made, use, offer to sell, sell, import or otherwise transfer the Product, where such license applies only to those claims licensable by You that are necessarily infringed by your Contribution alone or by combination of your Contribution with the Product to which such Contribution was Submitted. 4. Our rights We are not obliged to use Your Contribution as a part of the Product and We reserve the right to decide whether the Contribution is appropriate and can be included to the Product. If We include the Contribution to the Product We may license the Contribution under any licensing terms, including without limitation: (a) open source licenses like the GPLv3 license; and (b) binary, proprietary, or commercial licenses. Except for the licenses granted herein, You reserve all right, title, and interest in and to the Contribution. including copyleft, permissive, commercial, or proprietary licenses. 5. Moral Rights To the extent permitted by law, the You hereby irrevocably and unconditionally waive any and all moral rights conferred by Chapter IV of the UK Copyright Designs and Patents Act 1988 or any rights of a similar nature under laws now or in the future in force in any jurisdiction in and to any and all Contributions to Our Product, submitted by You and agree not to assert such moral rights against Us or any of our licensee, either direct or indirect. 6. Your Representations By signing this Agreement, You represent and confirm that: You have a legal authority to enter into this Agreement and You are legally entitled to grant the above license; The Contribution is Your original creation and You own a copyright and patent claims covering the Contribution which are required to grant the rights under the sections 2 and 3 of this Agreement; Should You wish to Submit materials that are not Your original creation, You may Submit them separately to the Product if You (a) retain all copyright and license information that was in the materials as you received them, (b) in the description accompanying your Submission, include the phrase \"Submission containing materials of a third party:\" followed by the names of the third party and any licenses or other restrictions of which You are aware; The rights You grant under the Sections 2 and 3 of this Agreement does not violate any grant of rights, which You have made to the third parties; If You are an employee, You have received permission to make such Contribution on behalf of the employer; If You are less, then eighteen years old, please have Your parents or guardian sign this Agreement. In addition, You agree to notify Us of any fact or circumstances of which you become aware that would make these representations inaccurate in any respect. 7. Disclaimer EXCEPT FOR THE EXPRESS WARRANTIES IN THE SECTION 6, THE CONTRIBUTION IS PROVIDED ON \u201cAS IS\u201d BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND EITHER EXPRESS OR IMPLIED, INCLUDING WITHOUT LIMITATION, ANY WARRANTIES OR CONDITIONS OF THE TITLE, NON-INFRINGEMENT, MERCHANTABILITY, OR FITNESS FOR A PARTICULAR PURPOSE. 8. Other Provisions of the Agreement This Agreement shall be governed and construed in accordance with the laws of the United Kingdom. Unless you explicitly state otherwise, any Contribution shall be under the terms and conditions of this Agreement, without any additional terms or conditions. Notwithstanding the above, nothing herein shall supersede or modify the terms of any separate license agreement you may have executed with Us regarding such Contribution. This Agreement sets out the entire agreement between You and Us and overrides all other agreements or understandings. The relationship of the parties under this Agreement is that of independent contractors, and neither party will have the rights to act as the agent of the other party. If You or We assign the rights or obligations received through this Agreement to a third party, as a conditions of the assignment, that third party must agree in writing to abide by all the rights and obligations in the Agreement. If any provisions of this Agreement is found to be invalid or unenforceable, such provisions shall be severed from the Agreement and the remainder of this Agreement shall be interpreted so as to best reflects the original intent of the parties.","title":"Contribution License Agreement"},{"location":"contributing/#contribution-license-agreement","text":"Thank you for your interest in ReadonlyREST documentation (\u201cProduct\u201d), managed by Beshu Limited, a company duly established under the laws of United Kingdom, with registration number No. 10888034, and registered address at Office 32 13-21 Crawford Street, WH1 1PG, the owner the product (\u201cWe\u201d or \u201cUs\u201d). We appreciate all the Contributions, made to our Product. The purpose of this Contribution License Agreement (\u201cCLA\u201d, or \u201cAgreement\u201d) is to clarify the intellectual property rights granted with the Contribution to the Product from any person or entity. This CLA serves as a protection for a Contributor, as well as the protection of Us, our Product and its users. This Agreement does not change your right to use your Contribution for the other purposes. By submitting the present Contribution to Us, you acknowledge that you have read this Contribution License Agreement (a copy of which you can download) and that you will abide and comply to the requirements of the Agreement.","title":"Contribution License Agreement"},{"location":"contributing/#1-definitions","text":"\u201cYou\u201d means an individual, who is a copyright owner of the Contribution, or a legal entity, which is authorized by a copyright owner to make a Contribution to the Product. \u201cContribution\u201d means any original work of authorship, including any modifications or additions to the existing work, in which You own or assert ownership of the Copyright, that is intentionally Submitted by You to Us for inclusion in the Product. \u201cSubmit\u201d means any form of electronic, verbal, or written communication sent to Us, including but not limited to electronic mailing lists, source code control systems, and issue tracking systems that are managed by Us, for the purpose of discussing and improving of our Product, but excluding communications that are conspicuously marked or otherwise designated in writing by You as \u201cNot a Contribution\u201d. \u201cProduct\u201d means OSS ReadonlyREST Plugin for Elasticsearch (specified on the following web-site: http://readonlyrest.com/download.html ), which is managed by BeShu Tech, which owns the Product.","title":"1. Definitions"},{"location":"contributing/#2-grant-of-copyright-license","text":"By signing this Agreement, being a subject to the terms and conditions of it, You hereby grant to Us a perpetual, worldwide, non-exclusive, no-charge, royalty-free, transferable, irrevocable copyright license with the right to sublicense such rights through multiple number of sublicensees, to reproduce, prepare derivative works, modify, publicly display, publicly perform and distribute Your Contributions as a part of the Product.","title":"2. Grant of Copyright License"},{"location":"contributing/#3-grant-of-patent-license","text":"By signing this Agreement, You hereby grant to Us a perpetual, worldwide, non-exclusive, no-charge, royalty-free, transferable, irrevocable patent license with the right to sublicense these rights to multiple number of sublicensees, to make, have made, use, offer to sell, sell, import or otherwise transfer the Product, where such license applies only to those claims licensable by You that are necessarily infringed by your Contribution alone or by combination of your Contribution with the Product to which such Contribution was Submitted.","title":"3. Grant of Patent License"},{"location":"contributing/#4-our-rights","text":"We are not obliged to use Your Contribution as a part of the Product and We reserve the right to decide whether the Contribution is appropriate and can be included to the Product. If We include the Contribution to the Product We may license the Contribution under any licensing terms, including without limitation: (a) open source licenses like the GPLv3 license; and (b) binary, proprietary, or commercial licenses. Except for the licenses granted herein, You reserve all right, title, and interest in and to the Contribution. including copyleft, permissive, commercial, or proprietary licenses.","title":"4. Our rights"},{"location":"contributing/#5-moral-rights","text":"To the extent permitted by law, the You hereby irrevocably and unconditionally waive any and all moral rights conferred by Chapter IV of the UK Copyright Designs and Patents Act 1988 or any rights of a similar nature under laws now or in the future in force in any jurisdiction in and to any and all Contributions to Our Product, submitted by You and agree not to assert such moral rights against Us or any of our licensee, either direct or indirect.","title":"5. Moral Rights"},{"location":"contributing/#6-your-representations","text":"By signing this Agreement, You represent and confirm that: You have a legal authority to enter into this Agreement and You are legally entitled to grant the above license; The Contribution is Your original creation and You own a copyright and patent claims covering the Contribution which are required to grant the rights under the sections 2 and 3 of this Agreement; Should You wish to Submit materials that are not Your original creation, You may Submit them separately to the Product if You (a) retain all copyright and license information that was in the materials as you received them, (b) in the description accompanying your Submission, include the phrase \"Submission containing materials of a third party:\" followed by the names of the third party and any licenses or other restrictions of which You are aware; The rights You grant under the Sections 2 and 3 of this Agreement does not violate any grant of rights, which You have made to the third parties; If You are an employee, You have received permission to make such Contribution on behalf of the employer; If You are less, then eighteen years old, please have Your parents or guardian sign this Agreement. In addition, You agree to notify Us of any fact or circumstances of which you become aware that would make these representations inaccurate in any respect.","title":"6. Your Representations"},{"location":"contributing/#7-disclaimer","text":"EXCEPT FOR THE EXPRESS WARRANTIES IN THE SECTION 6, THE CONTRIBUTION IS PROVIDED ON \u201cAS IS\u201d BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND EITHER EXPRESS OR IMPLIED, INCLUDING WITHOUT LIMITATION, ANY WARRANTIES OR CONDITIONS OF THE TITLE, NON-INFRINGEMENT, MERCHANTABILITY, OR FITNESS FOR A PARTICULAR PURPOSE.","title":"7. Disclaimer"},{"location":"contributing/#8-other-provisions-of-the-agreement","text":"This Agreement shall be governed and construed in accordance with the laws of the United Kingdom. Unless you explicitly state otherwise, any Contribution shall be under the terms and conditions of this Agreement, without any additional terms or conditions. Notwithstanding the above, nothing herein shall supersede or modify the terms of any separate license agreement you may have executed with Us regarding such Contribution. This Agreement sets out the entire agreement between You and Us and overrides all other agreements or understandings. The relationship of the parties under this Agreement is that of independent contractors, and neither party will have the rights to act as the agent of the other party. If You or We assign the rights or obligations received through this Agreement to a third party, as a conditions of the assignment, that third party must agree in writing to abide by all the rights and obligations in the Agreement. If any provisions of this Agreement is found to be invalid or unenforceable, such provisions shall be severed from the Agreement and the remainder of this Agreement shall be interpreted so as to best reflects the original intent of the parties.","title":"8. Other Provisions of the Agreement"},{"location":"elasticsearch/","text":"For Elasticsearch Overview: The ReadonlyREST Suite ReadonlyREST is a light weight Elasticsearch plugin that adds encryption, authentication, authorization and access control capabilities to Elasticsearch embedded REST API. The core of this plugin is an ACL engine that checks each incoming request through a sequence of rules a bit like a firewall. There are a dozen rules that can be grouped in sequences of blocks and form a powerful representation of a logic chain. The Elasticsearch plugin known as ReadonlyREST Free is released under the GPLv3 license, or alternatively, a commercial license (see ReadonlyREST Embedded ) and lays the technological foundations for the companion Kibana plugin which is released in two versions: ReadonlyREST PRO and ReadonlyREST Enterprise . Unlike the Elasticsearch plugin, the Kibana plugins are commercial only. But rely on the Elasticsearch plugin in order to work. For a description of the Kibana plugins, skip to the dedicated documentation page instead. ReadonlyREST Free plugin for Elasticsearch In this document we are going to describe how to operate the Elasticsearch plugin in all its features. Once installed, this plugin will greatly extend the Elasticsearch HTTP API (port 9200), adding numerous extra capabilities: Encryption : transform the Elasticsearch API from HTTP to HTTPS Authentication : require credentials Authorization : declare groups of users, permissions and partial access to indices. Access control : complex logic can be modeled using an ACL (access control list) written in YAML. Audit logs : a trace of the access requests can be logged to file or index (or both). Flow of a Search Request The following diagram models an instance of Elasticsearch with the ReadonlyREST plugin installed, and configured with SSL encryption and an ACL with at least one \"allow\" type ACL block. The User Agent (i.e. cURL, Kibana) sends a search request to Elasticsearch using the port 9200 and the HTTPS URL schema. The HTTPS filter in ReadonlyREST plugin unwraps the SSL layer and hands over the request to Elasticsearch HTTP stack The HTTP stack in Elasticsearch parses the HTTP request The HTTP handler in Elasticsearch extracts the indices, action, request type and creates a SearchRequest (internal Elasticsearch format). The SearchRequest goes through the ACL (access control list), external systems like LDAP can be asynchronously queried, and an exit result is eventually produced. The exit result is used by the audit log serializer, to write a record to index and/or Elasticsearch log file If no ACL block was matched, or if a type: forbid block was matched, ReadonlyREST does not forward the search request to the search engine, and creates an \"unauthorized\" HTTP response. In case the ACL matched an type: allow block, the request is forwarded to the search engine The Elasticsearch code creates a search response containing the results of the query 10.The search response is converted to an HTTP response by the Elasticsearch code The HTTP response flows back to ReadonlyREST's HTTPS filter and to the User agent Installing the plugin To install ReadonlyREST plugin for Elasticsearch: 1. Obtain the build From the official download page . Select your Elasticsearch version and send yourself a link to the compatible ReadonlyREST zip file. 2. Install the build bin/elasticsearch-plugin install file:///tmp/readonlyrest-X.Y.Z_esW.Q.U.zip Notice how we need to type in the format file:// + absolute path (yes, with three slashes). @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ @ WARNING: plugin requires additional permissions @ @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ When prompted about additional permissions, answer y . 3. Patch Elasticsearch If you are using Elasticsearch 8.0.x or newer, you need an extra post-installation step . Depending on the Elasticsearch version , this command might tweak the main Elasticsearch installation files and/or copy some jars to plugins/readonlyrest directory. # Patch ES $ jdk/bin/java -jar plugins/readonlyrest/ror-tools.jar patch \u26a0\ufe0fIMPORTANT : for Elasticsearch 8.3.x or newer, the patching operation requires root user privileges. You can verify if Elasticsearch was correctly patched using command verify : $ jdk/bin/java -jar plugins/readonlyrest/ror-tools.jar verify Please note that the tool assumes that you run it from the root of your ES installation directory or the default installation directory is /usr/share/elasticsearch . But if you want or need, you can instruct it where your Elasticsearch is installed by executing one of tool's command with --es-path parameter: $ jdk/bin/java -jar plugins/readonlyrest/ror-tools.jar patch --es-path /my/custom/path/to/es/folder or $ jdk/bin/java -jar plugins/readonlyrest/ror-tools.jar verify --es-path /my/custom/path/to/es/folder NB: In case of any problems with the ror-tools , please call: $ jdk/bin/java -jar plugins/readonlyrest/ror-tools.jar --help 4.Create settings file Create and edit the readonlyrest.yml settings file in the same directory where elasticsearch.yml is found : vim $ES_PATH_CONF/conf/readonlyrest.yml Now write some basic settings, just to get started. In this example we are going to tell ReadonlyREST to require HTTP Basic Authentication for all the HTTP requests, and return 401 Unauthorized otherwise. readonlyrest: access_control_rules: - name: \"Require HTTP Basic Auth\" type: allow auth_key: user:password 5. Disable X-Pack security module (applies to ES 6.4.0 or greater) ReadonlyREST and X-Pack security module can't run together, so the latter needs to be disabled. Edit elasticsearch.yml and append xpack.security.enabled: false . vim $ES_PATH_CONF/conf/elasticsearch.yml 6. Start Elasticsearch bin/elasticsearch or: service start elasticsearch Depending on your environment. Now you should be able to see the logs and ReadonlyREST related lines like the one below: [2018-09-18T13:56:25,275][INFO ][o.e.p.PluginsService ] [c3RKGFJ] loaded plugin [readonlyrest] 7. Test everything is working The following command should succeed, and the response should show a status code 200. curl -vvv -u user:password \"http://localhost:9200/_cat/indices\" The following command should not succeed, and the response should show a status code 401 curl -vvv \"http://localhost:9200/_cat/indices\" Upgrading the plugin To upgrade ReadonlyREST for Elasticsearch: 1. Stop Elasticsearch. Either kill the process manually, or use: service stop elasticsearch depending on your environment. 2. Unpatch Elasticsearch If you are using Elasticsearch 8.0.x or newer, you need an extra pre-uninstallation step . This will remove all previously copied jars from ROR's installation directory. # Unpatch ES $ jdk/bin/java -jar plugins/readonlyrest/ror-tools.jar unpatch You can verify if Elasticsearch was correctly unpatched using command verify : $ jdk/bin/java -jar plugins/readonlyrest/ror-tools.jar verify NB: In case of any problems with the ror-tools , please call: $ jdk/bin/java -jar plugins/readonlyrest/ror-tools.jar --help 3. Uninstall ReadonlyREST bin/elasticsearch-plugin remove readonlyrest 4. Install the new version of ReadonlyREST into Elasticsearch. bin/elasticsearch-plugin install file://<download_dir>/readonlyrest-<ROR_VERSION>_es<ES_VERSION>.zip e.g. bin/elasticsearch-plugin install file:///tmp/readonlyrest-1.16.15_es6.1.1.zip 5. Patch Elasticsearch If you are using Elasticsearch 8.0.x or newer, you need an extra post-installation step . Depending on the Elasticsearch version , this command might tweak the main Elasticsearch installation files and/or copy some jars to plugins/readonlyrest directory. # Patch ES $ jdk/bin/java -jar plugins/readonlyrest/ror-tools.jar patch \u26a0\ufe0fIMPORTANT : for Elasticsearch 8.3.x or newer, the patching operation requires root user privileges. You can verify if Elasticsearch was correctly patched using command verify : $ jdk/bin/java -jar plugins/readonlyrest/ror-tools.jar verify NB: In case of any problems with the ror-tools , please call: $ jdk/bin/java -jar plugins/readonlyrest/ror-tools.jar --help 6. Restart Elasticsearch. bin/elasticsearch or: service start elasticsearch Depending on your environment. Now you should be able to see the logs and ReadonlyREST related lines like the one below: [2018-09-18T13:56:25,275][INFO ][o.e.p.PluginsService ] [c3RKGFJ] loaded plugin [readonlyrest] Removing the plugin 1. Stop Elasticsearch. Either kill the process manually, or use: service stop elasticsearch depending on your environment. 2. Unpatch Elasticsearch If you are using Elasticsearch 8.0.x or newer, you need an extra pre-uninstallation step . This will remove all previously copied jars from ROR's installation directory. # Unpatch ES $ jdk/bin/java -jar plugins/readonlyrest/ror-tools.jar unpatch You can verify if Elasticsearch was correctly unpatched using command verify : $ jdk/bin/java -jar plugins/readonlyrest/ror-tools.jar verify NB: In case of any problems with the ror-tools , please call: $ jdk/bin/java -jar plugins/readonlyrest/ror-tools.jar --help 3. Uninstall ReadonlyREST from Elasticsearch: bin/elasticsearch-plugin remove readonlyrest 4. Start Elasticsearch. bin/elasticsearch or: service start elasticsearch Depending on your environment. Deploying ReadonlyREST in a stable production cluster Unless some advanced features are being used (see below),this Elasticsearch plugin operates like a lightweight, stateless filter glued in front of Elasticsearch HTTP API. Therefore it's sufficient to install the plugin only in the nodes that expose the HTTP interface (port 9200). Installing ReadonlyREST in a dedicated node has numerous advantages: No need to restart all nodes, only the one you have installed the plugin into. No need to restart all nodes for updating the security settings No need to restart all nodes when a security update is out Less complexity on the actual cluster nodes. For example, if we want to move to HTTPS all the traffic coming from Logstash into a 9 nodes Elasticsearch cluster which has been running stable in production for a while, it's not necessary to install ReadonlyREST plugin in all the nodes. Creating a dedicated, lightweight ES node where to install ReadonlyREST: (Optional) disable the HTTP interface from all the existing nodes Create a new, lightweight, dedicated node without shards, nor master eligibility. Configure ReadonlyREST with SSL encryption in the new node Configure Logstash to connect to the new node directly in HTTPS. An exception \u26a0\ufe0fIMPORTANT By default when fields rule is used, it's required to install ReadonlyREST plugin in all the data nodes. ACL basics The core of this plugin is an ACL (access control list). A logic structure very similar to the one found in firewalls. The ACL is part of the plugin configuration, and it's written in YAML. The ACL is composed of an ordered sequence of named blocks Each block contains some rules , and a policy (forbid or allow) HTTP requests run through the blocks, starting from the first, The first block that satisfies all the rules decides if to forbid or allow the request (according to its policy). If none of the block match, the request is rejected \u26a0\ufe0fIMPORTANT : The ACL blocks are evaluated sequentially , therefore the ordering of the ACL blocks is crucial . The order of the rules inside an ACL block instead, is irrelevant. readonlyrest: access_control_rules: - name: \"Block 1 - only Logstash indices are accessible\" type: allow # <-- default policy type is \"allow\", so this line could be omitted indices: [\"logstash-*\"] # <-- This is a rule - name: \"Block 2 - Blocking everything from a network\" type: forbid hosts: [\"10.0.0.0/24\"] # <-- this is a rule An Example of Access Control List (ACL) made of 2 blocks. The YAML snippet above, like all of this plugin's settings should be saved inside the readonlyrest.yml file. Create this file on the same path where elasticsearch.yml is found . TIP : If you are a subscriber of the PRO or Enterprise Kibana plugin, you can edit and refresh the settings through a GUI. For more on this, see the documentation for ReadonlyREST plugin for Kibana . Encryption An SSL encrypted connection is a prerequisite for secure exchange of credentials and data over the network. To make use of it you need to have certificate and private key. Letsencrypt certificates work just fine (see tutorial below). Both files, certificate and private key, have to be placed inside PKCS#12 or JKS keystore. See the tutorial at the end of this section. ReadonlyREST can be configured to encrypt network traffic on two independent levels: 1. HTTP (port 9200) 2. Internode communication - transport module (port 9300) An Elasticsearch node with ReadonlyREST can join an existing cluster based on native SSL from xpack.security module. This configuration is useful to deploy ReadonlyREST Enterprise for Kibana to an existing large production cluster without disrupting any configuration. More on this in the dedicated paragraph of this section. External REST API It wraps connection between client and exposed REST API in SSL context, hence making it encrypted and secure. \u26a0\ufe0fIMPORTANT: To enable SSL for REST API, open elasticsearch.yml and append this one line: http.type: ssl_netty4 Now in readonlyrest.yml add the following settings: readonlyrest: ssl: keystore_file: \"keystore.jks\" # or keystore.p12 for PKCS#12 format keystore_pass: readonlyrest key_pass: readonlyrest The keystore should be stored in the same directory with elasticsearch.yml and readonlyrest.yml . Internode communication - transport module This option encrypts communication between nodes forming Elasticsearch cluster. \u26a0\ufe0fIMPORTANT: To enable SSL for internode communication open elasticsearch.yml and append this one line: transport.type: ror_ssl_internode In readonlyrest.yml following settings must be added (it's just example configuration presenting most important properties): readonlyrest: ssl_internode: keystore_file: \"keystore.jks\" # or keystore.p12 for PKCS#12 format keystore_pass: readonlyrest key_pass: readonlyrest Similar to ssl for HTTP, the keystore should be stored in the same directory with elasticsearch.yml and readonlyrest.yml . This config must be added to all nodes taking part in encrypted communication within cluster. Internode communication with XPack nodes It is possible to set up internode SSL between ROR and XPack nodes. It works only for ES above 6.3. To set up cluster in such configuration you have to generate certificate for ROR node according to this description https://www.elastic.co/guide/en/elasticsearch/reference/current/security-basic-setup.html#generate-certificates. Generated elastic-certificates.p12 could be then used in ROR node with such configuration readonlyrest: ssl_internode: enable: true keystore_file: \"elastic-certificates.p12\" keystore_pass: [ password for generated certificate ] key_pass: [ password for generated certificate ] truststore_file: \"elastic-certificates.p12\" truststore_pass: [ password for generated certificate ] certificate_verification: true # certificate verification is enabled by default on XPack nodes Certificate verification By default certificate verification is disabled. It means that certificate is not validated in any way, so all certificates are accepted. It is useful on local/test environment, where security is not the most important concern. On production environment it is adviced to enable this option. It can be done by means of: certificate_verification: true under ssl_internode section. This option is applicable only for internode ssl. Client authentication By default the client authentication is disabled. When enabled, the server asks the client about its certificate, so ES is able to verify the client's identity. It can be enabled by means of: client_authentication: true under ssl section. This option is applicable only for REST API external ssl. Both certificate_verification and client_authentication can be enabled with single property verification . Using this property is deprecated and allowed because of backward compatibility support. Specialized properties make configuration more readable and explicit. Restrict SSL protocols and ciphers Optionally, it's possible to specify a list allowed SSL protocols and SSL ciphers. Connections from clients that don't support the listed protocols or ciphers will be dropped. readonlyrest: ssl: # put the keystore in the same dir with elasticsearch.yml keystore_file: \"keystore.jks\" keystore_pass: readonlyrest key_pass: readonlyrest allowed_protocols: [TLSv1.2] allowed_ciphers: [TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256] ReadonlyREST will log a list of available ciphers and protocols supported by the current JVM at startup. [2018-01-03T10:09:38,683][INFO ][t.b.r.e.SSLTransportNetty4] ROR SSL: Available ciphers: TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA,TLS_RSA_WITH_AES_128_GCM_SHA256,TLS_RSA_WITH_AES_128_CBC_SHA [2018-01-03T10:09:38,684][INFO ][t.b.r.e.SSLTransportNetty4] ROR SSL: Restricting to ciphers: TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256 [2018-01-03T10:09:38,684][INFO ][t.b.r.e.SSLTransportNetty4] ROR SSL: Available SSL protocols: TLSv1,TLSv1.1,TLSv1.2 [2018-01-03T10:09:38,685][INFO ][t.b.r.e.SSLTransportNetty4] ROR SSL: Restricting to SSL protocols: TLSv1.2 [2018-0 Custom truststore ReadonlyREST allows using custom truststore, replacing (provided by JRE) default one. Custom truststore can be set with: truststore_file: \"truststore.jks\" truststore_pass: truststorepass under ssl or ssl_internode section. This option is applicable for both ssl modes - external ssl and internode ssl. The truststore should be stored in the same directory with elasticsearch.yml and readonlyrest.yml (like keystore). When not specifed, ReadonlyREST uses default truststore. Using Let's encrypt We are going to show how to first add all the certificates and private key into PKCS#12 keystore, and then (optionally) converting it to JKS keystore. ReadonlyREST supports both formats. This tutorial can be a useful example on how to use certificates from other providers. 1. Create keys ./letsencrypt-auto certonly --standalone -d DOMAIN.TLD -d DOMAIN_2.TLD --email EMAIL@EMAIL.TLD Now change to the directory (probably /etc/letsencrypt/live/DOMAIN.tld) where the certificates were created. 2. Create a PKCS12 file with the full chain and private key openssl pkcs12 -export -in fullchain.pem -inkey privkey.pem -out pkcs.p12 -name NAME 3. Convert PKCS12 to JKS Keystore (Optional) The STORE_PASS is the password which was entered in step 2) as a password for the pkcs12 file. keytool -importkeystore -deststorepass PASSWORD_STORE -destkeypass PASSWORD_KEYPASS -destkeystore keystore.jks -srckeystore pkcs.p12 -srcstoretype PKCS12 -srcstorepass STORE_PASS -alias NAME If you happen to get a java.io.IOException: failed to decrypt safe contents entry: javax.crypto.BadPaddingException: Given final block not properly padded , you have probably forgotten to enter the correct password from step 2. (Credits for the original JKS tutorial to Maximilian Boehm ) Blocks of rules Every block must have at least the name field, and optionally a type field valued either \"allow\" or \"forbid\". If you omit the type , your block will be treated as type: allow by default. Keep in mind that ReadonlyREST ACL is a white list, so by default all request are blocked, unless you specify a block of rules that allowes all or some requests. name will appear in logs, so keep it short and distinctive. type can be either allow or forbid . Can be omitted, default is allow . - name: \"Block 1 - Allowing anything from localhost\" type: allow # In real life now you should increase the specificity by adding rules here (otherwise this block will allow all requests!) Example: the simplest example of an allow block. \u26a0\ufe0fIMPORTANT : if no blocks are configured, ReadonlyREST rejects all requests. Rules ReadonlyREST access control rules allow to take decisions on three levels: Network level HTTP level Elasticsearch level Please refrain from using HTTP level rules to protect certain indices or limit what people can do to an index. The level of control at this level is really coarse, especially because Elasticsearch REST API does not always respect RESTful principles. This makes of HTTP a bad abstraction level to write ACLs in Elasticsearch all together. The only clean and exhaustive way to implement access control is to reason about requests AFTER ElasticSearch has parsed them. Only then, the list of affected indices and the action will be known for sure. See Elasticsearch level rules. Transport level rules These are the most basic rules. It is possible to allow/forbid requests originating from a list of IP addresses, host names or IP networks (in slash notation). hosts hosts: [\"10.0.0.0/24\"] Match a request whose origin IP address (also called origin address, or OA in logs) matches one of the specified IP addresses or subnets. hosts_local hosts_local: [\"127.0.0.1\", \"127.0.0.2\"] Match a request whose destination IP address (called DA in logs) matches one of the specified IP addresses or subnets. This finds application when Elasticsearch HTTP API is bound to multiple IP addresses. HTTP Level rules accept_x-forwarded-for_header accept_x-forwarded-for_header: false \u26a0\ufe0fDEPRECATED (use x_forwarded_for instead ) A modifier for hosts rule: if the origin IP won't match, fallback to check the X-Forwarded-For header x_forwarded_for x_forwarded_for: [\"192.168.1.0/24\"] Behaves exactly like hosts , but gets the source IP address (a.k.a. origin address, OA in logs) inside the X-Forwarded-For header only (useful replacement to hosts rule when requests come through a load balancer like AWS ELB) Load balancers This is a nice tip if your Elasticsearch is behind a load balancer. If you want to match all the requests that come through the load balancer, use x_forwarded_for: [\"0.0.0.0/0\"] . This will match the requests with a valid IP address as a value of the X-Forwarded-For header. DNS lookup caching It's worth to note that resolutions of DNS are going to be cached by JVM. By default successfully resolved IPs will be cached forever (until Elasticsearch is restarted) for security reasons. However, this may not always be the desired behaviour, and it can be changed by adding the following JVM options either in the jvm.options file or declaring the ES_JAVA_OPTS environment variable: sun.net.inetaddr.ttl=TTL_VALUE (or/and sun.net.inetaddr.negative.ttl=TTL_VALUE ). More details about the problem can be found here . methods methods: [GET, DELETE] Match requests with HTTP methods specified in the list. N.B. Elasticsearch HTTP stack does not make any difference between HEAD and GET, so all the HEAD request will appear as GET. headers headers: [\"h1:x*y\",\"~h2:*xy\"] Match if all the HTTP headers in the request match the defined patterns in headers rule. This is useful in conjunction with proxy_auth , to carry authorization information (i.e. headers: x-usr-group: admins ). The ~ sign is a pattern negation, so eg. ~h2:*xy means: match if h2 header's value does not match the pattern *xy, or h2 is not present at all. headers_and headers_and: [\"hdr1:val_*xyz\",\"~hdr2:xyz_*\"] Alias for headers rule headers_or headers_or: [\"x-myheader:val*\",\"~header2:*xy\"] Match if at least one the specified HTTP headers key:value pairs is matched. uri_re uri_re: [\"^/secret-index/.*\", \"^/some-index/.*\"] \u2620\ufe0fHACKY (try to use indices/actions rule instead) Match if at least one specifed regular expression matches requested URI. maxBodyLength maxBodyLength: 0 Match requests having a request body length less or equal to an integer. Use 0 to match only requests without body. NB : Elasticsearch HTTP API breaks the specifications, nad GET requests might have a body length greater than zero. api_keys api_keys: [123456, abcdefg] A list of api keys expected in the header X-Api-Key Elasticsearch level rules indices indices: [\"sales\", \"logstash-*\"] Matches if the request involves a set of indices whose name is \"sales\", or starts with the string \"logstash-\", or a combination of both. If a request involves a wildcard (i.e. \"logstash-*\", \"*\"), this is first expanded to the list of available indices, and then treated normally as follows: Requests that do not involve any indices (cluster admin, etc) result in a \"match\". Requests that involve only allowed indices result in a \"match\". Requests that involve a mix of allowed and prohibited indices, are rewritten to only involve allowed indices, and result in a \"match\". Requests that involve only prohibited indices result in a \"no match\". And the ACL evaluation moves on to the next block. The rejection message and HTTP status code returned to the requester are chosen carefully with the main intent to make ES behave like the prohibited indices do not exist at all. The rule has also an extended version: indices: patterns: [\"sales\", \"logstash-*\"]` must_involve_indices: false The definition above has the same meaning as the shortest version shown at the beginning of this section. By default the rule will be matched when a request doesn't involve indices (eg. /_cat/nodes request). But we can change the behaviour by configuring must_involve_indices: true - in this case the request above will be rejected by the rule. In detail, with examples In ReadonlyREST we roughly classify requests as: \"read\": the request will not change the data or the configuration of the cluster \"write\": when allowed, the request changes the internal state of the cluster or the data. If a read request asks for a some indices they have permissions for and some indices that they do NOT have permission for, the request is rewritten to involve only the subset of indices they have permission for. This is behaviour is very useful in Kibana: different users can see the same dashboards with data from only their own indices. When the subset of indices is empty, it means that user are not allowed to access requested indices. In multitenancy environment we should consider two options: requested indices don't exist requested indices exist but logged user is not authorized to access them For both of these cases ROR is going to return HTTP 404 or HTTP 200 with an empty response. The same behaviour will be observed for ES with ROR disabled (for nonexistent index). If an index does exist, but a user is not authorized to access it, ROR is going to pretend that the index doesn't exist and a response will be the same like the index actually did not exist. See detailed example . It's also worth mentioning, that when prompt_for_basic_auth is set to true (that is, the default value), ROR is going to return 401 instead of 404 HTTP status code. It is relevant for users who don't use ROR Kibana's plugin and who would like to take advantage of default Kibana's behaviour which shows the native browser basic auth dialog, when it receives HTTP 401 response. If a write request wants to write to indices they don't have permission for, the write request is rejected. Requests related to templates Templates are also connected with indices, but rather indirectly. An index template has index patterns and could also have aliases. During an index template creation or modification, ROR checks if index patterns and aliases, defined in a request body, are allowed. When a user tries to remove or get template by name, ROR checks if the template can be considered as allowed for the user, and based on that information, it allows/forbids to remove or see it. See details . actions actions: [\"indices:data/read/*\"] Match if the request action starts with \"indices:data/read/\". In Elasticsearch, each request carries only one action. We extracted from Elasticsearch source code the full list of valid action strings as of all Elasticsearch versions. Please see the dedicated section to find the actions list of your specific Elasticsearch version . Example actions (see above for the full list): \"cluster:admin/data_frame/delete\" \"cluster:admin/data_frame/preview\" ... \"cluster:monitor/data_frame/stats/get\" \"cluster:monitor/health\" \"cluster:monitor/main\" \"cluster:monitor/nodes/hot_threads\" \"cluster:monitor/nodes/info\" ... \"indices:admin/aliases\" \"indices:admin/aliases/get\" \"indices:admin/analyze\" ... \"indices:data/read/get\" \"indices:data/read/mget\" \"indices:data/read/msearch\" \"indices:data/read/msearch/template\" ... \"indices:data/write/bulk\" \"indices:data/write/bulk_shard_operations[s]\" \"indices:data/write/delete\" \"indices:data/write/delete/byquery\" \"indices:data/write/index\" \"indices:data/write/reindex\" ... many more... kibana_access kibana_access: ro Enables the minimum set of actions necessary for browsers to use Kibana. This \"macro\" rule allows the minimum set of actions necessary for a browser to use Kibana. This rule allows a set of actions towards the designated kibana index (see kibana_index rule - defaults to \".kibana\"), plus a stricter subset of read-only actions towards other indices, which are considered \"data indices\". The idea is that with one single rule we allow the bare minimum set of index+action combinations necessary to support a Kibana browsing session. Possible access levels: ro_strict : the browser has a read-only view on Kibana dashboards and settings and all other indices. ro : some write requests can go through to the .kibana index so that UI state in discover can be saved and short urls can be created. rw : some more actions will be allowed towards the .kibana index only, so Kibana dashboards and settings can be modified. admin : like above, but has additional permissions to use the ReadonlyREST PRO/Enterprise Kibana app. NB: The \"admin\" access level does not mean the user will be allowed to access all indices/actions. It's just like \"rw\" with settings changes privileges. If you want really unrestricted access for your Kibana user, including ReadonlyREST PRO/Enterprise app, set kibana_access: unrestricted . You can use this rule with the users rule to restrict access to selected admins. This rule is often used with the indices rule, to limit the data a user is able to see represented on the dashboards. In that case do not forget to allow the custom kibana index in the indices rule! kibana_index kibana_index: .kibana-user1 Default value is .kibana Specify to what index we expect Kibana to attempt to read/write its settings (use this together with kibana.index setting in kibana.yml.) This value directly affects how kibana_access works because at all the access levels (yes, even admin), kibana_access rule will not maatch any write request in indices that are not the designated kibana index. If used in conjunction with ReadonlyREST Enterprise, this rule enables multi tenancy , because in ReadonlyREST, a tenancy is identified with a set of Kibana configurations, which are by design collected inside a kibana index (default: .kibana ). snapshots snapshots: [\"snap_@{user}_*\"] Restrict what snapshots names can be saved or restored repositories repositories: [\"repo_@{user}_*\"] Restrict what repositories can snapshots be saved into filter filter: '{\"query_string\":{\"query\":\"user:@{user}\"}}' This rule enables Document Level Security (DLS) . That is: return only the documents that satisfy the boolean query provided as an argument. This rule lets you filter the results of a read request using a boolean query. You can use dynamic variables i.e. @{user} (see dedicated paragraph) to inject a user name or some header values in the query, or even environmental variables. Example: per-user index segmentation In the index \"test-dls\", each user can only search documents whose field \"user\" matches their user name. I.e. A user with username \"paul\" requesting all documents in \"test-dls\" index, won't see returned a document containing a field \"user\": \"jeff\" . - name: \"::PER-USER INDEX SEGMENTATION::\" proxy_auth: \"*\" indices: [\"test-dls\"] filter: '{\"bool\": { \"must\": { \"match\": { \"user\": \"@{user}\" }}}}' Example 2: Prevent search of \"classified\" documents. In this example, we want to avoid that users belonging to group \"press\" can see any document that has a field \"access_level\" with the value \"CLASSIFIED\". And this policy is applied to all indices (no indices rule is specified). - name: \"::Press::\" groups: [\"press\"] filter: '{\"bool\": { \"must_not\": { \"match\": { \"access_level\": \"CLASSIFIED\" }}}}' \u26a0\ufe0fIMPORTANT The filter and fields rules will only affect \"read\" requests, therefore \"write\" requests will not match because otherwise it would implicitly allow clients to \"write\" without the filtering restriction. For reference, this behaviour is identical to x-pack and search guard. \u26a0\ufe0fIMPORTANT Beginning with version 1.27.0 all ROR internal requests from kibana will not match blocks containing filter and/or fields rules. There requests are used to perform kibana login and dynamic config reload. If you want to allow write requests (i.e. for Kibana sessions), just duplicate the ACL block, have the first one with filter and/or fields rule, and the second one without. fields This rule enables Field Level Security (FLS) . That is: for responses where fields with values are returned (e.g. Search/Get API) - filter and show only allowed fields make not allowed fields unsearchable - used in QueryDSL requests (e.g. Search/MSearch API) do not have impact on search result. In other words: FLS protects from usage some not allowed fields for a certain user. From user's perspective it seems like such fields are nonexistent. Definition Field rule definition consists of two parts: A non empty list of fields (blacklisted or whitelisted) names. Supports wildcards and user runtime variables. The FLS engine definition (global setting, optional). See: engine details . \u26a0\ufe0fIMPORTANT With default FLS engine it's required to install ReadonlyREST plugin in all the data nodes. Different configurations allowing to avoid such requirement are described in engine details . Field names Fields can be defined using two access modes: blacklist and whitelist. Blacklist mode (recommended) Specifies which fields should not be allowed prefixed with ~ (other fields from mapping become allowed implicitly). Example: fields: [\"~excluded_fields_prefix_*\", \"~excluded_field\", \"~another_excluded_field.nested_field\"] Return documents but deprived of the fields that: start with excluded_fields_prefix_ are equal to excluded_field are equal to another_excluded_field.nested_field Whitelist mode Specifies which fields should be allowed explicitly (other fields from mapping become not allowed implicitly). Example: fields: [\"allowed_fields_prefix_*\", \"_*\", \"allowed_field.nested_field.text\"] Return documents deprived of all the fields, except the ones that: start with allowed_fields_prefix_ start with underscore are equal to allowed_field.nested_field.text NB: You can only provide a full black list or white list. Grey lists (i.e. [\"~a\", \"b\"] ) are invalid settings and ROR will refuse to boot up if this condition is detected. Example: hide prices from catalogue indices - name: \"External users - hide prices\" fields: [\"~price\"] indices: [\"catalogue_*\"] \u26a0\ufe0fIMPORTANT Any metadata fields e.g. _id or _index can not be used in fields rule. \u26a0\ufe0fIMPORTANT The filter and fields rules will only affect \"read\" requests, therefore \"write\" requests will not match because otherwise it would implicitly allow clients to \"write\" without the filtering restriction. For reference, this behaviour is identical to x-pack and search guard. \u26a0\ufe0fIMPORTANT Beginning with version 1.27.0 all ROR internal requests from kibana will not match blocks containing filter and/or fields rules. There requests are used to perform kibana login and dynamic config reload. If you want to allow write requests (i.e. for Kibana sessions), just duplicate the ACL block, have the first one with filter and/or fields rule, and the second one without. Configuring an ACL with filter/fields rules when using Kibana A normal Kibana session interacts with Elasticsearch using a mix of actions which we can roughly group in two macro categories of \"read\" and \"write\" actions. However the fields and filter rules will only match read requests . They will also block ROR internal request used to log in to kibana and reload config. This means that a complete Kibana session cannot anymore be entirely matched by a single ACL block like it normally would. For example, this ACL block would perfectly support a complete Kibana session. That is, 100% of the actions (browser HTTP requests) would be allowed by this ACL block. - name: \"::RW_USER::\" auth_key: rw_user:pwd kibana_access: rw indices: [\"r*\", \".kibana\"] However, when we introduce a filter (or fields) rule, this block will be able to match only some of the actions (only the \"read\" ones). - name: \"::RW_USER::\" auth_key: rw_user:pwd kibana_access: rw # <-- won't work because of filter present in block indices: [\"r*\", \".kibana\"] filter: '{\"query_string\":{\"query\":\"DestCountry:FR\"}}' # <-- will reject all write requests! :( The solution is to duplicate the block. The first one will intercept (and filter!) the read requests. The second one will intercept the remaining actions. Both ACL blocks together will entirely support a whole Kibana session. - name: \"::RW_USER (filter read requests)::\" auth_key: rw_user:pwd indices: [\"r*\"] # <-- DO NOT FILTER THE .kibana INDEX! filter: '{\"query_string\":{\"query\":\"DestCountry:FR\"}}' - name: \"::RW_USER (allow remaining requests)::\" auth_key: rw_user:pwd kibana_access: rw indices: [\"r*\", \".kibana\"] NB: Look at how we make sure that the requests to \".kibana\" won't get filtered by specifying an indices rule in the first block. Here is another example, a bit more complex. Look at how we can duplicate the \"PERSONAL_GRP\" ACL block so that the read requests to the \"r*\" indices can be filtered, and all the other requests can be intercepted by the second rule (which is identical to the one we had before the duplication). Before adding the filter rule: - name: \"::PERSONAL_GRP::\" groups: [\"Personal\"] kibana_access: rw indices: [\"r*\", \".kibana_@{user}\"] kibana_hide_apps: [\"readonlyrest_kbn\", \"timelion\"] kibana_index: \".kibana_@{user}\" After adding the filter rule (using the block duplication strategy). - name: \"::PERSONAL_GRP (FILTERED SEARCH)::\" groups: [\"Personal\"] indices: [ \"r*\" ] filter: '{\"query_string\":{\"query\":\"DestCountry:FR\"}}' - name: \"::PERSONAL_GRP::\" groups: [\"Personal\"] kibana_access: rw indices: [\"r*\", \".kibana_@{user}\"] kibana_hide_apps: [\"readonlyrest_kbn\", \"timelion\"] kibana_index: \".kibana_@{user}\" response_fields This rule allows filtering Elasticsearch responses using a list of fields. It works in very similar way to fields rule. In contrast to fields rule, which filters out document fields, this rule filters out response fields. It doesn't make use of Field Level Security (FLS) and can be applied to every response returned by Elasticsearch. It can be configured in two modes: whitelist allowing only the defined fields from the response object blacklist filtering out (removing) only the defined fields from the response object Blacklist mode Specifies which fields should be filtered out by adding the ~ prefix to the field name. Other fields in the response will be implicitly allowed. For example: response_fields: [\"~excluded_fields_prefix_*\", \"~excluded_field\", \"~another_excluded_field.nested_field\"] The above will return the usual response object, but deprived (if found) of the fields that: start with excluded_fields_prefix_ are equal to excluded_field are equal to another_excluded_field.nested_field Whitelist mode In this mode rule is configured to filter out each field that isn't defined in the rule. response_fields: [\"allowed_fields_prefix_*\", \"_*\", \"allowed_field.nested_field.text\"] Return response deprived of all the fields, except the ones that: start with allowed_fields_prefix_ start with underscore are equal to allowed_field.nested_field.text NB: You can only provide a full black list or white list. Grey lists (i.e. [\"~a\", \"b\"] ) are invalid settings and ROR will refuse to boot up if this condition is detected. Example : allow only cluster_name and status field in cluster health response: Without any filtering response from /_cluster/health looks more or less like: { \"cluster_name\": \"ROR_SINGLE\", \"status\": \"yellow\", \"timed_out\": false, \"number_of_nodes\": 1, \"number_of_data_nodes\": 1, \"active_primary_shards\": 2, \"active_shards\": 2, \"relocating_shards\": 0, \"initializing_shards\": 0, \"unassigned_shards\": 2, \"delayed_unassigned_shards\": 0, \"number_of_pending_tasks\": 0, \"number_of_in_flight_fetch\": 0, \"task_max_waiting_in_queue_millis\": 0, \"active_shards_percent_as_number\": 50.0 } but after configuring such rule: - name: \"Filter cluster health response\" uri_re: \"^/_cluster/health\" response_fields: [\"cluster_name\", \"status\"] response from above will look like: { \"cluster_name\": \"ROR_SINGLE\", \"status\": \"yellow\" } NB: Any response field can be filtered using this rule. Authentication Local ReadonlyREST users are authenticated via HTTP Basic Auth. This authentication method is secure only if SSL is enabled. auth_key auth_key: sales:p455wd Accepts HTTP Basic Auth . Configure this value in clear text . Clients will need to provide the header e.g. Authorization: Basic c2FsZXM6cDQ1NXdk where \"c2FsZXM6cDQ1NXdk\" is Base64 for \"sales:p455wd\". \u26a0\ufe0fIMPORTANT : this rule is handy just for tests, replace it with another rule that hashes credentials, like: auth_key_sha512 , or auth_key_unix . Impersonation is supported by this rule by default. auth_key_sha512 auth_key_sha512: 280ac6f...94bf9 Accepts HTTP Basic Auth . The value is a string like username:password hashed in SHA512 . Clients will need to provide the usual Authorization header. There are also available other rules with less secure SHA algorithms auth_key_sha256 and auth_key_sha1 . The rules support also alternative syntax, where only password is hashed, eg: auth_key_sha512: \"admin:280ac6f...94bf9\" In the example below admin is the username and 280ac6f...94bf9 is the hashed secret. Impersonation is supported by these rules by default. auth_key_pbkdf2 auth_key_pbkdf2: \"KhIxF5EEYkH5GPX51zTRIR4cHqhpRVALSmTaWE18mZEL2KqCkRMeMU4GR848mGq4SDtNvsybtJ/sZBuX6oFaSg==\" # logstash:logstash auth_key_pbkdf2: \"logstash:JltDNAoXNtc7MIBs2FYlW0o1f815ucj+bel3drdAk2yOufg2PNfQ51qr0EQ6RSkojw/DzrDLFDeXONumzwKjOA==\" # logstash:logstash Accepts HTTP Basic Auth . The value is hashed in the same way as it's done in auth_key_sha512 rule, but it uses PBKDF2 key derivation function. At the moment there is no way to configure it, so during the hash generation, the user has to take into consideration the following PBKDF2 input parameters values: Input parameter Value Comment Pseudorandom function HmacSHA512 Salt use hashed value as a salt eg. hashed value = logstash:logstash , use logstash:logstash as the salt Iterations count 10000 Derived key length 512 bits The hash can be calculated using this calculator (notice that the salt has to base Base64 encoded). Impersonation is supported by this rule by default. auth_key_unix auth_key_unix: test:$6$rounds=65535$d07dnv4N$QeErsDT9Mz.ZoEPXW3dwQGL7tzwRz.eOrTBepIwfGEwdUAYSy/NirGoOaNyPx8lqiR6DYRSsDzVvVbhP4Y9wf0 # Hashed for \"test:test\" \u26a0\ufe0fIMPORTANT this hashing algorithm is very CPU intensive , so we implemented a caching mechanism around it. However, this will not protect Elasticsearch from a DoS attack with a high number of requests with random credentials. This method is based on /etc/shadow file syntax. If you configured sha512 encryption with 65535 rounds on your system the hash in /etc/shadow for the account test:test will be test:$6$rounds=65535$d07dnv4N$QeErsDT9Mz.ZoEPXW3dwQGL7tzwRz.eOrTBepIwfGEwdUAYSy/NirGoOaNyPx8lqiR6DYRSsDzVvVbhP4Y9wf0 readonlyrest: access_control_rules: - name: Accept requests from users in group team1 on index1 groups: [\"team1\"] indices: [\"index1\"] users: - username: test auth_key_unix: test:$6$rounds=65535$d07dnv4N$QeErsDT9Mz.ZoEPXW3dwQGL7tzwRz.eOrTBepIwfGEwdUAYSy/NirGoOaNyPx8lqiR6DYRSsDzVvVbhP4Y9wf0 #test:test groups: [\"team1\"] You can generate the hash with mkpasswd Linux command, you need whois package apt-get install whois (or equivalent) mkpasswd -m sha-512 -R 65534 Also you can generate the hash with a python script (works on Linux): #!/usr/bin/python import crypt import random import sys import string def sha512_crypt(password, salt=None, rounds=None): if salt is None: rand = random.SystemRandom() salt = ''.join([rand.choice(string.ascii_letters + string.digits) for _ in range(8)]) prefix = '$6$' if rounds is not None: rounds = max(1000, min(999999999, rounds or 5000)) prefix += 'rounds={0}$'.format(rounds) return crypt.crypt(password, prefix + salt) if __name__ == '__main__': if len(sys.argv) > 1: print sha512_crypt(sys.argv[1], rounds=65635) else: print \"Argument is missing, <password>\" Finally you have to put your username at the begining of the hash with \":\" separator test:$6$rounds=65535$d07dnv4N$QeErsDT9Mz.ZoEPXW3dwQGL7tzwRz.eOrTBepIwfGEwdUAYSy/NirGoOaNyPx8lqiR6DYRSsDzVvVbhP4Y9wf0 For example, test is the username and $6$rounds=65535$d07dnv4N$QeErsDT9Mz.ZoEPXW3dwQGL7tzwRz.eOrTBepIwfGEwdUAYSy/NirGoOaNyPx8lqiR6DYRSsDzVvVbhP4Y9wf0 is the hash for test (the password is identical to the username in this example). Impersonation is supported by this rule by default. proxy_auth: \"*\" proxy_auth: \"*\" Delegated authentication. Trust that a reverse proxy has taken care of authenticating the request and has written the resolved user name into the X-Forwarded-User header. The value \"*\" in the example, will let this rule match any username value contained in the X-Forwarded-User header. If you are using this technique for authentication using our Kibana plugins, don't forget to add this snippet to conf/kibana.yml : readonlyrest_kbn.proxy_auth_passthrough: true So that Kibana will forward the necessary headers to Elasticsearch. Impersonation is supported by this rule by default. users users: [\"root\", \"*@mydomain.com\"] Limit access to of specific users whose username is contained or matches the patterns in the array. This rule is independent from the authentication method chosen, so it will work well in conjunction LDAP, JWT, proxy_auth, and all others. For example: readonlyrest: access_control_rules: - name: \"JWT auth for viewer group (role), limited to certain usernames\" kibana_access: ro users: [\"root\", \"*@mydomain.com\"] jwt_auth: name: \"jwt_provider_1\" groups: [\"viewer\"] groups groups: [\"group1\", \"group2\"] The ACL block will match when the user belongs to any of the specified groups. The information about what users belong to what groups is defined in the users section, typically situated after the ACL, further down in the YAML. In the users section, each entry tells us that: A given user with a username matching one of patterns in the username array ... belongs to the local groups listed in the groups array (example 1 & 2 below) OR belongs to local groups that are result of \"detailed group mapping\" between local group name and external groups (example 3 below). when they can be authenticated and (if authorization rule is present) authorized by the present rule(s). In general it looks like this: ... - name: \"ACL block with groups rule\" indices: [x, y] groups: [\"local_group1\"] # this group name is defined in the \"users\" section users: - username: [\"pattern1\", \"pattern2\", ...] groups: [\"local_group1\", \"local_group2\", ...] <any_authentication_rule>: ... - username: [\"pattern1\", \"pattern2\", ...] groups: [\"local_group1\", \"local_group2\", ...] <any_authentication_rule>: ... <optionally_any_authorization_rule>: ... - username: [\"pattern1\", \"pattern2\", ...] groups: - local_group1: [\"external_group1\", \"external_group2\"] - local_group2: [\"external_group2\"] <authentication_with_authorization_rule>: ... # `ldap_auth` or `jwt_auth` or `ror_kbn_auth` For details see User management . Impersonation supports depends on authentication and authorization rules used in users section. groups_and groups_and: [\"group1\", \"group2\"] This rule is identical to the above defined groups rule, but this time ALL the groups listed in the array are required (boolean AND logic), as opposed to at least one (boolean OR logic) of the groups rule. session_max_idle session_max_idle: 1h \u26a0\ufe0fDEPRECATED Browser session timeout (via cookie). Example values 1w (one week), 10s (10 seconds), 7d (7 days), etc. NB: not available for Elasticsearch 2.x. ldap_authentication simple version: ldap_authentication: ldap1 extended version: ldap_authentication: name: ldap1 cache_ttl: 10 sec It handles LDAP authentication only using the configured LDAP connector (here ldap1 ). Check the LDAP connector section to see how to configure the connector. ldap_authorization ldap_authorization: name: \"ldap1\" groups: [\"group3\"] cache_ttl: 10 sec It handles LDAP authorization only using the configured LDAP connector (here ldap1 ). It matches when previously authenticated user has groups in LDAP and when he belongs to at least one of the configured groups (OR logic). Alternatively, groups_and can be used to require users belong to all the listed groups (AND logic). Check the LDAP connector section to see how to configure the connector. ldap_auth Shorthand rule that combines ldap_authentication and ldap_authorization rules together. It handles both authentication and authorization using the configured LDAP connector (here ldap1 ). ldap_auth: name: \"ldap1\" groups: [\"group1\", \"group2\"] The same functionality can be achieved using the two rules described below: ldap_authentication: ldap1 ldap_authorization: name: \"ldap1\" groups: [\"group1\", \"group2\"] # match when user belongs to at least one group In both ldap_auth and ldap_authorization , the groups clause can be replaced by group_and to require the valid LDAP user must belong to all the listed groups: ldap_auth: name: \"ldap1\" groups_and: [\"group1\", \"group2\"] # match when user belongs to ALL listed groups Or equivalently: ldap_authentication: ldap1 ldap_authorization: name: \"ldap1\" groups_and: [\"group1\", \"group2\"] # match when user belongs to ALL listed groups See the dedicated LDAP section Impersonation is not supported by default by LDAP rules. jwt_auth See below, the dedicated JSON Web Tokens section Impersonation is not supported by this rule by default. external-basic-auth Used to delegate authentication to another server that supports HTTP Basic Auth. See below, the dedicated External BASIC Auth section Impersonation is not supported by this rule by default. groups_provider_authorization Used to delegate groups resolution for a user to a JSON microservice. See below, the dedicated Groups Provider Authorization section Impersonation is not supported by this rule by default. ror_kbn_auth For Enterprise customers only, required for SAML authentication. readonlyrest: access_control_rules: - name: \"ReadonlyREST Enterprise instance #1\" ror_kbn_auth: name: \"kbn1\" groups: [\"SAML_GRP_1\", \"SAML_GRP_2\"] # <- use this field when a user should belong to at least one of the configured groups - name: \"ReadonlyREST Enterprise instance #1 - two groups required\" ror_kbn_auth: name: \"kbn1\" groups_and: [\"SAML_GRP_1\", \"SAML_GRP_2\"] # <- use this field when a user should belong to all configured groups - name: \"ReadonlyREST Enterprise instance #2\" ror_kbn_auth: name: \"kbn2\" ror_kbn: - name: kbn1 signature_key: \"shared_secret_kibana1\" # <- use environmental variables for better security! - name: kbn2 signature_key: \"shared_secret_kibana2\" # <- use environmental variables for better security! This authentication and authorization connector represents the secure channel (based on JWT tokens) of signed messages necessary for our Enterprise Kibana plugin to securely pass back to ES the username and groups information coming from browser-driven authentication protocols like SAML Continue reading about this in the kibana plugin documentation, in the dedicated SAML section Impersonation is not supported by this rule by default. Ancillary rules verbosity verbosity: error Don't spam elasticsearch log file printing log lines for requests that match this block. Defaults to info . Audit & Troubleshooting The main issues seen in support cases: Bad ordering or ACL blocks. Remember that the ACL is evaluated sequentially, block by block. And the first block whose rules all match is accepted. Users don't know how to read the HIS field in the logs, which instead is crucial because it contains a trace of the evaluation of rules and blocks. LDAP configuration: LDAP is tricky to configure in any system. Configure ES root logger to DEBUG editing $ES_PATH_CONF/config/log4j2.properties to see a trace of the LDAP messages. Interpreting logs ReadonlyREST prints a log line for each incoming request (this can be selectively avoided on ACL block level using the verbosity rule). Allowed requests This is an example of a request that matched an ACL block (allowed) and has been let through to Elasticsearch. ALLOWED by { name: '::PERSONAL_GRP::', policy: ALLOW} req={ ID:1667655475--1038482600#1312339, TYP:SearchRequest, CGR:N/A, USR:simone, BRS:true, ACT:indices:data/read/search, OA:127.0.0.1, IDX:, MET:GET, PTH:/_search, CNT:<N/A>, HDR:Accept,Authorization,content-length,Content-Type,Host,User-Agent,X-Forwarded-For, HIS:[::PERSONAL_GRP::->[kibana_access->true, kibana_hide_apps->true, auth_key->true, kibana_index->true]], [::Kafka::->[auth_key->false]], [::KIBANA-SRV::->[auth_key->false]], [guest lol->[auth_key->false]], [::LOGSTASH::->[auth_key->false]] } Explanation The log line immediately states that this request has been allowed by an ACL block called \"::PERSONAL_GRP::\". Immediately follows a summary of the requests' anatomy. The format is semi-structured, and it's intended for humans to read quickly, it's not JSON, or anything else. Similar information gets logged in JSON format into Elasticsearch documents enabling the audit logs feature described later. Here is a glossary: ID : ReadonlyREST-level request id TYP : String, the name of the Java class that internally represent the request type (very useful for debug) CGR : String, the request carries a \"current group\" header (used for multi-tenancy). USR : String, the user name ReadonlyREST was able to extract from Basic Auth, JWT, LDAP, or other methods as specified in the ACL. BRS : Boolean, an heuristic attempt to tell if the request comes from a browser. ACT : String, the elasticsearch level action associated with the request. For a list of actions, see our actions rule docs . OA : IP Address, originating address (source address) of the TCP connection underlying the http session. IDX : Strings array: the list of indices affected by this request. MET : String, HTTP Method CNT : String, HTTP body content. Comes as a summary of its lenght, full body of the request is available in debug mode. HDR : String array, list of HTTP headers, headers' content is available in debug mode. HIS : Chronologically ordered history of the ACL blocks and their rules being evaluated, This is super useful for knowing what ACL block/rule is forbidding/allowing this request. In the example, the block ::PERSONAL_GRP:: is allowing the request because all the rules in this block evaluate to true . Forbidden requests This is an example of a request that gets forbidden by ReadonlyREST ACL. FORBIDDEN by default req={ ID:747832602--1038482600#1312150, TYP:SearchRequest, CGR:N/A, USR:[no basic auth header], BRS:true, ACT:indices:data/read/search, OA:127.0.0.1, IDX:, MET:GET, PTH:/_search, CNT:<N/A>, HDR:Accept,content-length,Content-Type,Host,User-Agent,X-Forwarded-For, HIS:[::Infosec::->[groups->false]], [::KIBANA-SRV::->[auth_key->false]], [guest lol->[auth_key->false]], [::LOGSTASH::->[auth_key->false]], [::Infosec::->[groups->false]], [::ADMIN_GRP::->[groups->false]], [::Kafka::->[auth_key->false]], [::PERSONAL_GRP::->[groups->false]] } The above rule gets forbidden \"by default\". This means that no ACL block has matched the request, so ReadonlyREST's default policy of rejection takes effect. Requests finished with INDEX NOT FOUND This is an example of such request: INDEX NOT FOUND req={ ID:501806845-1996085406#74, TYP:GetIndexRequest, CGR:N/A, USR:dev1 (attempted), BRS:true, KDX:null, ACT:indices:admin/get, OA:172.20.0.1/32, XFF:null, DA:172.20.0.2/32, IDX:nonexistent*, MET:GET, PTH:/nonexistent*/_alias/, CNT:<N/A>, HDR:Accept-Encoding=gzip,deflate, Authorization=<OMITTED>, Connection=Keep-Alive, Host=localhost:32773, User-Agent=Apache-HttpClient/4.5.2 (Java/1.8.0_162), content-length=0, HIS:[CONTAINER ADMIN-> RULES:[auth_key->false]], [dev1 indexes-> RULES:[auth_key->true, indices->false], RESOLVED:[user=dev1]], [dev2 aliases-> RULES:[auth_key->false]], [dev3 - no indices rule-> RULES:[auth_key->false]] } The state above is only possible for read-only ES requests (ES requests which don't change ES cluster state) for a block containing an indices rule. If all other rules within the block are matched, but only the indices rule is mismatched, the final state of the block is forbidden due to an index not found. Audit logs ReadonlyREST can write events very similarly to Logstash into to a series of indices named by default readonlyrest_audit-YYYY-MM-DD . Every event contains information about a request and how the system has handled it. Here is an example of the data points contained in each audit event. We can leverage all this information to build interesting Kibana dashboards, or any other visualization. { \"error_message\": null, \"headers\": [ \"Accept\", \"Authorization\", \"content-length\", \"Host\", \"User-Agent\" ], \"acl_history\": \"[[::LOGSTASH::->[auth_key->false]], [::RW::->[kibana_access->true, indices->true, kibana_hide_apps->true, auth_key->true]], [kibana->[auth_key->false]], [::RO::->[auth_key->false]]]\", \"origin\": \"127.0.0.1\", \"final_state\": \"ALLOWED\", \"task_id\": 1158, \"type\": \"SearchRequest\", \"req_method\": \"GET\", \"path\": \"/readonlyrest_audit-2017-06-29/_search?pretty\", \"indices\": [ \"readonlyrest_audit-2017-06-29\" ], \"@timestamp\": \"2017-06-30T09:41:58Z\", \"content_len_kb\": 0, \"error_type\": null, \"processingMillis\": 0, \"action\": \"indices:data/read/search\", \"matched_block\": \"::RW::\", \"id\": \"933409190-292622897#1158\", \"content_len\": 0, \"user\": \"simone\" } Here is a configuration example, you can see the audit.collector: true setting, which normally defaults to false. Note how the successful requests matched by the first rule (Kibana) will not be written to the audit log, because the verbosity is set to error. Audit log in facts, obey the verbosity setting the same way regular text logs do. NB Following audit configurations are presented with the separate audit section, although it can be omitted as settings defined using previous approach (defined directly under readonlyrest section and starting with audit_ )` are still supported (but not recommended) preserving backward compatibility. readonlyrest: audit: collector: true access_control_rules: - name: Kibana type: allow auth_key: kibana:kibana verbosity: error - name: \"::RO::\" auth_key: simone:ro kibana_access: ro Extended audit If you want to log the request content then an additional serializer is provided. This will log the entire user request within the content field of the audit event. To enable, configure the audit_serializer parameter as below. readonlyrest: audit: collector: true serializer: tech.beshu.ror.requestcontext.QueryAuditLogSerializer ... Custom audit indices name and time granularity It is possible to change the name of the produced audit log indices by specifying a template value as audit.index_template . Example: tell ROR to write on monthly index. readonlyrest: audit: collector: true index_template: \"'custom-prefix'-yyyy-MM\" # <--monthly pattern ... \u26a0\ufe0fIMPORTANT : notice the single quotes inside the double quoted expression. This is the same syntax used for Java's SimpleDateFormat . Custom audit log serializer You can write your own custom audit log serializer class, add it to the ROR plugin class path and configure it through the YAML settings. We provided 2 project examples with custom serializers (in Scala and Java). You can use them as an example to write yours in one of those languages. Create custom audit log serializer in Scala Checkout https://github.com/sscarduzio/elasticsearch-readonlyrest-plugin git clone git@github.com:sscarduzio/elasticsearch-readonlyrest-plugin.git Install SBT https://www.scala-sbt.org/download.html Find and go to: elasticsearch-readonlyrest-plugin/custom-audit-examples/ror-custom-scala-serializer/ Create own serializer: from scratch (example can be found in class ScalaCustomAuditLogSerializer ) extending default one (example can be found in class ScalaCustomAuditLogSerializer ) Build serializer JAR: sbt assembly Jar can be find in: elasticsearch-readonlyrest-plugin/custom-audit-examples/ror-custom-scala-serializer/target/scala-2.13/ror-custom-scala-serializer-1.0.0.jar Create custom audit log serializer in Java Checkout https://github.com/sscarduzio/elasticsearch-readonlyrest-plugin git clone git@github.com:sscarduzio/elasticsearch-readonlyrest-plugin.git Install Maven https://maven.apache.org/install.html Find and go to: elasticsearch-readonlyrest-plugin/custom-audit-examples/ror-custom-java-serializer/ Create own serializer: from scratch (example can be found in class JavaCustomAuditLogSerializer ) extending default one (example can be found in class JavaCustomAuditLogSerializer ) Build serializer JAR: mvn package Jar can be find in: elasticsearch-readonlyrest-plugin/custom-audit-examples/ror-custom-java-serializer/target/ror-custom-java-serializer-1.0.0.jar Configuration mv ror-custom-java-serializer-1.0.0.jar plugins/readonlyrest/ Your config/readonlyrest.yml should start like this text readonlyrest: audit: collector: true serializer: \"JavaCustomAuditLogSerializer\" # when your serializer class is not in default package, you should use full class name here (eg. \"tech.beshu.ror.audit.instances.QueryAuditLogSerializer\") Start elasticsearch (with ROR installed) and grep for: text [2017-11-09T09:42:51,260][INFO ][t.b.r.r.SerializationTool] Using custom serializer: JavaCustomAuditLogSerializer Troubleshooting Follow these approaches until you find the solution to your problem Scenario: you can't understand why your requests are being forbidden by ReadonlyREST (or viceversa) Step 1: see what block/rule is matching Take the Elasticsearch log file, and grep the logs for ACT: . This will show you the whole request context (including the action and indices fields) of the blocked requests. You can now tweak your ACL blocks to include that action. Step 2: enable debug logs Logs are good for auditing the activity on the REST API. You can configure them by editing $ES_PATH_CONF/config/logging.yml (Elasticsearch 2.x) or $ES_PATH_CONF/config/log4j2.properties file (Elasticsearch 5.x) For example, you can enable the debug log globally by setting the rootLogger to debug . rootLogger.level = debug This is really useful especially to debug the activity of LDAP and other external connectors. Trick: log requests to different files Here is a log4j2.properties snippet for ES 5.x that logs all the received requests as a new line in a separate file: #Plugin readonly rest separate access logging file definition appender.access_log_rolling.type = RollingFile appender.access_log_rolling.name = access_log_rolling appender.access_log_rolling.fileName = ${sys:es.logs}_access.log appender.access_log_rolling.layout.pattern = [%d{ISO8601}][%-5p][%-25c] %marker%.-10000m%n appender.access_log_rolling.layout.type = PatternLayout appender.access_log_rolling.filePattern = ${sys:es.logs}_access-%d{yyyy-MM-dd}.log appender.access_log_rolling.policies.type = Policies appender.access_log_rolling.policies.time.type = TimeBasedTriggeringPolicy appender.access_log_rolling.policies.time.interval = 1 appender.access_log_rolling.policies.time.modulate = true logger.access_log_rolling.name = tech.beshu.ror logger.access_log_rolling.level = info logger.access_log_rolling.appenderRef.access_log_rolling.ref = access_log_rolling logger.access_log_rolling.additivity = false # exclude kibana, beat and logstash users as they generate too much noise logger.access_log_rolling.filter.regex.type = RegexFilter logger.access_log_rolling.filter.regex.regex = .*USR:(kibana|beat|logstash),.* logger.access_log_rolling.filter.regex.onMatch = DENY logger.access_log_rolling.filter.regex.onMismatch = ACCEPT Custom audit cluster It's possible to set a custom audit cluster responsible for audit logs storage. When a custom cluster is specified, items will be sent to defined cluster nodes instead of the local one. readonlyrest: audit: collector: true cluster: [\"https://user1:password@auditNode1:9200\", \"https://user2:password@auditNode2:9200\"] ... Setting audit.cluster is optional, it accepts non empty list of audit cluster nodes URIs. Users and Groups Sometimes we want to make allow/forbid decisions according to the username associated to a HTTP request. The extraction of the user identity (username) can be done via HTTP Basic Auth (Authorization header) or delegated to a reverse proxy (see proxy_auth rule). The validation of the said credentials can be carried on locally with hard coded credential hashes (see auth_key_sha256 rule), via one or more LDAP server, or we can forward the Authorization header to an external web server and examine the HTTP status code (see external_authentication ). Optionally we can introduce the notion of groups (see them as bags of users). The aim of having groups is to write a very specific block once, and being able to allow multiple usernames that satisfy the block. Groups can be declared and associated to users statically in the readonlyrest.yml file. Alternatively, groups for a given username can be retrieved from an LDAP server or from a LDAP server, or a custom JSON/XML service. You can mix and match the techniques to satisfy your requirements. For example, you can configure ReadonlyREST to: Extract the username from X-Forwarded-User Resolve groups associated to said user through a JSON microservice Another example: Extract the username from Authorization header (HTTP Basic Auth) Validate said username's password via LDAP server resolve groups associated to the user from groups defined in readonlyrest.yml More examples are shown below together with a sample configuration. Local users and groups The groups rule accepts a list of group names. This rule will match if the resolved username (i.e. via auth_key ) is associated to the given groups. In this example, the usernames are statically associated to group names. access_control_rules: - name: Accept requests from users in group team1 on index1 type: allow # Optional, defaults to \"allow\" will omit now on. groups: [\"team1\"] indices: [\"index1\"] - name: Accept requests from users in group team2 on index2 groups: [\"team2\"] indices: [\"index2\"] - name: Accept requests from users in groups team1 OR team2 on index3 groups: [\"team1\", \"team2\"] indices: [\"index3\"] - name: Accept requests from users in groups team1 AND team2 on index3 groups_and: [\"team1\", \"team2\"] indices: [\"index3\"] users: - username: \"alice\" groups: [\"team1\"] auth_key: alice:p455phrase - username: \"bob\" groups: [\"team2\", \"team4\"] auth_key: bob:s3cr37 - username: \"claire\" groups: [\"team1\", \"team5\"] auth_key_sha256: e0bba5fda92dbb0570fd2e729a3c8ed6b1d52b380581f32427a38e396ba28ec6 #claire:p455key Example: rules are associated to groups (instead of users) and users-group association is declared separately later under users: Group mapping Sometimes we'd like to take advantage of groups (roles) existing in external systems (like LDAP). We can do that in users section too. It's possible to map external groups to local ones. For details see External to local groups mapping . Username case sensitivity ReadonlyREST can cooperate with services, that operates in case-insensitive way. For this case ROR has toggleable username case sensitivity option username_case_sensitivity . readonlyrest: username_case_sensitivity: case_sensitive By default, usernames are case-sensitive username_case_sensitivity: case_sensitive . By setting username_case_sensitivity: case_sensitive username comparison will be case-insensitive in any rule. Environmental variables Anywhere in readonlyrest.yml you can use the espression ${MY_ENV_VAR} to replace in place the environmental variables. This is very useful for injecting credentials like LDAP bind passwords, especially in Docker. For example, here we declare an environment variable, and we write ${LDAP_PASSWORD} in our settings: $ export LDAP_PASSWORD=S3cr3tP4ss $ cat readonlyrest.yml .... ldaps: - name: ldap1 host: \"ldap1.example.com\" port: 389 ssl_enabled: false ssl_trust_all_certs: true bind_dn: \"cn=admin,dc=example,dc=com\" bind_password: \"${LDAP_PASSWORD}\" search_user_base_DN: \"ou=People,dc=example,dc=com\" .... And ReadonlyREST ES will load \"S3cr3tP4ss\" as bind_password . Dynamic variables One of the neatest feature in ReadonlyREST is that you can use dynamic variables inside most rules values. The variables you can currently replace into rules values are these: @{acl:user} gets replaced with the username of the successfully authenticated user. Using this variable is allowed only in blocks where one of the rules is authentication rule (of course it must be rule different from the one containing given variable). @{user} old style user variable definition. Preferred approach is to use @{acl:user} . @{acl:current_group} gets replaced with user's current group. Usually resolved by authorization rule defined in block, but value can be also retrieved by means of kibana plugin. This variable doesn't specify usage requirements. @{xyz} gets replaced with any xyz HTTP header included in the incoming request (useful when reverse proxies handle authentication) Indices from user name You can let users authenticate externally, i.e. via LDAP, and use their user name string inside the indices rule. readonlyrest: access_control_rules: - name: \"Users can see only their logstash indices i.e. alice can see alice_logstash-20170922\" ldap_authentication: name: \"myLDAP\" indices: [\"@{acl:user}_logstash-*\"] # LDAP connector settings omitted, see LDAP section below.. Uri regex matching user's current group You can let users authorize externally, i.e. via LDAP, and use their group inside the uri_re rule. readonlyrest: access_control_rules: - name: \"Users can access uri with value containing user's current group, i.e. user with group 'g1' can access: '/path/g1/some_thing'\" ldap_authorization: name: \"ldap1\" groups: [\"g1\", \"g2\", \"g3\"] uri_re: [\"^/path/@{acl:current_group}/.*\"] # LDAP connector settings omitted, see LDAP section below.. Kibana index from headers Imagine that we delegate authentication to a reverse proxy, so we know that only authenticated users will ever reach Elasticsearch. We can tell the reverse proxy (i.e. Nginx) to inject a header called x-nginx-user containing the username. readonlyrest: access_control_rules: - name: \"Identify a personal kibana index where each user is supposed to save their dashboards\" kibana_access: rw kibana_index: \".kibana_@{x-nginx-user}\" Dynamic variables from JWT claims The JWT token is an authentication string passed generally as a header or a query parameter to the web browser. If you squint, you can see it's a concatenation of three base64 encoded strings. If you base64 decode the middle string, you can see the \"claims object\". That is the object containing the current user's metadata. Here is an example of JWT claims object. { \"user\": \"jdoe\", \"display_name\": \"John Doe\", \"department\": \"infosec\", \"allowedIndices\": [\"x\", \"y\"] } Here follow some examples of how to use JWT claims as dynamic variables in ReadonlyREST ACL blocks, notice the \"jwt:\" prefix: # Using JWT claims as dynamic variables indices: [ \".kibana_@{jwt:department}\", \"otherIdx\" ] # claims = { \"user\": \"u1\", \"department\": \"infosec\"} # -> indices: [\".kibana_infosec\", \"otherIdx\"] # Using nested values in JWT using JSONPATH as dynamic variables indices: [ \".kibana_@{jwt:jsonpath.to.department}\", \"otherIdx\"] # claims = { \"jsonpath\": {\"to\": { \"department\": \"infosec\" }}} # -> indices: [\".kibana_infosec\", \"otherIdx\"] # Referencing array-typed values from JWT claims will expand in a list of strings indices: [ \".kibana_@explode{jwt:allowedIndices}\", \"otherIdx\"] # claims = {\"username\": \"u1\", \"allowedIndices\": [\"x\", \"y\"] } # -> indices: [\".kibana_x\", \".kibana_y\", \"otherIdx\"] # Explode operator will generate an array of strings from a comma-separated string indices: [\"logstash_@explode{x-indices_csv_string}*\", \"otherIdx\"] # HTTP Headers: [{ \"x-indices_csv_string\": \"a,b\"}] # -> indices: [\"logstash_a*\", \"logstash_b*\", \"otherIdx\"] LDAP connector The auhentication and authorization rules for LDAP ( ldap_auth , ldap_authentication , ldap_authorization ) defined in the rules section, always need to contain a reference by name to one LDAP connector. One or more LDAP connectors need to be defined in the section \"ldaps\" of the ACL. Configuration notes If you would like to experiment with LDAP and need a development server, you can stand up an OpenLDAP server configuring it using our schema file, which can be found in our tests ). Technical configuration There are also plenty of technical settings which can be useful: * an LDAP server address: * single host: * host (String, required) - LDAP server address * port (Integer, optional, default: 389 ) - LDAP server port * ssl_enabled (Boolean, optional, default: true ) - enables or disables SSL for LDAP connection * several hosts: * hosts (List, required) - list of LDAP server addresses. The address should look like this ldap://[HOST]:[PORT] or/and ldaps://[HOST]:[PORT] * ha (enum: [ FAILOVER , ROUND_ROBIN ], optional, default: FAILOVER ) - provides high availability strategy for LDAP * auto-discovery: * server_discovery (Boolean|YAML object, optional, default: false ) - for details see LDAP server discovery section * connection_pool_size (Integer, optional, default: 30 ) - indicates how many connections LDAP connector should create to LDAP server * connection_timeout (Duration, optional, default: 10 sec ) - instructs connector how long it should wait for the connection to LDAP server * request_timeout (Duration, optional, default: 10 sec ) - instructs connector how long it should wait for receiving a whole response from LDAP server * ssl_trust_all_certs (Boolean, optional, default: false ) - if it is set to true , untrusted certificates will be accepted * ignore_ldap_connectivity_problems (Boolean, optional, default: false ) - when it is set to true , it allows ROR to function even when LDAP server is unreachable. Rules using unreachable LDAP servers won't match. By default, ROR starts only after it's able to connect to each server * cache_ttl (Duration, optional, default: 0 sec ) - tells how long LDAP connector should cache queries results (for default see caching section ) * circuit_breaker (YAML object, optional, default: max_retries: 10 , reset_duration: 10 sec ) - for details see circuit breaker section Query configuration Usually, we would like to configure three main things for defining the way LDAP users and groups are queried: a way to authenticate client (LDAP binding; used by all LDAP rules): bind_dn (string, optional, default: [not present]) - a username used to connect to the LDAP service. We can skip this setting when our LDAP service allows for anonymous binding bind_password (string, optional, default: [not present]) - a password used to connect to the LDAP service. We can skip this setting when our LDAP service allows for anonymous binding a way to search users . In ROR it can be done using the following YAML keys (used by all LDAP rules): search_user_base_DN (string, required) - should refer to the base Distinguished Name of the users to be authenticated user_id_attribute (string, optional, default: uid ) - should refer to a unique ID for the user within the base DN a way to search user groups (NOT used by ldap_authentication rule). In ROR, depending on LDAP schema, a relation between users and groups can be defined in: Group entry - it has an attribute that refers to User entries: search_groups_base_DN (required) - should refer to the base Distinguished Name of the groups to which these users may belong group_name_attribute (string, optional, default: cn ) - is the LDAP group object attribute that contains the names of the ROR groups unique_member_attribute (string, optional, default: uniqueMember ) - is the LDAP group object attribute that contains the names of the ROR groups group_search_filter (string, optional, default: (cn=*) ) - is the LDAP search filter (or filters) to limit the user groups returned by LDAP. By default, this filter will be joined (with & ) with unique_member_attribute=user_dn filter resulting in this LDAP search filter: (&YOUR_GROUP_SEARCH_FILTER(unique_member_attribute=user_dn)) . group_attribute_is_dn (boolean, optional, default: true ) - when true the search filter will look like that: (&YOUR_GROUP_SEARCH_FILTER(unique_member_attribute={USER_DN})) then false the search filer will look like that: (&YOUR_GROUP_SEARCH_FILTER(unique_member_attribute={USER_ID_ATTRIBUTE_VALUE})) User entry - it has an attribute that refers to Group entries: search_groups_base_DN (string, required) - should refer to the base Distinguished Name of the groups to which these users may belong group_name_attribute (string, optional, default: cn ) - is the LDAP group object attribute that contains the names of the ROR groups groups_from_user_attribute (string, optional, default: memberOf ) - is the LDAP user object attribute that contains the names of the ROR groups Examples: group_search_filter: \"(objectClass=group)\" group_search_filter: \"(objectClass=group)(cn=application*)\" group_search_filter: \"(cn=*)\" # basically no group filtering Caching Too many calls made by ROR to our LDAP service can sometimes be problematic (eg. when one LDAP connector is used in many rules). The problem can be simply solved by using caching functionality. Caching can be configured per LDAP connector or per LDAP rule (see ldap_auth , ldap_authentication , ldap_authorization rules). By default cache is diabled. We can enabled it by set cache_ttl > 0 sec . In the cache will be stored only results of successful requests - info about authentication result and/or returned LDAP groups for the given credentials. When LDAP connector level cache is used any rule that use the connector can take advantage of cached results. When we configure cache_ttl at LDAP rule level, the results of LDAP calls made by the rule will be stored in cache. Other LDAP rules won't have access to this cache. Circuit Breaker The LDAP connector is equipped by default with a circuit breaker functionality. The circuit breaker can disable the connector from sending new requests to the server when it doesn't respond properly. After receiving a configurable number of failed responses in a row, the circuit breaker feature disables sending any new requests by terminating them immediately with an exception. After a configurable amount of time, the circuit breaker feature allows one request to pass again. If it succeeds, the connector goes back to normal operation. If not, a test request is sent again after a configurable amount of time. A general description of the concept could be found on wiki and more about specific implementation could be found in library documentation . The circuit breaker feature can be customized to adapt to specific needs using the following configuration parameters: max_retries is the number of failed responses in a row that will trigger the circuit breaker. reset_duration defines how long the circuit breaker feature will block the incoming requests before starting to send one test request. to the LDAP server. LDAP Server discovery The LDAP connector can get all LDAP hostnames from DNS server rather than from the configuration file. By default _ldap._tcp SRV records are used for that, but any other SRV record can be configured. The simplest configuration example of an LDAP connector instance using server discovery is: - name: ldap server_discovery: true search_user_base_DN: \"ou=People,dc=example2,dc=com\" search_groups_base_DN: \"ou=Groups,dc=example2,dc=com\" This configuration is using the system DNS to fetch all the _ldap._tcp SRV records which are expected to contain the hostname and port of all the LDAP servers we should connect to. Each SRV record also has priority and weight assigned to it which determine the order in which they should be contacted. Records with a lower priority value will be used before those with a higher priority value. The weight will be used if there are multiple service records with the same priority, and it controls how likely each record is to be chosen. A record with a weight of 2 is twice as likely to be chosen as a record with the same priority and a weight of 1. The server discovery mechanism can be optionally configured further, by adding a few more configuration parameters, all of which are optional: record_name - DNS SRV record name. By default it's _ldap._tcp , but could be _ldap._tcp.domainname or any custom value. dns_url - Address of non-default DNS server in form dns://IP[:PORT] . By default, the system DNS is used. ttl - DNS cache timeout. Specifies how long values from DNS will be kept in the cache. Default is 1h. use_ssl - Use true when SSL should be used for LDAP connections. Default is false which means that SSL won't be used. Example: - name: ldap server_discovery: record_name: \"_ldap._tcp.example.com\" dns_url: \"dns://192.168.1.100\" ttl: \"3 hours\" use_ssl: true search_user_base_DN: \"ou=People,dc=example2,dc=com\" search_groups_base_DN: \"ou=Groups,dc=example2,dc=com\" ROR with LDAP - examples In this example, users' credentials are validated via LDAP. The groups associated with each validated user, are resolved using the same LDAP server. Simpler: authentication and authorization in one rule readonlyrest: access_control_rules: - name: Accept requests from users in group team1 on index1 type: allow # Optional, defaults to \"allow\", will omit from now on. ldap_auth: name: \"ldap1\" # ldap name from below 'ldaps' section groups: [\"g1\", \"g2\"] # group within 'ou=Groups,dc=example,dc=com' indices: [\"index1\"] - name: Accept requests from users in group team2 on index2 ldap_auth: name: \"ldap2\" groups: [\"g3\"] cache_ttl_in_sec: 60 indices: [\"index2\"] ldaps: - name: ldap1 host: \"ldap1.example.com\" port: 389 ssl_enabled: false ssl_trust_all_certs: true ignore_ldap_connectivity_problems: true bind_dn: \"cn=admin,dc=example,dc=com\" bind_password: \"password\" search_user_base_DN: \"ou=People,dc=example,dc=com\" user_id_attribute: \"uid\" search_groups_base_DN: \"ou=Groups,dc=example,dc=com\" unique_member_attribute: \"uniqueMember\" connection_pool_size: 10 connection_timeout: 10s request_timeout: 10s cache_ttl: 60s group_search_filter: \"(objectClass=group)(cn=application*)\" group_name_attribute: \"cn\" circuit_breaker: max_retries: 2 reset_duration: 5s # High availability LDAP settings (using \"hosts\", rather than \"host\") - name: ldap2 hosts: - \"ldaps://ssl-ldap2.foo.com:636\" - \"ldaps://ssl-ldap3.foo.com:636\" ha: \"ROUND_ROBIN\" search_user_base_DN: \"ou=People,dc=example2,dc=com\" search_groups_base_DN: \"ou=Groups,dc=example2,dc=com\" # Server discovery variant - name: ldap3 server_discovery: true search_user_base_DN: \"ou=People,dc=example2,dc=com\" search_groups_base_DN: \"ou=Groups,dc=example2,dc=com\" Advanced: authentication and authorization in separate rules readonlyrest: enable: true response_if_req_forbidden: Forbidden by ReadonlyREST ES plugin access_control_rules: - name: Accept requests to index1 from users with valid LDAP credentials, belonging to LDAP group 'team1' ldap_authentication: \"ldap1\" ldap_authorization: name: \"ldap1\" # ldap name from 'ldaps' section groups: [\"g1\", \"g2\"] # group within 'ou=Groups,dc=example,dc=com' indices: [\"index1\"] - name: Accept requests to index2 from users with valid LDAP credentials, belonging to LDAP group 'team2' ldap_authentication: name: \"ldap2\" cache_ttl: 60s ldap_authorization: name: \"ldap2\" groups: [\"g3\"] cache_ttl: 60s indices: [\"index2\"] ldaps: - name: ldap1 host: \"ldap1.example.com\" port: 389 ssl_enabled: false ssl_trust_all_certs: true ignore_ldap_connectivity_problems: true bind_dn: \"cn=admin,dc=example,dc=com\" bind_password: \"password\" search_user_base_DN: \"ou=People,dc=example,dc=com\" user_id_attribute: \"uid\" search_groups_base_DN: \"ou=Groups,dc=example,dc=com\" unique_member_attribute: \"uniqueMember\" connection_pool_size: 10 connection_timeout: 10s request_timeout: 10s cache_ttl: 60s # High availability LDAP settings (using \"hosts\", rather than \"host\") - name: ldap2 hosts: - \"ldaps://ssl-ldap2.foo.com:636\" - \"ldaps://ssl-ldap3.foo.com:636\" ha: \"ROUND_ROBIN\" search_user_base_DN: \"ou=People,dc=example2,dc=com\" search_groups_base_DN: \"ou=Groups,dc=example2,dc=com\" External Basic Auth ReadonlyREST will forward the received Authorization header to a website of choice and evaluate the returned HTTP status code to verify the provided credentials. This is useful if you already have a web server with all the credentials configured and the credentials are passed over the Authorization header. readonlyrest: access_control_rules: - name: \"::Tweets::\" methods: GET indices: [\"twitter\"] external_authentication: \"ext1\" - name: \"::Facebook posts::\" methods: GET indices: [\"facebook\"] external_authentication: service: \"ext2\" cache_ttl_in_sec: 60 external_authentication_service_configs: - name: \"ext1\" authentication_endpoint: \"http://external-website1:8080/auth1\" success_status_code: 200 cache_ttl_in_sec: 60 validate: false # SSL certificate validation (default to true) http_connection_settings: connection_timeout_in_sec: 5 # default 2 socket_timeout_in_sec: 3 # default 5 connection_request_timeout_in_sec: 3 # default 5 connection_pool_size: 10 # default 30 - name: \"ext2\" authentication_endpoint: \"http://external-website2:8080/auth2\" success_status_code: 204 cache_ttl_in_sec: 60 To define an external authentication service the user should specify: name for service (then this name is used as id in service attribute of external_authentication rule) authentication_endpoint (GET request) success_status_code - authentication response success status code Cache can be defined at the service level or/and at the rule level. In the example, both are shown, but you might opt for setting up either. Custom groups providers This external authorization connector makes it possible to resolve to what groups a users belong, using an external JSON or XML service. readonlyrest: access_control_rules: - name: \"::Tweets::\" methods: GET indices: [\"twitter\"] proxy_auth: proxy_auth_config: \"proxy1\" users: [\"*\"] groups_provider_authorization: user_groups_provider: \"GroupsService\" groups: [\"group3\"] - name: \"::Facebook posts::\" methods: GET indices: [\"facebook\"] proxy_auth: proxy_auth_config: \"proxy1\" users: [\"*\"] groups_provider_authorization: user_groups_provider: \"GroupsService\" groups: [\"group1\"] cache_ttl_in_sec: 60 proxy_auth_configs: - name: \"proxy1\" user_id_header: \"X-Auth-Token\" # default X-Forwarded-User user_groups_providers: - name: GroupsService groups_endpoint: \"http://localhost:8080/groups\" auth_token_name: \"token\" auth_token_passed_as: QUERY_PARAM # HEADER OR QUERY_PARAM response_groups_json_path: \"$..groups[?(@.name)].name\" # see: https://github.com/json-path/JsonPath cache_ttl_in_sec: 60 http_connection_settings: connection_timeout_in_sec: 5 # default 2 socket_timeout_in_sec: 3 # default 5 connection_request_timeout_in_sec: 3 # default 5 connection_pool_size: 10 # default 30 In example above, a user is authenticated by reverse proxy and then external service is asked for groups for that user. If groups returned by the service contain any group declared in groups list, user is authorized and rule matches. To define user groups provider you should specify: name for service (then this name is used as id in user_groups_provider attribute of groups_provider_authorization rule) groups_endpoint - service with groups endpoint (GET request) auth_token_name - user identifier will be passed with this name auth_token_passed_as - user identifier can be send using HEADER or QUERY_PARAM response_groups_json_path - response can be unrestricted, but you have to specify JSON Path for groups name list (see example in tests) As usual, the cache behaviour can be defined at service level or/and at rule level. JSON Web Token (JWT) Auth The information about the username can be extracted from the \"claims\" inside a JSON Web Token. Here is an example. readonlyrest: access_control_rules: - name: Valid JWT token with a viewer group kibana_access: ro jwt_auth: name: \"jwt_provider_1\" groups: [\"viewer\"] - name: Valid JWT token with a writer group kibana_access: rw jwt_auth: name: \"jwt_provider_1\" groups: [\"writer\"] - name: Valid JWT token with a viewer and writer groups kibana_access: rw jwt_auth: name: \"jwt_provider_1\" groups_and: [\"writer\", \"viewer\"] jwt: - name: jwt_provider_1 signature_algo: HMAC # can be NONE, RSA, HMAC (default), and EC signature_key: \"your_signature_min_256_chars\" user_claim: email groups_claim: resource_access.client-app.groups # JSON-path style header_name: Authorization You can verify groups assigned to the user with the groups field. The rule matches when the user belongs to at least one of the configured groups (OR logic). Alternatively, groups_and matches when the user belongs to all given groups (AND logic). The user_claim indicates which field in the JSON will be interpreted as the username. The signature_key is used shared secret between the issuer of the JWT and ReadonlyREST. It is used to verify the cryptographical \"paternity\" of the message. The header_name is used if we expect the JWT Token in a custom header (i.e. Google Cloud IAP signed headers ) The signature_algo indicates the family of cryptographic algorithms used to validate the JWT. Accepted signature_algo values The value of this configuration represents the cryptographic family of the JWT protocol. Use the below table to tell what value you should configure, given a JWT token sample. You can decode sample JWT token using an online tool . Algorithm declared in JWT token signature_algo value NONE None HS256 HMAC HS384 HMAC HS512 HMAC RS256 RSA RS384 RSA RS512 RSA PS256 RSA PS384 RSA PS512 RSA ES256 EC ES384 EC ES512 EC GPLv3 License ReadonlyREST Free (Elasticsearch plugin) is released under the GPLv3 license. For what this kind of software concerns, this is identical to GPLv2, that is, you can treat ReadonlyREST as you would treat Linux code. The big difference from Linux is that here you can ask for a commercial license and stop thinking about legal implications. Here is a practical summary of what dealing with GPLv3 means: You CAN Distribute for free or commercially a version (partial or total) of this software (along with its license and attributions) as part of a product or solution that is also released under GPL-compatible license . Please notify us if you do so. Use a modified version internally to your company without making your changes available under the GPLv3 license. Distribute for free or commercially a modified version (partial or total) of this software, provided that the source is contributed back as pull request to the original project or publicly made available under the GPLv3 or compatible license. You CANNOT Sell or give away a modified version of the plugin (or parts of it, or any derived work) without publishing the modified source under GPLv3 compatible licenses. Modify the code for a paying client without immediately contributing your changes back to this project's GitHub as a pull request, or alternatively publicly release said fork under GPLv3 or compatible license. GPLv3 license FAQ 1. Q : I sell a proprietary software solution that already includes many other OSS components (i.e. Elasticsearch). Can I bundle also ReadonlyREST into it? A : No, GPLv3 does not allow it. But hey, no problem, just go for the Enterprise subscription . 2. Q : I have a SaaS and we want to use a version of ReadonlyREST for Elasticsearch (as is, or modified), do I need a commercial license? A : No, you don't. Go for it! However if you are using Kibana, consider the Enterprise offer which includes multi-tenancy. 3. Q : I'm a consultant and I will charge my customer for modifying this software and they will not sell it as a product or part of their product. A : This is fine with GPLv3. Dual-license Please don't hesitate to contact us for a re-licensed copy of this source. Your success is what makes this project worthwhile, don't let legal issues slow you down. See commercial license FAQ page for more information. Installation Download the binary release of the latest version of ReadonlyREST from the download page cd to the Elasticsearch home Install the plugin Elasticsearch 5.x bin/elasticsearch-plugin install file:///download-folder/readonlyrest-1.13.2_es5.1.2.zip Elasticsearch 2.x bin/plugin install file:///download-folder/readonlyrest-1.13.2_es5.1.2.zip Edit config/readonlyrest.yml and add your configuration as seen in examples. Build from Source You need to have installed: git, maven, Java 8 JDK, zip. So use apt-get or brew to get them. Clone the repo git clone https://github.com/sscarduzio/elasticsearch-readonlyrest-plugin cd elasticsearch-readonlyrest-plugin Launch the build script bin/build.sh You should find the plugin's zip files under /target (Elasticsearch 2.x) or build/releases/ (Elasticsearch 5.x). Examples A small library of typical use cases. Secure Logstash We have a Logstash agent installed somewhere and we want to ship the logs to our Elasticsearch cluster securely. Elasticsearch side Step 1: Bring Elasticsearch HTTP interface (port 9200) to HTTPS When you get SSL certificates (i.e. from your IT department, or from LetsEncrypt), you should obtain a private key and a certificate chain. In order to use them with ReadonlyREST, we need to wrap them into a JKS (Java key store) file. For the sake of this example, or for your testing, we won't use real SSL certificates, we are going to create a self signed certificate. Remember, we'll do with a self-signed certificate for example convenience, but if you deploy this to a server, use a real one! keytool -genkey -keyalg RSA -alias selfsigned -keystore keystore.jks -storepass readonlyrest -validity 360 -keysize 2048 Now copy the keystore.jks inside the plugin directory inside the Elasticsearch home. cp keystore.jks /elasticsearch/config/ IMPORTANT: to enable ReadonlyREST's SSL stack, open elasticsearch.yml and append this one line: http.type: ssl_netty4 Step 3 Now We need to create some credentials for logstash to login, let's say user = logstash password = logstash Step 4 Hash the credentials string logstash:logstash using SHA256. The simplest way is to paste the string in an online tool You should have obtained \"280ac6f756a64a80143447c980289e7e4c6918b92588c8095c7c3f049a13fbf9\". Step 5 Let's add some configuration to our Elasticsearch: edit conf/readonlyrest.yml and append the following lines: readonlyrest: ssl: enable: true # keystore in the same dir with readonlyrest.yml keystore_file: \"keystore.jks\" keystore_pass: readonlyrest key_pass: readonlyrest response_if_req_forbidden: Forbidden by ReadonlyREST ES plugin access_control_rules: - name: \"::LOGSTASH::\" auth_key_sha256: \"280ac6f756a64a80143447c980289e7e4c6918b92588c8095c7c3f049a13fbf9\" #logstash:logstash actions: [\"cluster:monitor/main\",\"indices:admin/types/exists\",\"indices:data/read/*\",\"indices:data/write/*\",\"indices:admin/template/*\",\"indices:admin/create\"] indices: [\"logstash-*\"] Logstash side Edit the logstash configuration file and fix the output block as follows: output { elasticsearch { ssl => true ssl_certificate_verification => false hosts => [\"YOUR_ELASTICSEARCH_HOST:9200\"] user => logstash password => logstash } } The ssl_certificate_verification bit is necessary for accepting self-signed SSL certificates. You might also need to add cacert parameter to provide the path to your .cer or .pem file. Secure Metricbeats Very similarly to Logstaash, here's a snippet of configuration for Metricbeats logging agent configuration of metricbeat - elasticsearch section On the Metricbeats side output.elasticsearch: output.elasticsearch: username: metricbeat password: hereyourpasswordformetricbeat protocol: https hosts: [\"xx.xx.xx.xx:9200\"] worker: 1 index: \"log_metricbeat-%{+yyyy.MM}\" template.enabled: false template.versions.2x.enabled: false ssl.enabled: true ssl.certificate_authorities: [\"./certs/your-rootca_cert.pem\"] ssl.certificate: \"./certs/your_srv_cert.pem\" ssl.key: \"./certs/your_srv_key.pem\" Of course, if you do not use ssl, disable it. On the Elasticsearch side readonlyrest: ssl: enable: true # keystore in the same dir with elasticsearch.yml keystore_file: \"keystore.jks\" keystore_pass: readonlyrest key_pass: readonlyrest access_control_rules: - name: \"metricbeat can write and create its own indices\" auth_key_sha1: fd2e44724a234234454324253094080986e8fda actions: [\"indices:data/read/*\",\"indices:data/write/*\",\"indices:admin/template/*\",\"indices:admin/create\"] indices: [\"metricbeat-*\", \"log_metricbeat*\"]","title":"For Elasticsearch"},{"location":"elasticsearch/#for-elasticsearch","text":"","title":"For Elasticsearch"},{"location":"elasticsearch/#overview-the-readonlyrest-suite","text":"ReadonlyREST is a light weight Elasticsearch plugin that adds encryption, authentication, authorization and access control capabilities to Elasticsearch embedded REST API. The core of this plugin is an ACL engine that checks each incoming request through a sequence of rules a bit like a firewall. There are a dozen rules that can be grouped in sequences of blocks and form a powerful representation of a logic chain. The Elasticsearch plugin known as ReadonlyREST Free is released under the GPLv3 license, or alternatively, a commercial license (see ReadonlyREST Embedded ) and lays the technological foundations for the companion Kibana plugin which is released in two versions: ReadonlyREST PRO and ReadonlyREST Enterprise . Unlike the Elasticsearch plugin, the Kibana plugins are commercial only. But rely on the Elasticsearch plugin in order to work. For a description of the Kibana plugins, skip to the dedicated documentation page instead.","title":"Overview: The ReadonlyREST Suite"},{"location":"elasticsearch/#readonlyrest-free-plugin-for-elasticsearch","text":"In this document we are going to describe how to operate the Elasticsearch plugin in all its features. Once installed, this plugin will greatly extend the Elasticsearch HTTP API (port 9200), adding numerous extra capabilities: Encryption : transform the Elasticsearch API from HTTP to HTTPS Authentication : require credentials Authorization : declare groups of users, permissions and partial access to indices. Access control : complex logic can be modeled using an ACL (access control list) written in YAML. Audit logs : a trace of the access requests can be logged to file or index (or both).","title":"ReadonlyREST Free plugin for Elasticsearch"},{"location":"elasticsearch/#flow-of-a-search-request","text":"The following diagram models an instance of Elasticsearch with the ReadonlyREST plugin installed, and configured with SSL encryption and an ACL with at least one \"allow\" type ACL block. The User Agent (i.e. cURL, Kibana) sends a search request to Elasticsearch using the port 9200 and the HTTPS URL schema. The HTTPS filter in ReadonlyREST plugin unwraps the SSL layer and hands over the request to Elasticsearch HTTP stack The HTTP stack in Elasticsearch parses the HTTP request The HTTP handler in Elasticsearch extracts the indices, action, request type and creates a SearchRequest (internal Elasticsearch format). The SearchRequest goes through the ACL (access control list), external systems like LDAP can be asynchronously queried, and an exit result is eventually produced. The exit result is used by the audit log serializer, to write a record to index and/or Elasticsearch log file If no ACL block was matched, or if a type: forbid block was matched, ReadonlyREST does not forward the search request to the search engine, and creates an \"unauthorized\" HTTP response. In case the ACL matched an type: allow block, the request is forwarded to the search engine The Elasticsearch code creates a search response containing the results of the query 10.The search response is converted to an HTTP response by the Elasticsearch code The HTTP response flows back to ReadonlyREST's HTTPS filter and to the User agent","title":"Flow of a Search Request"},{"location":"elasticsearch/#installing-the-plugin","text":"To install ReadonlyREST plugin for Elasticsearch:","title":"Installing the plugin"},{"location":"elasticsearch/#1-obtain-the-build","text":"From the official download page . Select your Elasticsearch version and send yourself a link to the compatible ReadonlyREST zip file.","title":"1. Obtain the build"},{"location":"elasticsearch/#2-install-the-build","text":"bin/elasticsearch-plugin install file:///tmp/readonlyrest-X.Y.Z_esW.Q.U.zip Notice how we need to type in the format file:// + absolute path (yes, with three slashes). @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ @ WARNING: plugin requires additional permissions @ @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ When prompted about additional permissions, answer y .","title":"2. Install the build"},{"location":"elasticsearch/#3-patch-elasticsearch","text":"If you are using Elasticsearch 8.0.x or newer, you need an extra post-installation step . Depending on the Elasticsearch version , this command might tweak the main Elasticsearch installation files and/or copy some jars to plugins/readonlyrest directory. # Patch ES $ jdk/bin/java -jar plugins/readonlyrest/ror-tools.jar patch \u26a0\ufe0fIMPORTANT : for Elasticsearch 8.3.x or newer, the patching operation requires root user privileges. You can verify if Elasticsearch was correctly patched using command verify : $ jdk/bin/java -jar plugins/readonlyrest/ror-tools.jar verify Please note that the tool assumes that you run it from the root of your ES installation directory or the default installation directory is /usr/share/elasticsearch . But if you want or need, you can instruct it where your Elasticsearch is installed by executing one of tool's command with --es-path parameter: $ jdk/bin/java -jar plugins/readonlyrest/ror-tools.jar patch --es-path /my/custom/path/to/es/folder or $ jdk/bin/java -jar plugins/readonlyrest/ror-tools.jar verify --es-path /my/custom/path/to/es/folder NB: In case of any problems with the ror-tools , please call: $ jdk/bin/java -jar plugins/readonlyrest/ror-tools.jar --help","title":"3. Patch Elasticsearch"},{"location":"elasticsearch/#4create-settings-file","text":"Create and edit the readonlyrest.yml settings file in the same directory where elasticsearch.yml is found : vim $ES_PATH_CONF/conf/readonlyrest.yml Now write some basic settings, just to get started. In this example we are going to tell ReadonlyREST to require HTTP Basic Authentication for all the HTTP requests, and return 401 Unauthorized otherwise. readonlyrest: access_control_rules: - name: \"Require HTTP Basic Auth\" type: allow auth_key: user:password","title":"4.Create settings file"},{"location":"elasticsearch/#5-disable-x-pack-security-module","text":"(applies to ES 6.4.0 or greater) ReadonlyREST and X-Pack security module can't run together, so the latter needs to be disabled. Edit elasticsearch.yml and append xpack.security.enabled: false . vim $ES_PATH_CONF/conf/elasticsearch.yml","title":"5. Disable X-Pack security module"},{"location":"elasticsearch/#6-start-elasticsearch","text":"bin/elasticsearch or: service start elasticsearch Depending on your environment. Now you should be able to see the logs and ReadonlyREST related lines like the one below: [2018-09-18T13:56:25,275][INFO ][o.e.p.PluginsService ] [c3RKGFJ] loaded plugin [readonlyrest]","title":"6. Start Elasticsearch"},{"location":"elasticsearch/#7-test-everything-is-working","text":"The following command should succeed, and the response should show a status code 200. curl -vvv -u user:password \"http://localhost:9200/_cat/indices\" The following command should not succeed, and the response should show a status code 401 curl -vvv \"http://localhost:9200/_cat/indices\"","title":"7. Test everything is working"},{"location":"elasticsearch/#upgrading-the-plugin","text":"To upgrade ReadonlyREST for Elasticsearch:","title":"Upgrading the plugin"},{"location":"elasticsearch/#1-stop-elasticsearch","text":"Either kill the process manually, or use: service stop elasticsearch depending on your environment.","title":"1. Stop Elasticsearch."},{"location":"elasticsearch/#2-unpatch-elasticsearch","text":"If you are using Elasticsearch 8.0.x or newer, you need an extra pre-uninstallation step . This will remove all previously copied jars from ROR's installation directory. # Unpatch ES $ jdk/bin/java -jar plugins/readonlyrest/ror-tools.jar unpatch You can verify if Elasticsearch was correctly unpatched using command verify : $ jdk/bin/java -jar plugins/readonlyrest/ror-tools.jar verify NB: In case of any problems with the ror-tools , please call: $ jdk/bin/java -jar plugins/readonlyrest/ror-tools.jar --help","title":"2. Unpatch Elasticsearch"},{"location":"elasticsearch/#3-uninstall-readonlyrest","text":"bin/elasticsearch-plugin remove readonlyrest","title":"3. Uninstall ReadonlyREST"},{"location":"elasticsearch/#4-install-the-new-version-of-readonlyrest-into-elasticsearch","text":"bin/elasticsearch-plugin install file://<download_dir>/readonlyrest-<ROR_VERSION>_es<ES_VERSION>.zip e.g. bin/elasticsearch-plugin install file:///tmp/readonlyrest-1.16.15_es6.1.1.zip","title":"4. Install the new version of ReadonlyREST into Elasticsearch."},{"location":"elasticsearch/#5-patch-elasticsearch","text":"If you are using Elasticsearch 8.0.x or newer, you need an extra post-installation step . Depending on the Elasticsearch version , this command might tweak the main Elasticsearch installation files and/or copy some jars to plugins/readonlyrest directory. # Patch ES $ jdk/bin/java -jar plugins/readonlyrest/ror-tools.jar patch \u26a0\ufe0fIMPORTANT : for Elasticsearch 8.3.x or newer, the patching operation requires root user privileges. You can verify if Elasticsearch was correctly patched using command verify : $ jdk/bin/java -jar plugins/readonlyrest/ror-tools.jar verify NB: In case of any problems with the ror-tools , please call: $ jdk/bin/java -jar plugins/readonlyrest/ror-tools.jar --help","title":"5. Patch Elasticsearch"},{"location":"elasticsearch/#6-restart-elasticsearch","text":"bin/elasticsearch or: service start elasticsearch Depending on your environment. Now you should be able to see the logs and ReadonlyREST related lines like the one below: [2018-09-18T13:56:25,275][INFO ][o.e.p.PluginsService ] [c3RKGFJ] loaded plugin [readonlyrest]","title":"6. Restart Elasticsearch."},{"location":"elasticsearch/#removing-the-plugin","text":"","title":"Removing the plugin"},{"location":"elasticsearch/#1-stop-elasticsearch_1","text":"Either kill the process manually, or use: service stop elasticsearch depending on your environment.","title":"1. Stop Elasticsearch."},{"location":"elasticsearch/#2-unpatch-elasticsearch_1","text":"If you are using Elasticsearch 8.0.x or newer, you need an extra pre-uninstallation step . This will remove all previously copied jars from ROR's installation directory. # Unpatch ES $ jdk/bin/java -jar plugins/readonlyrest/ror-tools.jar unpatch You can verify if Elasticsearch was correctly unpatched using command verify : $ jdk/bin/java -jar plugins/readonlyrest/ror-tools.jar verify NB: In case of any problems with the ror-tools , please call: $ jdk/bin/java -jar plugins/readonlyrest/ror-tools.jar --help","title":"2. Unpatch Elasticsearch"},{"location":"elasticsearch/#3-uninstall-readonlyrest-from-elasticsearch","text":"bin/elasticsearch-plugin remove readonlyrest","title":"3. Uninstall ReadonlyREST from Elasticsearch:"},{"location":"elasticsearch/#4-start-elasticsearch","text":"bin/elasticsearch or: service start elasticsearch Depending on your environment.","title":"4. Start Elasticsearch."},{"location":"elasticsearch/#deploying-readonlyrest-in-a-stable-production-cluster","text":"Unless some advanced features are being used (see below),this Elasticsearch plugin operates like a lightweight, stateless filter glued in front of Elasticsearch HTTP API. Therefore it's sufficient to install the plugin only in the nodes that expose the HTTP interface (port 9200). Installing ReadonlyREST in a dedicated node has numerous advantages: No need to restart all nodes, only the one you have installed the plugin into. No need to restart all nodes for updating the security settings No need to restart all nodes when a security update is out Less complexity on the actual cluster nodes. For example, if we want to move to HTTPS all the traffic coming from Logstash into a 9 nodes Elasticsearch cluster which has been running stable in production for a while, it's not necessary to install ReadonlyREST plugin in all the nodes. Creating a dedicated, lightweight ES node where to install ReadonlyREST: (Optional) disable the HTTP interface from all the existing nodes Create a new, lightweight, dedicated node without shards, nor master eligibility. Configure ReadonlyREST with SSL encryption in the new node Configure Logstash to connect to the new node directly in HTTPS.","title":"Deploying ReadonlyREST in a stable production cluster"},{"location":"elasticsearch/#an-exception","text":"\u26a0\ufe0fIMPORTANT By default when fields rule is used, it's required to install ReadonlyREST plugin in all the data nodes.","title":"An exception"},{"location":"elasticsearch/#acl-basics","text":"The core of this plugin is an ACL (access control list). A logic structure very similar to the one found in firewalls. The ACL is part of the plugin configuration, and it's written in YAML. The ACL is composed of an ordered sequence of named blocks Each block contains some rules , and a policy (forbid or allow) HTTP requests run through the blocks, starting from the first, The first block that satisfies all the rules decides if to forbid or allow the request (according to its policy). If none of the block match, the request is rejected \u26a0\ufe0fIMPORTANT : The ACL blocks are evaluated sequentially , therefore the ordering of the ACL blocks is crucial . The order of the rules inside an ACL block instead, is irrelevant. readonlyrest: access_control_rules: - name: \"Block 1 - only Logstash indices are accessible\" type: allow # <-- default policy type is \"allow\", so this line could be omitted indices: [\"logstash-*\"] # <-- This is a rule - name: \"Block 2 - Blocking everything from a network\" type: forbid hosts: [\"10.0.0.0/24\"] # <-- this is a rule An Example of Access Control List (ACL) made of 2 blocks. The YAML snippet above, like all of this plugin's settings should be saved inside the readonlyrest.yml file. Create this file on the same path where elasticsearch.yml is found . TIP : If you are a subscriber of the PRO or Enterprise Kibana plugin, you can edit and refresh the settings through a GUI. For more on this, see the documentation for ReadonlyREST plugin for Kibana .","title":"ACL basics"},{"location":"elasticsearch/#encryption","text":"An SSL encrypted connection is a prerequisite for secure exchange of credentials and data over the network. To make use of it you need to have certificate and private key. Letsencrypt certificates work just fine (see tutorial below). Both files, certificate and private key, have to be placed inside PKCS#12 or JKS keystore. See the tutorial at the end of this section. ReadonlyREST can be configured to encrypt network traffic on two independent levels: 1. HTTP (port 9200) 2. Internode communication - transport module (port 9300) An Elasticsearch node with ReadonlyREST can join an existing cluster based on native SSL from xpack.security module. This configuration is useful to deploy ReadonlyREST Enterprise for Kibana to an existing large production cluster without disrupting any configuration. More on this in the dedicated paragraph of this section.","title":"Encryption"},{"location":"elasticsearch/#external-rest-api","text":"It wraps connection between client and exposed REST API in SSL context, hence making it encrypted and secure. \u26a0\ufe0fIMPORTANT: To enable SSL for REST API, open elasticsearch.yml and append this one line: http.type: ssl_netty4 Now in readonlyrest.yml add the following settings: readonlyrest: ssl: keystore_file: \"keystore.jks\" # or keystore.p12 for PKCS#12 format keystore_pass: readonlyrest key_pass: readonlyrest The keystore should be stored in the same directory with elasticsearch.yml and readonlyrest.yml .","title":"External REST API"},{"location":"elasticsearch/#internode-communication-transport-module","text":"This option encrypts communication between nodes forming Elasticsearch cluster. \u26a0\ufe0fIMPORTANT: To enable SSL for internode communication open elasticsearch.yml and append this one line: transport.type: ror_ssl_internode In readonlyrest.yml following settings must be added (it's just example configuration presenting most important properties): readonlyrest: ssl_internode: keystore_file: \"keystore.jks\" # or keystore.p12 for PKCS#12 format keystore_pass: readonlyrest key_pass: readonlyrest Similar to ssl for HTTP, the keystore should be stored in the same directory with elasticsearch.yml and readonlyrest.yml . This config must be added to all nodes taking part in encrypted communication within cluster.","title":"Internode communication - transport module"},{"location":"elasticsearch/#internode-communication-with-xpack-nodes","text":"It is possible to set up internode SSL between ROR and XPack nodes. It works only for ES above 6.3. To set up cluster in such configuration you have to generate certificate for ROR node according to this description https://www.elastic.co/guide/en/elasticsearch/reference/current/security-basic-setup.html#generate-certificates. Generated elastic-certificates.p12 could be then used in ROR node with such configuration readonlyrest: ssl_internode: enable: true keystore_file: \"elastic-certificates.p12\" keystore_pass: [ password for generated certificate ] key_pass: [ password for generated certificate ] truststore_file: \"elastic-certificates.p12\" truststore_pass: [ password for generated certificate ] certificate_verification: true # certificate verification is enabled by default on XPack nodes","title":"Internode communication with XPack nodes"},{"location":"elasticsearch/#certificate-verification","text":"By default certificate verification is disabled. It means that certificate is not validated in any way, so all certificates are accepted. It is useful on local/test environment, where security is not the most important concern. On production environment it is adviced to enable this option. It can be done by means of: certificate_verification: true under ssl_internode section. This option is applicable only for internode ssl.","title":"Certificate verification"},{"location":"elasticsearch/#client-authentication","text":"By default the client authentication is disabled. When enabled, the server asks the client about its certificate, so ES is able to verify the client's identity. It can be enabled by means of: client_authentication: true under ssl section. This option is applicable only for REST API external ssl. Both certificate_verification and client_authentication can be enabled with single property verification . Using this property is deprecated and allowed because of backward compatibility support. Specialized properties make configuration more readable and explicit.","title":"Client authentication"},{"location":"elasticsearch/#restrict-ssl-protocols-and-ciphers","text":"Optionally, it's possible to specify a list allowed SSL protocols and SSL ciphers. Connections from clients that don't support the listed protocols or ciphers will be dropped. readonlyrest: ssl: # put the keystore in the same dir with elasticsearch.yml keystore_file: \"keystore.jks\" keystore_pass: readonlyrest key_pass: readonlyrest allowed_protocols: [TLSv1.2] allowed_ciphers: [TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256] ReadonlyREST will log a list of available ciphers and protocols supported by the current JVM at startup. [2018-01-03T10:09:38,683][INFO ][t.b.r.e.SSLTransportNetty4] ROR SSL: Available ciphers: TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA,TLS_RSA_WITH_AES_128_GCM_SHA256,TLS_RSA_WITH_AES_128_CBC_SHA [2018-01-03T10:09:38,684][INFO ][t.b.r.e.SSLTransportNetty4] ROR SSL: Restricting to ciphers: TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256 [2018-01-03T10:09:38,684][INFO ][t.b.r.e.SSLTransportNetty4] ROR SSL: Available SSL protocols: TLSv1,TLSv1.1,TLSv1.2 [2018-01-03T10:09:38,685][INFO ][t.b.r.e.SSLTransportNetty4] ROR SSL: Restricting to SSL protocols: TLSv1.2 [2018-0","title":"Restrict SSL protocols and ciphers"},{"location":"elasticsearch/#custom-truststore","text":"ReadonlyREST allows using custom truststore, replacing (provided by JRE) default one. Custom truststore can be set with: truststore_file: \"truststore.jks\" truststore_pass: truststorepass under ssl or ssl_internode section. This option is applicable for both ssl modes - external ssl and internode ssl. The truststore should be stored in the same directory with elasticsearch.yml and readonlyrest.yml (like keystore). When not specifed, ReadonlyREST uses default truststore.","title":"Custom truststore"},{"location":"elasticsearch/#using-lets-encrypt","text":"We are going to show how to first add all the certificates and private key into PKCS#12 keystore, and then (optionally) converting it to JKS keystore. ReadonlyREST supports both formats. This tutorial can be a useful example on how to use certificates from other providers.","title":"Using Let's encrypt"},{"location":"elasticsearch/#1-create-keys","text":"./letsencrypt-auto certonly --standalone -d DOMAIN.TLD -d DOMAIN_2.TLD --email EMAIL@EMAIL.TLD Now change to the directory (probably /etc/letsencrypt/live/DOMAIN.tld) where the certificates were created.","title":"1. Create keys"},{"location":"elasticsearch/#2-create-a-pkcs12-file-with-the-full-chain-and-private-key","text":"openssl pkcs12 -export -in fullchain.pem -inkey privkey.pem -out pkcs.p12 -name NAME","title":"2. Create a PKCS12 file with the full chain and private key"},{"location":"elasticsearch/#3-convert-pkcs12-to-jks-keystore-optional","text":"The STORE_PASS is the password which was entered in step 2) as a password for the pkcs12 file. keytool -importkeystore -deststorepass PASSWORD_STORE -destkeypass PASSWORD_KEYPASS -destkeystore keystore.jks -srckeystore pkcs.p12 -srcstoretype PKCS12 -srcstorepass STORE_PASS -alias NAME If you happen to get a java.io.IOException: failed to decrypt safe contents entry: javax.crypto.BadPaddingException: Given final block not properly padded , you have probably forgotten to enter the correct password from step 2. (Credits for the original JKS tutorial to Maximilian Boehm )","title":"3. Convert PKCS12 to JKS Keystore (Optional)"},{"location":"elasticsearch/#blocks-of-rules","text":"Every block must have at least the name field, and optionally a type field valued either \"allow\" or \"forbid\". If you omit the type , your block will be treated as type: allow by default. Keep in mind that ReadonlyREST ACL is a white list, so by default all request are blocked, unless you specify a block of rules that allowes all or some requests. name will appear in logs, so keep it short and distinctive. type can be either allow or forbid . Can be omitted, default is allow . - name: \"Block 1 - Allowing anything from localhost\" type: allow # In real life now you should increase the specificity by adding rules here (otherwise this block will allow all requests!) Example: the simplest example of an allow block. \u26a0\ufe0fIMPORTANT : if no blocks are configured, ReadonlyREST rejects all requests.","title":"Blocks of rules"},{"location":"elasticsearch/#rules","text":"ReadonlyREST access control rules allow to take decisions on three levels: Network level HTTP level Elasticsearch level Please refrain from using HTTP level rules to protect certain indices or limit what people can do to an index. The level of control at this level is really coarse, especially because Elasticsearch REST API does not always respect RESTful principles. This makes of HTTP a bad abstraction level to write ACLs in Elasticsearch all together. The only clean and exhaustive way to implement access control is to reason about requests AFTER ElasticSearch has parsed them. Only then, the list of affected indices and the action will be known for sure. See Elasticsearch level rules.","title":"Rules"},{"location":"elasticsearch/#transport-level-rules","text":"These are the most basic rules. It is possible to allow/forbid requests originating from a list of IP addresses, host names or IP networks (in slash notation).","title":"Transport level rules"},{"location":"elasticsearch/#hosts","text":"hosts: [\"10.0.0.0/24\"] Match a request whose origin IP address (also called origin address, or OA in logs) matches one of the specified IP addresses or subnets.","title":"hosts"},{"location":"elasticsearch/#hosts_local","text":"hosts_local: [\"127.0.0.1\", \"127.0.0.2\"] Match a request whose destination IP address (called DA in logs) matches one of the specified IP addresses or subnets. This finds application when Elasticsearch HTTP API is bound to multiple IP addresses.","title":"hosts_local"},{"location":"elasticsearch/#http-level-rules","text":"","title":"HTTP Level rules"},{"location":"elasticsearch/#accept_x-forwarded-for_header","text":"accept_x-forwarded-for_header: false \u26a0\ufe0fDEPRECATED (use x_forwarded_for instead ) A modifier for hosts rule: if the origin IP won't match, fallback to check the X-Forwarded-For header","title":"accept_x-forwarded-for_header"},{"location":"elasticsearch/#x_forwarded_for","text":"x_forwarded_for: [\"192.168.1.0/24\"] Behaves exactly like hosts , but gets the source IP address (a.k.a. origin address, OA in logs) inside the X-Forwarded-For header only (useful replacement to hosts rule when requests come through a load balancer like AWS ELB) Load balancers This is a nice tip if your Elasticsearch is behind a load balancer. If you want to match all the requests that come through the load balancer, use x_forwarded_for: [\"0.0.0.0/0\"] . This will match the requests with a valid IP address as a value of the X-Forwarded-For header. DNS lookup caching It's worth to note that resolutions of DNS are going to be cached by JVM. By default successfully resolved IPs will be cached forever (until Elasticsearch is restarted) for security reasons. However, this may not always be the desired behaviour, and it can be changed by adding the following JVM options either in the jvm.options file or declaring the ES_JAVA_OPTS environment variable: sun.net.inetaddr.ttl=TTL_VALUE (or/and sun.net.inetaddr.negative.ttl=TTL_VALUE ). More details about the problem can be found here .","title":"x_forwarded_for"},{"location":"elasticsearch/#methods","text":"methods: [GET, DELETE] Match requests with HTTP methods specified in the list. N.B. Elasticsearch HTTP stack does not make any difference between HEAD and GET, so all the HEAD request will appear as GET.","title":"methods"},{"location":"elasticsearch/#headers","text":"headers: [\"h1:x*y\",\"~h2:*xy\"] Match if all the HTTP headers in the request match the defined patterns in headers rule. This is useful in conjunction with proxy_auth , to carry authorization information (i.e. headers: x-usr-group: admins ). The ~ sign is a pattern negation, so eg. ~h2:*xy means: match if h2 header's value does not match the pattern *xy, or h2 is not present at all.","title":"headers"},{"location":"elasticsearch/#headers_and","text":"headers_and: [\"hdr1:val_*xyz\",\"~hdr2:xyz_*\"] Alias for headers rule","title":"headers_and"},{"location":"elasticsearch/#headers_or","text":"headers_or: [\"x-myheader:val*\",\"~header2:*xy\"] Match if at least one the specified HTTP headers key:value pairs is matched.","title":"headers_or"},{"location":"elasticsearch/#uri_re","text":"uri_re: [\"^/secret-index/.*\", \"^/some-index/.*\"] \u2620\ufe0fHACKY (try to use indices/actions rule instead) Match if at least one specifed regular expression matches requested URI.","title":"uri_re"},{"location":"elasticsearch/#maxbodylength","text":"maxBodyLength: 0 Match requests having a request body length less or equal to an integer. Use 0 to match only requests without body. NB : Elasticsearch HTTP API breaks the specifications, nad GET requests might have a body length greater than zero.","title":"maxBodyLength"},{"location":"elasticsearch/#api_keys","text":"api_keys: [123456, abcdefg] A list of api keys expected in the header X-Api-Key","title":"api_keys"},{"location":"elasticsearch/#elasticsearch-level-rules","text":"","title":"Elasticsearch level rules"},{"location":"elasticsearch/#indices","text":"indices: [\"sales\", \"logstash-*\"] Matches if the request involves a set of indices whose name is \"sales\", or starts with the string \"logstash-\", or a combination of both. If a request involves a wildcard (i.e. \"logstash-*\", \"*\"), this is first expanded to the list of available indices, and then treated normally as follows: Requests that do not involve any indices (cluster admin, etc) result in a \"match\". Requests that involve only allowed indices result in a \"match\". Requests that involve a mix of allowed and prohibited indices, are rewritten to only involve allowed indices, and result in a \"match\". Requests that involve only prohibited indices result in a \"no match\". And the ACL evaluation moves on to the next block. The rejection message and HTTP status code returned to the requester are chosen carefully with the main intent to make ES behave like the prohibited indices do not exist at all. The rule has also an extended version: indices: patterns: [\"sales\", \"logstash-*\"]` must_involve_indices: false The definition above has the same meaning as the shortest version shown at the beginning of this section. By default the rule will be matched when a request doesn't involve indices (eg. /_cat/nodes request). But we can change the behaviour by configuring must_involve_indices: true - in this case the request above will be rejected by the rule. In detail, with examples In ReadonlyREST we roughly classify requests as: \"read\": the request will not change the data or the configuration of the cluster \"write\": when allowed, the request changes the internal state of the cluster or the data. If a read request asks for a some indices they have permissions for and some indices that they do NOT have permission for, the request is rewritten to involve only the subset of indices they have permission for. This is behaviour is very useful in Kibana: different users can see the same dashboards with data from only their own indices. When the subset of indices is empty, it means that user are not allowed to access requested indices. In multitenancy environment we should consider two options: requested indices don't exist requested indices exist but logged user is not authorized to access them For both of these cases ROR is going to return HTTP 404 or HTTP 200 with an empty response. The same behaviour will be observed for ES with ROR disabled (for nonexistent index). If an index does exist, but a user is not authorized to access it, ROR is going to pretend that the index doesn't exist and a response will be the same like the index actually did not exist. See detailed example . It's also worth mentioning, that when prompt_for_basic_auth is set to true (that is, the default value), ROR is going to return 401 instead of 404 HTTP status code. It is relevant for users who don't use ROR Kibana's plugin and who would like to take advantage of default Kibana's behaviour which shows the native browser basic auth dialog, when it receives HTTP 401 response. If a write request wants to write to indices they don't have permission for, the write request is rejected. Requests related to templates Templates are also connected with indices, but rather indirectly. An index template has index patterns and could also have aliases. During an index template creation or modification, ROR checks if index patterns and aliases, defined in a request body, are allowed. When a user tries to remove or get template by name, ROR checks if the template can be considered as allowed for the user, and based on that information, it allows/forbids to remove or see it. See details .","title":"indices"},{"location":"elasticsearch/#actions","text":"actions: [\"indices:data/read/*\"] Match if the request action starts with \"indices:data/read/\". In Elasticsearch, each request carries only one action. We extracted from Elasticsearch source code the full list of valid action strings as of all Elasticsearch versions. Please see the dedicated section to find the actions list of your specific Elasticsearch version . Example actions (see above for the full list): \"cluster:admin/data_frame/delete\" \"cluster:admin/data_frame/preview\" ... \"cluster:monitor/data_frame/stats/get\" \"cluster:monitor/health\" \"cluster:monitor/main\" \"cluster:monitor/nodes/hot_threads\" \"cluster:monitor/nodes/info\" ... \"indices:admin/aliases\" \"indices:admin/aliases/get\" \"indices:admin/analyze\" ... \"indices:data/read/get\" \"indices:data/read/mget\" \"indices:data/read/msearch\" \"indices:data/read/msearch/template\" ... \"indices:data/write/bulk\" \"indices:data/write/bulk_shard_operations[s]\" \"indices:data/write/delete\" \"indices:data/write/delete/byquery\" \"indices:data/write/index\" \"indices:data/write/reindex\" ... many more...","title":"actions"},{"location":"elasticsearch/#kibana_access","text":"kibana_access: ro Enables the minimum set of actions necessary for browsers to use Kibana. This \"macro\" rule allows the minimum set of actions necessary for a browser to use Kibana. This rule allows a set of actions towards the designated kibana index (see kibana_index rule - defaults to \".kibana\"), plus a stricter subset of read-only actions towards other indices, which are considered \"data indices\". The idea is that with one single rule we allow the bare minimum set of index+action combinations necessary to support a Kibana browsing session. Possible access levels: ro_strict : the browser has a read-only view on Kibana dashboards and settings and all other indices. ro : some write requests can go through to the .kibana index so that UI state in discover can be saved and short urls can be created. rw : some more actions will be allowed towards the .kibana index only, so Kibana dashboards and settings can be modified. admin : like above, but has additional permissions to use the ReadonlyREST PRO/Enterprise Kibana app. NB: The \"admin\" access level does not mean the user will be allowed to access all indices/actions. It's just like \"rw\" with settings changes privileges. If you want really unrestricted access for your Kibana user, including ReadonlyREST PRO/Enterprise app, set kibana_access: unrestricted . You can use this rule with the users rule to restrict access to selected admins. This rule is often used with the indices rule, to limit the data a user is able to see represented on the dashboards. In that case do not forget to allow the custom kibana index in the indices rule!","title":"kibana_access"},{"location":"elasticsearch/#kibana_index","text":"kibana_index: .kibana-user1 Default value is .kibana Specify to what index we expect Kibana to attempt to read/write its settings (use this together with kibana.index setting in kibana.yml.) This value directly affects how kibana_access works because at all the access levels (yes, even admin), kibana_access rule will not maatch any write request in indices that are not the designated kibana index. If used in conjunction with ReadonlyREST Enterprise, this rule enables multi tenancy , because in ReadonlyREST, a tenancy is identified with a set of Kibana configurations, which are by design collected inside a kibana index (default: .kibana ).","title":"kibana_index"},{"location":"elasticsearch/#snapshots","text":"snapshots: [\"snap_@{user}_*\"] Restrict what snapshots names can be saved or restored","title":"snapshots"},{"location":"elasticsearch/#repositories","text":"repositories: [\"repo_@{user}_*\"] Restrict what repositories can snapshots be saved into","title":"repositories"},{"location":"elasticsearch/#filter","text":"filter: '{\"query_string\":{\"query\":\"user:@{user}\"}}' This rule enables Document Level Security (DLS) . That is: return only the documents that satisfy the boolean query provided as an argument. This rule lets you filter the results of a read request using a boolean query. You can use dynamic variables i.e. @{user} (see dedicated paragraph) to inject a user name or some header values in the query, or even environmental variables. Example: per-user index segmentation In the index \"test-dls\", each user can only search documents whose field \"user\" matches their user name. I.e. A user with username \"paul\" requesting all documents in \"test-dls\" index, won't see returned a document containing a field \"user\": \"jeff\" . - name: \"::PER-USER INDEX SEGMENTATION::\" proxy_auth: \"*\" indices: [\"test-dls\"] filter: '{\"bool\": { \"must\": { \"match\": { \"user\": \"@{user}\" }}}}' Example 2: Prevent search of \"classified\" documents. In this example, we want to avoid that users belonging to group \"press\" can see any document that has a field \"access_level\" with the value \"CLASSIFIED\". And this policy is applied to all indices (no indices rule is specified). - name: \"::Press::\" groups: [\"press\"] filter: '{\"bool\": { \"must_not\": { \"match\": { \"access_level\": \"CLASSIFIED\" }}}}' \u26a0\ufe0fIMPORTANT The filter and fields rules will only affect \"read\" requests, therefore \"write\" requests will not match because otherwise it would implicitly allow clients to \"write\" without the filtering restriction. For reference, this behaviour is identical to x-pack and search guard. \u26a0\ufe0fIMPORTANT Beginning with version 1.27.0 all ROR internal requests from kibana will not match blocks containing filter and/or fields rules. There requests are used to perform kibana login and dynamic config reload. If you want to allow write requests (i.e. for Kibana sessions), just duplicate the ACL block, have the first one with filter and/or fields rule, and the second one without.","title":"filter"},{"location":"elasticsearch/#fields","text":"This rule enables Field Level Security (FLS) . That is: for responses where fields with values are returned (e.g. Search/Get API) - filter and show only allowed fields make not allowed fields unsearchable - used in QueryDSL requests (e.g. Search/MSearch API) do not have impact on search result. In other words: FLS protects from usage some not allowed fields for a certain user. From user's perspective it seems like such fields are nonexistent. Definition Field rule definition consists of two parts: A non empty list of fields (blacklisted or whitelisted) names. Supports wildcards and user runtime variables. The FLS engine definition (global setting, optional). See: engine details . \u26a0\ufe0fIMPORTANT With default FLS engine it's required to install ReadonlyREST plugin in all the data nodes. Different configurations allowing to avoid such requirement are described in engine details . Field names Fields can be defined using two access modes: blacklist and whitelist. Blacklist mode (recommended) Specifies which fields should not be allowed prefixed with ~ (other fields from mapping become allowed implicitly). Example: fields: [\"~excluded_fields_prefix_*\", \"~excluded_field\", \"~another_excluded_field.nested_field\"] Return documents but deprived of the fields that: start with excluded_fields_prefix_ are equal to excluded_field are equal to another_excluded_field.nested_field Whitelist mode Specifies which fields should be allowed explicitly (other fields from mapping become not allowed implicitly). Example: fields: [\"allowed_fields_prefix_*\", \"_*\", \"allowed_field.nested_field.text\"] Return documents deprived of all the fields, except the ones that: start with allowed_fields_prefix_ start with underscore are equal to allowed_field.nested_field.text NB: You can only provide a full black list or white list. Grey lists (i.e. [\"~a\", \"b\"] ) are invalid settings and ROR will refuse to boot up if this condition is detected. Example: hide prices from catalogue indices - name: \"External users - hide prices\" fields: [\"~price\"] indices: [\"catalogue_*\"] \u26a0\ufe0fIMPORTANT Any metadata fields e.g. _id or _index can not be used in fields rule. \u26a0\ufe0fIMPORTANT The filter and fields rules will only affect \"read\" requests, therefore \"write\" requests will not match because otherwise it would implicitly allow clients to \"write\" without the filtering restriction. For reference, this behaviour is identical to x-pack and search guard. \u26a0\ufe0fIMPORTANT Beginning with version 1.27.0 all ROR internal requests from kibana will not match blocks containing filter and/or fields rules. There requests are used to perform kibana login and dynamic config reload. If you want to allow write requests (i.e. for Kibana sessions), just duplicate the ACL block, have the first one with filter and/or fields rule, and the second one without.","title":"fields"},{"location":"elasticsearch/#configuring-an-acl-with-filterfields-rules-when-using-kibana","text":"A normal Kibana session interacts with Elasticsearch using a mix of actions which we can roughly group in two macro categories of \"read\" and \"write\" actions. However the fields and filter rules will only match read requests . They will also block ROR internal request used to log in to kibana and reload config. This means that a complete Kibana session cannot anymore be entirely matched by a single ACL block like it normally would. For example, this ACL block would perfectly support a complete Kibana session. That is, 100% of the actions (browser HTTP requests) would be allowed by this ACL block. - name: \"::RW_USER::\" auth_key: rw_user:pwd kibana_access: rw indices: [\"r*\", \".kibana\"] However, when we introduce a filter (or fields) rule, this block will be able to match only some of the actions (only the \"read\" ones). - name: \"::RW_USER::\" auth_key: rw_user:pwd kibana_access: rw # <-- won't work because of filter present in block indices: [\"r*\", \".kibana\"] filter: '{\"query_string\":{\"query\":\"DestCountry:FR\"}}' # <-- will reject all write requests! :( The solution is to duplicate the block. The first one will intercept (and filter!) the read requests. The second one will intercept the remaining actions. Both ACL blocks together will entirely support a whole Kibana session. - name: \"::RW_USER (filter read requests)::\" auth_key: rw_user:pwd indices: [\"r*\"] # <-- DO NOT FILTER THE .kibana INDEX! filter: '{\"query_string\":{\"query\":\"DestCountry:FR\"}}' - name: \"::RW_USER (allow remaining requests)::\" auth_key: rw_user:pwd kibana_access: rw indices: [\"r*\", \".kibana\"] NB: Look at how we make sure that the requests to \".kibana\" won't get filtered by specifying an indices rule in the first block. Here is another example, a bit more complex. Look at how we can duplicate the \"PERSONAL_GRP\" ACL block so that the read requests to the \"r*\" indices can be filtered, and all the other requests can be intercepted by the second rule (which is identical to the one we had before the duplication). Before adding the filter rule: - name: \"::PERSONAL_GRP::\" groups: [\"Personal\"] kibana_access: rw indices: [\"r*\", \".kibana_@{user}\"] kibana_hide_apps: [\"readonlyrest_kbn\", \"timelion\"] kibana_index: \".kibana_@{user}\" After adding the filter rule (using the block duplication strategy). - name: \"::PERSONAL_GRP (FILTERED SEARCH)::\" groups: [\"Personal\"] indices: [ \"r*\" ] filter: '{\"query_string\":{\"query\":\"DestCountry:FR\"}}' - name: \"::PERSONAL_GRP::\" groups: [\"Personal\"] kibana_access: rw indices: [\"r*\", \".kibana_@{user}\"] kibana_hide_apps: [\"readonlyrest_kbn\", \"timelion\"] kibana_index: \".kibana_@{user}\"","title":"Configuring an ACL with filter/fields rules when using Kibana"},{"location":"elasticsearch/#response_fields","text":"This rule allows filtering Elasticsearch responses using a list of fields. It works in very similar way to fields rule. In contrast to fields rule, which filters out document fields, this rule filters out response fields. It doesn't make use of Field Level Security (FLS) and can be applied to every response returned by Elasticsearch. It can be configured in two modes: whitelist allowing only the defined fields from the response object blacklist filtering out (removing) only the defined fields from the response object Blacklist mode Specifies which fields should be filtered out by adding the ~ prefix to the field name. Other fields in the response will be implicitly allowed. For example: response_fields: [\"~excluded_fields_prefix_*\", \"~excluded_field\", \"~another_excluded_field.nested_field\"] The above will return the usual response object, but deprived (if found) of the fields that: start with excluded_fields_prefix_ are equal to excluded_field are equal to another_excluded_field.nested_field Whitelist mode In this mode rule is configured to filter out each field that isn't defined in the rule. response_fields: [\"allowed_fields_prefix_*\", \"_*\", \"allowed_field.nested_field.text\"] Return response deprived of all the fields, except the ones that: start with allowed_fields_prefix_ start with underscore are equal to allowed_field.nested_field.text NB: You can only provide a full black list or white list. Grey lists (i.e. [\"~a\", \"b\"] ) are invalid settings and ROR will refuse to boot up if this condition is detected. Example : allow only cluster_name and status field in cluster health response: Without any filtering response from /_cluster/health looks more or less like: { \"cluster_name\": \"ROR_SINGLE\", \"status\": \"yellow\", \"timed_out\": false, \"number_of_nodes\": 1, \"number_of_data_nodes\": 1, \"active_primary_shards\": 2, \"active_shards\": 2, \"relocating_shards\": 0, \"initializing_shards\": 0, \"unassigned_shards\": 2, \"delayed_unassigned_shards\": 0, \"number_of_pending_tasks\": 0, \"number_of_in_flight_fetch\": 0, \"task_max_waiting_in_queue_millis\": 0, \"active_shards_percent_as_number\": 50.0 } but after configuring such rule: - name: \"Filter cluster health response\" uri_re: \"^/_cluster/health\" response_fields: [\"cluster_name\", \"status\"] response from above will look like: { \"cluster_name\": \"ROR_SINGLE\", \"status\": \"yellow\" } NB: Any response field can be filtered using this rule.","title":"response_fields"},{"location":"elasticsearch/#authentication","text":"Local ReadonlyREST users are authenticated via HTTP Basic Auth. This authentication method is secure only if SSL is enabled.","title":"Authentication"},{"location":"elasticsearch/#auth_key","text":"auth_key: sales:p455wd Accepts HTTP Basic Auth . Configure this value in clear text . Clients will need to provide the header e.g. Authorization: Basic c2FsZXM6cDQ1NXdk where \"c2FsZXM6cDQ1NXdk\" is Base64 for \"sales:p455wd\". \u26a0\ufe0fIMPORTANT : this rule is handy just for tests, replace it with another rule that hashes credentials, like: auth_key_sha512 , or auth_key_unix . Impersonation is supported by this rule by default.","title":"auth_key"},{"location":"elasticsearch/#auth_key_sha512","text":"auth_key_sha512: 280ac6f...94bf9 Accepts HTTP Basic Auth . The value is a string like username:password hashed in SHA512 . Clients will need to provide the usual Authorization header. There are also available other rules with less secure SHA algorithms auth_key_sha256 and auth_key_sha1 . The rules support also alternative syntax, where only password is hashed, eg: auth_key_sha512: \"admin:280ac6f...94bf9\" In the example below admin is the username and 280ac6f...94bf9 is the hashed secret. Impersonation is supported by these rules by default.","title":"auth_key_sha512"},{"location":"elasticsearch/#auth_key_pbkdf2","text":"auth_key_pbkdf2: \"KhIxF5EEYkH5GPX51zTRIR4cHqhpRVALSmTaWE18mZEL2KqCkRMeMU4GR848mGq4SDtNvsybtJ/sZBuX6oFaSg==\" # logstash:logstash auth_key_pbkdf2: \"logstash:JltDNAoXNtc7MIBs2FYlW0o1f815ucj+bel3drdAk2yOufg2PNfQ51qr0EQ6RSkojw/DzrDLFDeXONumzwKjOA==\" # logstash:logstash Accepts HTTP Basic Auth . The value is hashed in the same way as it's done in auth_key_sha512 rule, but it uses PBKDF2 key derivation function. At the moment there is no way to configure it, so during the hash generation, the user has to take into consideration the following PBKDF2 input parameters values: Input parameter Value Comment Pseudorandom function HmacSHA512 Salt use hashed value as a salt eg. hashed value = logstash:logstash , use logstash:logstash as the salt Iterations count 10000 Derived key length 512 bits The hash can be calculated using this calculator (notice that the salt has to base Base64 encoded). Impersonation is supported by this rule by default.","title":"auth_key_pbkdf2"},{"location":"elasticsearch/#auth_key_unix","text":"auth_key_unix: test:$6$rounds=65535$d07dnv4N$QeErsDT9Mz.ZoEPXW3dwQGL7tzwRz.eOrTBepIwfGEwdUAYSy/NirGoOaNyPx8lqiR6DYRSsDzVvVbhP4Y9wf0 # Hashed for \"test:test\" \u26a0\ufe0fIMPORTANT this hashing algorithm is very CPU intensive , so we implemented a caching mechanism around it. However, this will not protect Elasticsearch from a DoS attack with a high number of requests with random credentials. This method is based on /etc/shadow file syntax. If you configured sha512 encryption with 65535 rounds on your system the hash in /etc/shadow for the account test:test will be test:$6$rounds=65535$d07dnv4N$QeErsDT9Mz.ZoEPXW3dwQGL7tzwRz.eOrTBepIwfGEwdUAYSy/NirGoOaNyPx8lqiR6DYRSsDzVvVbhP4Y9wf0 readonlyrest: access_control_rules: - name: Accept requests from users in group team1 on index1 groups: [\"team1\"] indices: [\"index1\"] users: - username: test auth_key_unix: test:$6$rounds=65535$d07dnv4N$QeErsDT9Mz.ZoEPXW3dwQGL7tzwRz.eOrTBepIwfGEwdUAYSy/NirGoOaNyPx8lqiR6DYRSsDzVvVbhP4Y9wf0 #test:test groups: [\"team1\"] You can generate the hash with mkpasswd Linux command, you need whois package apt-get install whois (or equivalent) mkpasswd -m sha-512 -R 65534 Also you can generate the hash with a python script (works on Linux): #!/usr/bin/python import crypt import random import sys import string def sha512_crypt(password, salt=None, rounds=None): if salt is None: rand = random.SystemRandom() salt = ''.join([rand.choice(string.ascii_letters + string.digits) for _ in range(8)]) prefix = '$6$' if rounds is not None: rounds = max(1000, min(999999999, rounds or 5000)) prefix += 'rounds={0}$'.format(rounds) return crypt.crypt(password, prefix + salt) if __name__ == '__main__': if len(sys.argv) > 1: print sha512_crypt(sys.argv[1], rounds=65635) else: print \"Argument is missing, <password>\" Finally you have to put your username at the begining of the hash with \":\" separator test:$6$rounds=65535$d07dnv4N$QeErsDT9Mz.ZoEPXW3dwQGL7tzwRz.eOrTBepIwfGEwdUAYSy/NirGoOaNyPx8lqiR6DYRSsDzVvVbhP4Y9wf0 For example, test is the username and $6$rounds=65535$d07dnv4N$QeErsDT9Mz.ZoEPXW3dwQGL7tzwRz.eOrTBepIwfGEwdUAYSy/NirGoOaNyPx8lqiR6DYRSsDzVvVbhP4Y9wf0 is the hash for test (the password is identical to the username in this example). Impersonation is supported by this rule by default.","title":"auth_key_unix"},{"location":"elasticsearch/#proxy_auth","text":"proxy_auth: \"*\" Delegated authentication. Trust that a reverse proxy has taken care of authenticating the request and has written the resolved user name into the X-Forwarded-User header. The value \"*\" in the example, will let this rule match any username value contained in the X-Forwarded-User header. If you are using this technique for authentication using our Kibana plugins, don't forget to add this snippet to conf/kibana.yml : readonlyrest_kbn.proxy_auth_passthrough: true So that Kibana will forward the necessary headers to Elasticsearch. Impersonation is supported by this rule by default.","title":"proxy_auth: \"*\""},{"location":"elasticsearch/#users","text":"users: [\"root\", \"*@mydomain.com\"] Limit access to of specific users whose username is contained or matches the patterns in the array. This rule is independent from the authentication method chosen, so it will work well in conjunction LDAP, JWT, proxy_auth, and all others. For example: readonlyrest: access_control_rules: - name: \"JWT auth for viewer group (role), limited to certain usernames\" kibana_access: ro users: [\"root\", \"*@mydomain.com\"] jwt_auth: name: \"jwt_provider_1\" groups: [\"viewer\"]","title":"users"},{"location":"elasticsearch/#groups","text":"groups: [\"group1\", \"group2\"] The ACL block will match when the user belongs to any of the specified groups. The information about what users belong to what groups is defined in the users section, typically situated after the ACL, further down in the YAML. In the users section, each entry tells us that: A given user with a username matching one of patterns in the username array ... belongs to the local groups listed in the groups array (example 1 & 2 below) OR belongs to local groups that are result of \"detailed group mapping\" between local group name and external groups (example 3 below). when they can be authenticated and (if authorization rule is present) authorized by the present rule(s). In general it looks like this: ... - name: \"ACL block with groups rule\" indices: [x, y] groups: [\"local_group1\"] # this group name is defined in the \"users\" section users: - username: [\"pattern1\", \"pattern2\", ...] groups: [\"local_group1\", \"local_group2\", ...] <any_authentication_rule>: ... - username: [\"pattern1\", \"pattern2\", ...] groups: [\"local_group1\", \"local_group2\", ...] <any_authentication_rule>: ... <optionally_any_authorization_rule>: ... - username: [\"pattern1\", \"pattern2\", ...] groups: - local_group1: [\"external_group1\", \"external_group2\"] - local_group2: [\"external_group2\"] <authentication_with_authorization_rule>: ... # `ldap_auth` or `jwt_auth` or `ror_kbn_auth` For details see User management . Impersonation supports depends on authentication and authorization rules used in users section.","title":"groups"},{"location":"elasticsearch/#groups_and","text":"groups_and: [\"group1\", \"group2\"] This rule is identical to the above defined groups rule, but this time ALL the groups listed in the array are required (boolean AND logic), as opposed to at least one (boolean OR logic) of the groups rule.","title":"groups_and"},{"location":"elasticsearch/#session_max_idle","text":"session_max_idle: 1h \u26a0\ufe0fDEPRECATED Browser session timeout (via cookie). Example values 1w (one week), 10s (10 seconds), 7d (7 days), etc. NB: not available for Elasticsearch 2.x.","title":"session_max_idle"},{"location":"elasticsearch/#ldap_authentication","text":"simple version: ldap_authentication: ldap1 extended version: ldap_authentication: name: ldap1 cache_ttl: 10 sec It handles LDAP authentication only using the configured LDAP connector (here ldap1 ). Check the LDAP connector section to see how to configure the connector.","title":"ldap_authentication"},{"location":"elasticsearch/#ldap_authorization","text":"ldap_authorization: name: \"ldap1\" groups: [\"group3\"] cache_ttl: 10 sec It handles LDAP authorization only using the configured LDAP connector (here ldap1 ). It matches when previously authenticated user has groups in LDAP and when he belongs to at least one of the configured groups (OR logic). Alternatively, groups_and can be used to require users belong to all the listed groups (AND logic). Check the LDAP connector section to see how to configure the connector.","title":"ldap_authorization"},{"location":"elasticsearch/#ldap_auth","text":"Shorthand rule that combines ldap_authentication and ldap_authorization rules together. It handles both authentication and authorization using the configured LDAP connector (here ldap1 ). ldap_auth: name: \"ldap1\" groups: [\"group1\", \"group2\"] The same functionality can be achieved using the two rules described below: ldap_authentication: ldap1 ldap_authorization: name: \"ldap1\" groups: [\"group1\", \"group2\"] # match when user belongs to at least one group In both ldap_auth and ldap_authorization , the groups clause can be replaced by group_and to require the valid LDAP user must belong to all the listed groups: ldap_auth: name: \"ldap1\" groups_and: [\"group1\", \"group2\"] # match when user belongs to ALL listed groups Or equivalently: ldap_authentication: ldap1 ldap_authorization: name: \"ldap1\" groups_and: [\"group1\", \"group2\"] # match when user belongs to ALL listed groups See the dedicated LDAP section Impersonation is not supported by default by LDAP rules.","title":"ldap_auth"},{"location":"elasticsearch/#jwt_auth","text":"See below, the dedicated JSON Web Tokens section Impersonation is not supported by this rule by default.","title":"jwt_auth"},{"location":"elasticsearch/#external-basic-auth","text":"Used to delegate authentication to another server that supports HTTP Basic Auth. See below, the dedicated External BASIC Auth section Impersonation is not supported by this rule by default.","title":"external-basic-auth"},{"location":"elasticsearch/#groups_provider_authorization","text":"Used to delegate groups resolution for a user to a JSON microservice. See below, the dedicated Groups Provider Authorization section Impersonation is not supported by this rule by default.","title":"groups_provider_authorization"},{"location":"elasticsearch/#ror_kbn_auth","text":"For Enterprise customers only, required for SAML authentication. readonlyrest: access_control_rules: - name: \"ReadonlyREST Enterprise instance #1\" ror_kbn_auth: name: \"kbn1\" groups: [\"SAML_GRP_1\", \"SAML_GRP_2\"] # <- use this field when a user should belong to at least one of the configured groups - name: \"ReadonlyREST Enterprise instance #1 - two groups required\" ror_kbn_auth: name: \"kbn1\" groups_and: [\"SAML_GRP_1\", \"SAML_GRP_2\"] # <- use this field when a user should belong to all configured groups - name: \"ReadonlyREST Enterprise instance #2\" ror_kbn_auth: name: \"kbn2\" ror_kbn: - name: kbn1 signature_key: \"shared_secret_kibana1\" # <- use environmental variables for better security! - name: kbn2 signature_key: \"shared_secret_kibana2\" # <- use environmental variables for better security! This authentication and authorization connector represents the secure channel (based on JWT tokens) of signed messages necessary for our Enterprise Kibana plugin to securely pass back to ES the username and groups information coming from browser-driven authentication protocols like SAML Continue reading about this in the kibana plugin documentation, in the dedicated SAML section Impersonation is not supported by this rule by default.","title":"ror_kbn_auth"},{"location":"elasticsearch/#ancillary-rules","text":"","title":"Ancillary rules"},{"location":"elasticsearch/#verbosity","text":"verbosity: error Don't spam elasticsearch log file printing log lines for requests that match this block. Defaults to info .","title":"verbosity"},{"location":"elasticsearch/#audit-troubleshooting","text":"The main issues seen in support cases: Bad ordering or ACL blocks. Remember that the ACL is evaluated sequentially, block by block. And the first block whose rules all match is accepted. Users don't know how to read the HIS field in the logs, which instead is crucial because it contains a trace of the evaluation of rules and blocks. LDAP configuration: LDAP is tricky to configure in any system. Configure ES root logger to DEBUG editing $ES_PATH_CONF/config/log4j2.properties to see a trace of the LDAP messages.","title":"Audit &amp; Troubleshooting"},{"location":"elasticsearch/#interpreting-logs","text":"ReadonlyREST prints a log line for each incoming request (this can be selectively avoided on ACL block level using the verbosity rule). Allowed requests This is an example of a request that matched an ACL block (allowed) and has been let through to Elasticsearch. ALLOWED by { name: '::PERSONAL_GRP::', policy: ALLOW} req={ ID:1667655475--1038482600#1312339, TYP:SearchRequest, CGR:N/A, USR:simone, BRS:true, ACT:indices:data/read/search, OA:127.0.0.1, IDX:, MET:GET, PTH:/_search, CNT:<N/A>, HDR:Accept,Authorization,content-length,Content-Type,Host,User-Agent,X-Forwarded-For, HIS:[::PERSONAL_GRP::->[kibana_access->true, kibana_hide_apps->true, auth_key->true, kibana_index->true]], [::Kafka::->[auth_key->false]], [::KIBANA-SRV::->[auth_key->false]], [guest lol->[auth_key->false]], [::LOGSTASH::->[auth_key->false]] } Explanation The log line immediately states that this request has been allowed by an ACL block called \"::PERSONAL_GRP::\". Immediately follows a summary of the requests' anatomy. The format is semi-structured, and it's intended for humans to read quickly, it's not JSON, or anything else. Similar information gets logged in JSON format into Elasticsearch documents enabling the audit logs feature described later. Here is a glossary: ID : ReadonlyREST-level request id TYP : String, the name of the Java class that internally represent the request type (very useful for debug) CGR : String, the request carries a \"current group\" header (used for multi-tenancy). USR : String, the user name ReadonlyREST was able to extract from Basic Auth, JWT, LDAP, or other methods as specified in the ACL. BRS : Boolean, an heuristic attempt to tell if the request comes from a browser. ACT : String, the elasticsearch level action associated with the request. For a list of actions, see our actions rule docs . OA : IP Address, originating address (source address) of the TCP connection underlying the http session. IDX : Strings array: the list of indices affected by this request. MET : String, HTTP Method CNT : String, HTTP body content. Comes as a summary of its lenght, full body of the request is available in debug mode. HDR : String array, list of HTTP headers, headers' content is available in debug mode. HIS : Chronologically ordered history of the ACL blocks and their rules being evaluated, This is super useful for knowing what ACL block/rule is forbidding/allowing this request. In the example, the block ::PERSONAL_GRP:: is allowing the request because all the rules in this block evaluate to true . Forbidden requests This is an example of a request that gets forbidden by ReadonlyREST ACL. FORBIDDEN by default req={ ID:747832602--1038482600#1312150, TYP:SearchRequest, CGR:N/A, USR:[no basic auth header], BRS:true, ACT:indices:data/read/search, OA:127.0.0.1, IDX:, MET:GET, PTH:/_search, CNT:<N/A>, HDR:Accept,content-length,Content-Type,Host,User-Agent,X-Forwarded-For, HIS:[::Infosec::->[groups->false]], [::KIBANA-SRV::->[auth_key->false]], [guest lol->[auth_key->false]], [::LOGSTASH::->[auth_key->false]], [::Infosec::->[groups->false]], [::ADMIN_GRP::->[groups->false]], [::Kafka::->[auth_key->false]], [::PERSONAL_GRP::->[groups->false]] } The above rule gets forbidden \"by default\". This means that no ACL block has matched the request, so ReadonlyREST's default policy of rejection takes effect. Requests finished with INDEX NOT FOUND This is an example of such request: INDEX NOT FOUND req={ ID:501806845-1996085406#74, TYP:GetIndexRequest, CGR:N/A, USR:dev1 (attempted), BRS:true, KDX:null, ACT:indices:admin/get, OA:172.20.0.1/32, XFF:null, DA:172.20.0.2/32, IDX:nonexistent*, MET:GET, PTH:/nonexistent*/_alias/, CNT:<N/A>, HDR:Accept-Encoding=gzip,deflate, Authorization=<OMITTED>, Connection=Keep-Alive, Host=localhost:32773, User-Agent=Apache-HttpClient/4.5.2 (Java/1.8.0_162), content-length=0, HIS:[CONTAINER ADMIN-> RULES:[auth_key->false]], [dev1 indexes-> RULES:[auth_key->true, indices->false], RESOLVED:[user=dev1]], [dev2 aliases-> RULES:[auth_key->false]], [dev3 - no indices rule-> RULES:[auth_key->false]] } The state above is only possible for read-only ES requests (ES requests which don't change ES cluster state) for a block containing an indices rule. If all other rules within the block are matched, but only the indices rule is mismatched, the final state of the block is forbidden due to an index not found.","title":"Interpreting logs"},{"location":"elasticsearch/#audit-logs","text":"ReadonlyREST can write events very similarly to Logstash into to a series of indices named by default readonlyrest_audit-YYYY-MM-DD . Every event contains information about a request and how the system has handled it. Here is an example of the data points contained in each audit event. We can leverage all this information to build interesting Kibana dashboards, or any other visualization. { \"error_message\": null, \"headers\": [ \"Accept\", \"Authorization\", \"content-length\", \"Host\", \"User-Agent\" ], \"acl_history\": \"[[::LOGSTASH::->[auth_key->false]], [::RW::->[kibana_access->true, indices->true, kibana_hide_apps->true, auth_key->true]], [kibana->[auth_key->false]], [::RO::->[auth_key->false]]]\", \"origin\": \"127.0.0.1\", \"final_state\": \"ALLOWED\", \"task_id\": 1158, \"type\": \"SearchRequest\", \"req_method\": \"GET\", \"path\": \"/readonlyrest_audit-2017-06-29/_search?pretty\", \"indices\": [ \"readonlyrest_audit-2017-06-29\" ], \"@timestamp\": \"2017-06-30T09:41:58Z\", \"content_len_kb\": 0, \"error_type\": null, \"processingMillis\": 0, \"action\": \"indices:data/read/search\", \"matched_block\": \"::RW::\", \"id\": \"933409190-292622897#1158\", \"content_len\": 0, \"user\": \"simone\" } Here is a configuration example, you can see the audit.collector: true setting, which normally defaults to false. Note how the successful requests matched by the first rule (Kibana) will not be written to the audit log, because the verbosity is set to error. Audit log in facts, obey the verbosity setting the same way regular text logs do. NB Following audit configurations are presented with the separate audit section, although it can be omitted as settings defined using previous approach (defined directly under readonlyrest section and starting with audit_ )` are still supported (but not recommended) preserving backward compatibility. readonlyrest: audit: collector: true access_control_rules: - name: Kibana type: allow auth_key: kibana:kibana verbosity: error - name: \"::RO::\" auth_key: simone:ro kibana_access: ro","title":"Audit logs"},{"location":"elasticsearch/#extended-audit","text":"If you want to log the request content then an additional serializer is provided. This will log the entire user request within the content field of the audit event. To enable, configure the audit_serializer parameter as below. readonlyrest: audit: collector: true serializer: tech.beshu.ror.requestcontext.QueryAuditLogSerializer ...","title":"Extended audit"},{"location":"elasticsearch/#custom-audit-indices-name-and-time-granularity","text":"It is possible to change the name of the produced audit log indices by specifying a template value as audit.index_template . Example: tell ROR to write on monthly index. readonlyrest: audit: collector: true index_template: \"'custom-prefix'-yyyy-MM\" # <--monthly pattern ... \u26a0\ufe0fIMPORTANT : notice the single quotes inside the double quoted expression. This is the same syntax used for Java's SimpleDateFormat .","title":"Custom audit indices name and time granularity"},{"location":"elasticsearch/#custom-audit-log-serializer","text":"You can write your own custom audit log serializer class, add it to the ROR plugin class path and configure it through the YAML settings. We provided 2 project examples with custom serializers (in Scala and Java). You can use them as an example to write yours in one of those languages.","title":"Custom audit log serializer"},{"location":"elasticsearch/#create-custom-audit-log-serializer-in-scala","text":"Checkout https://github.com/sscarduzio/elasticsearch-readonlyrest-plugin git clone git@github.com:sscarduzio/elasticsearch-readonlyrest-plugin.git Install SBT https://www.scala-sbt.org/download.html Find and go to: elasticsearch-readonlyrest-plugin/custom-audit-examples/ror-custom-scala-serializer/ Create own serializer: from scratch (example can be found in class ScalaCustomAuditLogSerializer ) extending default one (example can be found in class ScalaCustomAuditLogSerializer ) Build serializer JAR: sbt assembly Jar can be find in: elasticsearch-readonlyrest-plugin/custom-audit-examples/ror-custom-scala-serializer/target/scala-2.13/ror-custom-scala-serializer-1.0.0.jar","title":"Create custom audit log serializer in Scala"},{"location":"elasticsearch/#create-custom-audit-log-serializer-in-java","text":"Checkout https://github.com/sscarduzio/elasticsearch-readonlyrest-plugin git clone git@github.com:sscarduzio/elasticsearch-readonlyrest-plugin.git Install Maven https://maven.apache.org/install.html Find and go to: elasticsearch-readonlyrest-plugin/custom-audit-examples/ror-custom-java-serializer/ Create own serializer: from scratch (example can be found in class JavaCustomAuditLogSerializer ) extending default one (example can be found in class JavaCustomAuditLogSerializer ) Build serializer JAR: mvn package Jar can be find in: elasticsearch-readonlyrest-plugin/custom-audit-examples/ror-custom-java-serializer/target/ror-custom-java-serializer-1.0.0.jar","title":"Create custom audit log serializer in Java"},{"location":"elasticsearch/#configuration","text":"mv ror-custom-java-serializer-1.0.0.jar plugins/readonlyrest/ Your config/readonlyrest.yml should start like this text readonlyrest: audit: collector: true serializer: \"JavaCustomAuditLogSerializer\" # when your serializer class is not in default package, you should use full class name here (eg. \"tech.beshu.ror.audit.instances.QueryAuditLogSerializer\") Start elasticsearch (with ROR installed) and grep for: text [2017-11-09T09:42:51,260][INFO ][t.b.r.r.SerializationTool] Using custom serializer: JavaCustomAuditLogSerializer","title":"Configuration"},{"location":"elasticsearch/#troubleshooting","text":"Follow these approaches until you find the solution to your problem Scenario: you can't understand why your requests are being forbidden by ReadonlyREST (or viceversa) Step 1: see what block/rule is matching Take the Elasticsearch log file, and grep the logs for ACT: . This will show you the whole request context (including the action and indices fields) of the blocked requests. You can now tweak your ACL blocks to include that action. Step 2: enable debug logs Logs are good for auditing the activity on the REST API. You can configure them by editing $ES_PATH_CONF/config/logging.yml (Elasticsearch 2.x) or $ES_PATH_CONF/config/log4j2.properties file (Elasticsearch 5.x) For example, you can enable the debug log globally by setting the rootLogger to debug . rootLogger.level = debug This is really useful especially to debug the activity of LDAP and other external connectors. Trick: log requests to different files Here is a log4j2.properties snippet for ES 5.x that logs all the received requests as a new line in a separate file: #Plugin readonly rest separate access logging file definition appender.access_log_rolling.type = RollingFile appender.access_log_rolling.name = access_log_rolling appender.access_log_rolling.fileName = ${sys:es.logs}_access.log appender.access_log_rolling.layout.pattern = [%d{ISO8601}][%-5p][%-25c] %marker%.-10000m%n appender.access_log_rolling.layout.type = PatternLayout appender.access_log_rolling.filePattern = ${sys:es.logs}_access-%d{yyyy-MM-dd}.log appender.access_log_rolling.policies.type = Policies appender.access_log_rolling.policies.time.type = TimeBasedTriggeringPolicy appender.access_log_rolling.policies.time.interval = 1 appender.access_log_rolling.policies.time.modulate = true logger.access_log_rolling.name = tech.beshu.ror logger.access_log_rolling.level = info logger.access_log_rolling.appenderRef.access_log_rolling.ref = access_log_rolling logger.access_log_rolling.additivity = false # exclude kibana, beat and logstash users as they generate too much noise logger.access_log_rolling.filter.regex.type = RegexFilter logger.access_log_rolling.filter.regex.regex = .*USR:(kibana|beat|logstash),.* logger.access_log_rolling.filter.regex.onMatch = DENY logger.access_log_rolling.filter.regex.onMismatch = ACCEPT","title":"Troubleshooting"},{"location":"elasticsearch/#custom-audit-cluster","text":"It's possible to set a custom audit cluster responsible for audit logs storage. When a custom cluster is specified, items will be sent to defined cluster nodes instead of the local one. readonlyrest: audit: collector: true cluster: [\"https://user1:password@auditNode1:9200\", \"https://user2:password@auditNode2:9200\"] ... Setting audit.cluster is optional, it accepts non empty list of audit cluster nodes URIs.","title":"Custom audit cluster"},{"location":"elasticsearch/#users-and-groups","text":"Sometimes we want to make allow/forbid decisions according to the username associated to a HTTP request. The extraction of the user identity (username) can be done via HTTP Basic Auth (Authorization header) or delegated to a reverse proxy (see proxy_auth rule). The validation of the said credentials can be carried on locally with hard coded credential hashes (see auth_key_sha256 rule), via one or more LDAP server, or we can forward the Authorization header to an external web server and examine the HTTP status code (see external_authentication ). Optionally we can introduce the notion of groups (see them as bags of users). The aim of having groups is to write a very specific block once, and being able to allow multiple usernames that satisfy the block. Groups can be declared and associated to users statically in the readonlyrest.yml file. Alternatively, groups for a given username can be retrieved from an LDAP server or from a LDAP server, or a custom JSON/XML service. You can mix and match the techniques to satisfy your requirements. For example, you can configure ReadonlyREST to: Extract the username from X-Forwarded-User Resolve groups associated to said user through a JSON microservice Another example: Extract the username from Authorization header (HTTP Basic Auth) Validate said username's password via LDAP server resolve groups associated to the user from groups defined in readonlyrest.yml More examples are shown below together with a sample configuration.","title":"Users and Groups"},{"location":"elasticsearch/#local-users-and-groups","text":"The groups rule accepts a list of group names. This rule will match if the resolved username (i.e. via auth_key ) is associated to the given groups. In this example, the usernames are statically associated to group names. access_control_rules: - name: Accept requests from users in group team1 on index1 type: allow # Optional, defaults to \"allow\" will omit now on. groups: [\"team1\"] indices: [\"index1\"] - name: Accept requests from users in group team2 on index2 groups: [\"team2\"] indices: [\"index2\"] - name: Accept requests from users in groups team1 OR team2 on index3 groups: [\"team1\", \"team2\"] indices: [\"index3\"] - name: Accept requests from users in groups team1 AND team2 on index3 groups_and: [\"team1\", \"team2\"] indices: [\"index3\"] users: - username: \"alice\" groups: [\"team1\"] auth_key: alice:p455phrase - username: \"bob\" groups: [\"team2\", \"team4\"] auth_key: bob:s3cr37 - username: \"claire\" groups: [\"team1\", \"team5\"] auth_key_sha256: e0bba5fda92dbb0570fd2e729a3c8ed6b1d52b380581f32427a38e396ba28ec6 #claire:p455key Example: rules are associated to groups (instead of users) and users-group association is declared separately later under users:","title":"Local users and groups"},{"location":"elasticsearch/#group-mapping","text":"Sometimes we'd like to take advantage of groups (roles) existing in external systems (like LDAP). We can do that in users section too. It's possible to map external groups to local ones. For details see External to local groups mapping .","title":"Group mapping"},{"location":"elasticsearch/#username-case-sensitivity","text":"ReadonlyREST can cooperate with services, that operates in case-insensitive way. For this case ROR has toggleable username case sensitivity option username_case_sensitivity . readonlyrest: username_case_sensitivity: case_sensitive By default, usernames are case-sensitive username_case_sensitivity: case_sensitive . By setting username_case_sensitivity: case_sensitive username comparison will be case-insensitive in any rule.","title":"Username case sensitivity"},{"location":"elasticsearch/#environmental-variables","text":"Anywhere in readonlyrest.yml you can use the espression ${MY_ENV_VAR} to replace in place the environmental variables. This is very useful for injecting credentials like LDAP bind passwords, especially in Docker. For example, here we declare an environment variable, and we write ${LDAP_PASSWORD} in our settings: $ export LDAP_PASSWORD=S3cr3tP4ss $ cat readonlyrest.yml .... ldaps: - name: ldap1 host: \"ldap1.example.com\" port: 389 ssl_enabled: false ssl_trust_all_certs: true bind_dn: \"cn=admin,dc=example,dc=com\" bind_password: \"${LDAP_PASSWORD}\" search_user_base_DN: \"ou=People,dc=example,dc=com\" .... And ReadonlyREST ES will load \"S3cr3tP4ss\" as bind_password .","title":"Environmental variables"},{"location":"elasticsearch/#dynamic-variables","text":"One of the neatest feature in ReadonlyREST is that you can use dynamic variables inside most rules values. The variables you can currently replace into rules values are these: @{acl:user} gets replaced with the username of the successfully authenticated user. Using this variable is allowed only in blocks where one of the rules is authentication rule (of course it must be rule different from the one containing given variable). @{user} old style user variable definition. Preferred approach is to use @{acl:user} . @{acl:current_group} gets replaced with user's current group. Usually resolved by authorization rule defined in block, but value can be also retrieved by means of kibana plugin. This variable doesn't specify usage requirements. @{xyz} gets replaced with any xyz HTTP header included in the incoming request (useful when reverse proxies handle authentication)","title":"Dynamic variables"},{"location":"elasticsearch/#indices-from-user-name","text":"You can let users authenticate externally, i.e. via LDAP, and use their user name string inside the indices rule. readonlyrest: access_control_rules: - name: \"Users can see only their logstash indices i.e. alice can see alice_logstash-20170922\" ldap_authentication: name: \"myLDAP\" indices: [\"@{acl:user}_logstash-*\"] # LDAP connector settings omitted, see LDAP section below..","title":"Indices from user name"},{"location":"elasticsearch/#uri-regex-matching-users-current-group","text":"You can let users authorize externally, i.e. via LDAP, and use their group inside the uri_re rule. readonlyrest: access_control_rules: - name: \"Users can access uri with value containing user's current group, i.e. user with group 'g1' can access: '/path/g1/some_thing'\" ldap_authorization: name: \"ldap1\" groups: [\"g1\", \"g2\", \"g3\"] uri_re: [\"^/path/@{acl:current_group}/.*\"] # LDAP connector settings omitted, see LDAP section below..","title":"Uri regex matching user's current group"},{"location":"elasticsearch/#kibana-index-from-headers","text":"Imagine that we delegate authentication to a reverse proxy, so we know that only authenticated users will ever reach Elasticsearch. We can tell the reverse proxy (i.e. Nginx) to inject a header called x-nginx-user containing the username. readonlyrest: access_control_rules: - name: \"Identify a personal kibana index where each user is supposed to save their dashboards\" kibana_access: rw kibana_index: \".kibana_@{x-nginx-user}\"","title":"Kibana index from headers"},{"location":"elasticsearch/#dynamic-variables-from-jwt-claims","text":"The JWT token is an authentication string passed generally as a header or a query parameter to the web browser. If you squint, you can see it's a concatenation of three base64 encoded strings. If you base64 decode the middle string, you can see the \"claims object\". That is the object containing the current user's metadata. Here is an example of JWT claims object. { \"user\": \"jdoe\", \"display_name\": \"John Doe\", \"department\": \"infosec\", \"allowedIndices\": [\"x\", \"y\"] } Here follow some examples of how to use JWT claims as dynamic variables in ReadonlyREST ACL blocks, notice the \"jwt:\" prefix: # Using JWT claims as dynamic variables indices: [ \".kibana_@{jwt:department}\", \"otherIdx\" ] # claims = { \"user\": \"u1\", \"department\": \"infosec\"} # -> indices: [\".kibana_infosec\", \"otherIdx\"] # Using nested values in JWT using JSONPATH as dynamic variables indices: [ \".kibana_@{jwt:jsonpath.to.department}\", \"otherIdx\"] # claims = { \"jsonpath\": {\"to\": { \"department\": \"infosec\" }}} # -> indices: [\".kibana_infosec\", \"otherIdx\"] # Referencing array-typed values from JWT claims will expand in a list of strings indices: [ \".kibana_@explode{jwt:allowedIndices}\", \"otherIdx\"] # claims = {\"username\": \"u1\", \"allowedIndices\": [\"x\", \"y\"] } # -> indices: [\".kibana_x\", \".kibana_y\", \"otherIdx\"] # Explode operator will generate an array of strings from a comma-separated string indices: [\"logstash_@explode{x-indices_csv_string}*\", \"otherIdx\"] # HTTP Headers: [{ \"x-indices_csv_string\": \"a,b\"}] # -> indices: [\"logstash_a*\", \"logstash_b*\", \"otherIdx\"]","title":"Dynamic variables from JWT claims"},{"location":"elasticsearch/#ldap-connector","text":"The auhentication and authorization rules for LDAP ( ldap_auth , ldap_authentication , ldap_authorization ) defined in the rules section, always need to contain a reference by name to one LDAP connector. One or more LDAP connectors need to be defined in the section \"ldaps\" of the ACL.","title":"LDAP connector"},{"location":"elasticsearch/#configuration-notes","text":"If you would like to experiment with LDAP and need a development server, you can stand up an OpenLDAP server configuring it using our schema file, which can be found in our tests ).","title":"Configuration notes"},{"location":"elasticsearch/#technical-configuration","text":"There are also plenty of technical settings which can be useful: * an LDAP server address: * single host: * host (String, required) - LDAP server address * port (Integer, optional, default: 389 ) - LDAP server port * ssl_enabled (Boolean, optional, default: true ) - enables or disables SSL for LDAP connection * several hosts: * hosts (List, required) - list of LDAP server addresses. The address should look like this ldap://[HOST]:[PORT] or/and ldaps://[HOST]:[PORT] * ha (enum: [ FAILOVER , ROUND_ROBIN ], optional, default: FAILOVER ) - provides high availability strategy for LDAP * auto-discovery: * server_discovery (Boolean|YAML object, optional, default: false ) - for details see LDAP server discovery section * connection_pool_size (Integer, optional, default: 30 ) - indicates how many connections LDAP connector should create to LDAP server * connection_timeout (Duration, optional, default: 10 sec ) - instructs connector how long it should wait for the connection to LDAP server * request_timeout (Duration, optional, default: 10 sec ) - instructs connector how long it should wait for receiving a whole response from LDAP server * ssl_trust_all_certs (Boolean, optional, default: false ) - if it is set to true , untrusted certificates will be accepted * ignore_ldap_connectivity_problems (Boolean, optional, default: false ) - when it is set to true , it allows ROR to function even when LDAP server is unreachable. Rules using unreachable LDAP servers won't match. By default, ROR starts only after it's able to connect to each server * cache_ttl (Duration, optional, default: 0 sec ) - tells how long LDAP connector should cache queries results (for default see caching section ) * circuit_breaker (YAML object, optional, default: max_retries: 10 , reset_duration: 10 sec ) - for details see circuit breaker section","title":"Technical configuration"},{"location":"elasticsearch/#query-configuration","text":"Usually, we would like to configure three main things for defining the way LDAP users and groups are queried: a way to authenticate client (LDAP binding; used by all LDAP rules): bind_dn (string, optional, default: [not present]) - a username used to connect to the LDAP service. We can skip this setting when our LDAP service allows for anonymous binding bind_password (string, optional, default: [not present]) - a password used to connect to the LDAP service. We can skip this setting when our LDAP service allows for anonymous binding a way to search users . In ROR it can be done using the following YAML keys (used by all LDAP rules): search_user_base_DN (string, required) - should refer to the base Distinguished Name of the users to be authenticated user_id_attribute (string, optional, default: uid ) - should refer to a unique ID for the user within the base DN a way to search user groups (NOT used by ldap_authentication rule). In ROR, depending on LDAP schema, a relation between users and groups can be defined in: Group entry - it has an attribute that refers to User entries: search_groups_base_DN (required) - should refer to the base Distinguished Name of the groups to which these users may belong group_name_attribute (string, optional, default: cn ) - is the LDAP group object attribute that contains the names of the ROR groups unique_member_attribute (string, optional, default: uniqueMember ) - is the LDAP group object attribute that contains the names of the ROR groups group_search_filter (string, optional, default: (cn=*) ) - is the LDAP search filter (or filters) to limit the user groups returned by LDAP. By default, this filter will be joined (with & ) with unique_member_attribute=user_dn filter resulting in this LDAP search filter: (&YOUR_GROUP_SEARCH_FILTER(unique_member_attribute=user_dn)) . group_attribute_is_dn (boolean, optional, default: true ) - when true the search filter will look like that: (&YOUR_GROUP_SEARCH_FILTER(unique_member_attribute={USER_DN})) then false the search filer will look like that: (&YOUR_GROUP_SEARCH_FILTER(unique_member_attribute={USER_ID_ATTRIBUTE_VALUE})) User entry - it has an attribute that refers to Group entries: search_groups_base_DN (string, required) - should refer to the base Distinguished Name of the groups to which these users may belong group_name_attribute (string, optional, default: cn ) - is the LDAP group object attribute that contains the names of the ROR groups groups_from_user_attribute (string, optional, default: memberOf ) - is the LDAP user object attribute that contains the names of the ROR groups Examples: group_search_filter: \"(objectClass=group)\" group_search_filter: \"(objectClass=group)(cn=application*)\" group_search_filter: \"(cn=*)\" # basically no group filtering","title":"Query configuration"},{"location":"elasticsearch/#caching","text":"Too many calls made by ROR to our LDAP service can sometimes be problematic (eg. when one LDAP connector is used in many rules). The problem can be simply solved by using caching functionality. Caching can be configured per LDAP connector or per LDAP rule (see ldap_auth , ldap_authentication , ldap_authorization rules). By default cache is diabled. We can enabled it by set cache_ttl > 0 sec . In the cache will be stored only results of successful requests - info about authentication result and/or returned LDAP groups for the given credentials. When LDAP connector level cache is used any rule that use the connector can take advantage of cached results. When we configure cache_ttl at LDAP rule level, the results of LDAP calls made by the rule will be stored in cache. Other LDAP rules won't have access to this cache.","title":"Caching"},{"location":"elasticsearch/#circuit-breaker","text":"The LDAP connector is equipped by default with a circuit breaker functionality. The circuit breaker can disable the connector from sending new requests to the server when it doesn't respond properly. After receiving a configurable number of failed responses in a row, the circuit breaker feature disables sending any new requests by terminating them immediately with an exception. After a configurable amount of time, the circuit breaker feature allows one request to pass again. If it succeeds, the connector goes back to normal operation. If not, a test request is sent again after a configurable amount of time. A general description of the concept could be found on wiki and more about specific implementation could be found in library documentation . The circuit breaker feature can be customized to adapt to specific needs using the following configuration parameters: max_retries is the number of failed responses in a row that will trigger the circuit breaker. reset_duration defines how long the circuit breaker feature will block the incoming requests before starting to send one test request. to the LDAP server.","title":"Circuit Breaker"},{"location":"elasticsearch/#ldap-server-discovery","text":"The LDAP connector can get all LDAP hostnames from DNS server rather than from the configuration file. By default _ldap._tcp SRV records are used for that, but any other SRV record can be configured. The simplest configuration example of an LDAP connector instance using server discovery is: - name: ldap server_discovery: true search_user_base_DN: \"ou=People,dc=example2,dc=com\" search_groups_base_DN: \"ou=Groups,dc=example2,dc=com\" This configuration is using the system DNS to fetch all the _ldap._tcp SRV records which are expected to contain the hostname and port of all the LDAP servers we should connect to. Each SRV record also has priority and weight assigned to it which determine the order in which they should be contacted. Records with a lower priority value will be used before those with a higher priority value. The weight will be used if there are multiple service records with the same priority, and it controls how likely each record is to be chosen. A record with a weight of 2 is twice as likely to be chosen as a record with the same priority and a weight of 1. The server discovery mechanism can be optionally configured further, by adding a few more configuration parameters, all of which are optional: record_name - DNS SRV record name. By default it's _ldap._tcp , but could be _ldap._tcp.domainname or any custom value. dns_url - Address of non-default DNS server in form dns://IP[:PORT] . By default, the system DNS is used. ttl - DNS cache timeout. Specifies how long values from DNS will be kept in the cache. Default is 1h. use_ssl - Use true when SSL should be used for LDAP connections. Default is false which means that SSL won't be used. Example: - name: ldap server_discovery: record_name: \"_ldap._tcp.example.com\" dns_url: \"dns://192.168.1.100\" ttl: \"3 hours\" use_ssl: true search_user_base_DN: \"ou=People,dc=example2,dc=com\" search_groups_base_DN: \"ou=Groups,dc=example2,dc=com\"","title":"LDAP Server discovery"},{"location":"elasticsearch/#ror-with-ldap-examples","text":"In this example, users' credentials are validated via LDAP. The groups associated with each validated user, are resolved using the same LDAP server. Simpler: authentication and authorization in one rule readonlyrest: access_control_rules: - name: Accept requests from users in group team1 on index1 type: allow # Optional, defaults to \"allow\", will omit from now on. ldap_auth: name: \"ldap1\" # ldap name from below 'ldaps' section groups: [\"g1\", \"g2\"] # group within 'ou=Groups,dc=example,dc=com' indices: [\"index1\"] - name: Accept requests from users in group team2 on index2 ldap_auth: name: \"ldap2\" groups: [\"g3\"] cache_ttl_in_sec: 60 indices: [\"index2\"] ldaps: - name: ldap1 host: \"ldap1.example.com\" port: 389 ssl_enabled: false ssl_trust_all_certs: true ignore_ldap_connectivity_problems: true bind_dn: \"cn=admin,dc=example,dc=com\" bind_password: \"password\" search_user_base_DN: \"ou=People,dc=example,dc=com\" user_id_attribute: \"uid\" search_groups_base_DN: \"ou=Groups,dc=example,dc=com\" unique_member_attribute: \"uniqueMember\" connection_pool_size: 10 connection_timeout: 10s request_timeout: 10s cache_ttl: 60s group_search_filter: \"(objectClass=group)(cn=application*)\" group_name_attribute: \"cn\" circuit_breaker: max_retries: 2 reset_duration: 5s # High availability LDAP settings (using \"hosts\", rather than \"host\") - name: ldap2 hosts: - \"ldaps://ssl-ldap2.foo.com:636\" - \"ldaps://ssl-ldap3.foo.com:636\" ha: \"ROUND_ROBIN\" search_user_base_DN: \"ou=People,dc=example2,dc=com\" search_groups_base_DN: \"ou=Groups,dc=example2,dc=com\" # Server discovery variant - name: ldap3 server_discovery: true search_user_base_DN: \"ou=People,dc=example2,dc=com\" search_groups_base_DN: \"ou=Groups,dc=example2,dc=com\" Advanced: authentication and authorization in separate rules readonlyrest: enable: true response_if_req_forbidden: Forbidden by ReadonlyREST ES plugin access_control_rules: - name: Accept requests to index1 from users with valid LDAP credentials, belonging to LDAP group 'team1' ldap_authentication: \"ldap1\" ldap_authorization: name: \"ldap1\" # ldap name from 'ldaps' section groups: [\"g1\", \"g2\"] # group within 'ou=Groups,dc=example,dc=com' indices: [\"index1\"] - name: Accept requests to index2 from users with valid LDAP credentials, belonging to LDAP group 'team2' ldap_authentication: name: \"ldap2\" cache_ttl: 60s ldap_authorization: name: \"ldap2\" groups: [\"g3\"] cache_ttl: 60s indices: [\"index2\"] ldaps: - name: ldap1 host: \"ldap1.example.com\" port: 389 ssl_enabled: false ssl_trust_all_certs: true ignore_ldap_connectivity_problems: true bind_dn: \"cn=admin,dc=example,dc=com\" bind_password: \"password\" search_user_base_DN: \"ou=People,dc=example,dc=com\" user_id_attribute: \"uid\" search_groups_base_DN: \"ou=Groups,dc=example,dc=com\" unique_member_attribute: \"uniqueMember\" connection_pool_size: 10 connection_timeout: 10s request_timeout: 10s cache_ttl: 60s # High availability LDAP settings (using \"hosts\", rather than \"host\") - name: ldap2 hosts: - \"ldaps://ssl-ldap2.foo.com:636\" - \"ldaps://ssl-ldap3.foo.com:636\" ha: \"ROUND_ROBIN\" search_user_base_DN: \"ou=People,dc=example2,dc=com\" search_groups_base_DN: \"ou=Groups,dc=example2,dc=com\"","title":"ROR with LDAP - examples"},{"location":"elasticsearch/#external-basic-auth_1","text":"ReadonlyREST will forward the received Authorization header to a website of choice and evaluate the returned HTTP status code to verify the provided credentials. This is useful if you already have a web server with all the credentials configured and the credentials are passed over the Authorization header. readonlyrest: access_control_rules: - name: \"::Tweets::\" methods: GET indices: [\"twitter\"] external_authentication: \"ext1\" - name: \"::Facebook posts::\" methods: GET indices: [\"facebook\"] external_authentication: service: \"ext2\" cache_ttl_in_sec: 60 external_authentication_service_configs: - name: \"ext1\" authentication_endpoint: \"http://external-website1:8080/auth1\" success_status_code: 200 cache_ttl_in_sec: 60 validate: false # SSL certificate validation (default to true) http_connection_settings: connection_timeout_in_sec: 5 # default 2 socket_timeout_in_sec: 3 # default 5 connection_request_timeout_in_sec: 3 # default 5 connection_pool_size: 10 # default 30 - name: \"ext2\" authentication_endpoint: \"http://external-website2:8080/auth2\" success_status_code: 204 cache_ttl_in_sec: 60 To define an external authentication service the user should specify: name for service (then this name is used as id in service attribute of external_authentication rule) authentication_endpoint (GET request) success_status_code - authentication response success status code Cache can be defined at the service level or/and at the rule level. In the example, both are shown, but you might opt for setting up either.","title":"External Basic Auth"},{"location":"elasticsearch/#custom-groups-providers","text":"This external authorization connector makes it possible to resolve to what groups a users belong, using an external JSON or XML service. readonlyrest: access_control_rules: - name: \"::Tweets::\" methods: GET indices: [\"twitter\"] proxy_auth: proxy_auth_config: \"proxy1\" users: [\"*\"] groups_provider_authorization: user_groups_provider: \"GroupsService\" groups: [\"group3\"] - name: \"::Facebook posts::\" methods: GET indices: [\"facebook\"] proxy_auth: proxy_auth_config: \"proxy1\" users: [\"*\"] groups_provider_authorization: user_groups_provider: \"GroupsService\" groups: [\"group1\"] cache_ttl_in_sec: 60 proxy_auth_configs: - name: \"proxy1\" user_id_header: \"X-Auth-Token\" # default X-Forwarded-User user_groups_providers: - name: GroupsService groups_endpoint: \"http://localhost:8080/groups\" auth_token_name: \"token\" auth_token_passed_as: QUERY_PARAM # HEADER OR QUERY_PARAM response_groups_json_path: \"$..groups[?(@.name)].name\" # see: https://github.com/json-path/JsonPath cache_ttl_in_sec: 60 http_connection_settings: connection_timeout_in_sec: 5 # default 2 socket_timeout_in_sec: 3 # default 5 connection_request_timeout_in_sec: 3 # default 5 connection_pool_size: 10 # default 30 In example above, a user is authenticated by reverse proxy and then external service is asked for groups for that user. If groups returned by the service contain any group declared in groups list, user is authorized and rule matches. To define user groups provider you should specify: name for service (then this name is used as id in user_groups_provider attribute of groups_provider_authorization rule) groups_endpoint - service with groups endpoint (GET request) auth_token_name - user identifier will be passed with this name auth_token_passed_as - user identifier can be send using HEADER or QUERY_PARAM response_groups_json_path - response can be unrestricted, but you have to specify JSON Path for groups name list (see example in tests) As usual, the cache behaviour can be defined at service level or/and at rule level.","title":"Custom groups providers"},{"location":"elasticsearch/#json-web-token-jwt-auth","text":"The information about the username can be extracted from the \"claims\" inside a JSON Web Token. Here is an example. readonlyrest: access_control_rules: - name: Valid JWT token with a viewer group kibana_access: ro jwt_auth: name: \"jwt_provider_1\" groups: [\"viewer\"] - name: Valid JWT token with a writer group kibana_access: rw jwt_auth: name: \"jwt_provider_1\" groups: [\"writer\"] - name: Valid JWT token with a viewer and writer groups kibana_access: rw jwt_auth: name: \"jwt_provider_1\" groups_and: [\"writer\", \"viewer\"] jwt: - name: jwt_provider_1 signature_algo: HMAC # can be NONE, RSA, HMAC (default), and EC signature_key: \"your_signature_min_256_chars\" user_claim: email groups_claim: resource_access.client-app.groups # JSON-path style header_name: Authorization You can verify groups assigned to the user with the groups field. The rule matches when the user belongs to at least one of the configured groups (OR logic). Alternatively, groups_and matches when the user belongs to all given groups (AND logic). The user_claim indicates which field in the JSON will be interpreted as the username. The signature_key is used shared secret between the issuer of the JWT and ReadonlyREST. It is used to verify the cryptographical \"paternity\" of the message. The header_name is used if we expect the JWT Token in a custom header (i.e. Google Cloud IAP signed headers ) The signature_algo indicates the family of cryptographic algorithms used to validate the JWT. Accepted signature_algo values The value of this configuration represents the cryptographic family of the JWT protocol. Use the below table to tell what value you should configure, given a JWT token sample. You can decode sample JWT token using an online tool . Algorithm declared in JWT token signature_algo value NONE None HS256 HMAC HS384 HMAC HS512 HMAC RS256 RSA RS384 RSA RS512 RSA PS256 RSA PS384 RSA PS512 RSA ES256 EC ES384 EC ES512 EC","title":"JSON Web Token (JWT) Auth"},{"location":"elasticsearch/#gplv3-license","text":"ReadonlyREST Free (Elasticsearch plugin) is released under the GPLv3 license. For what this kind of software concerns, this is identical to GPLv2, that is, you can treat ReadonlyREST as you would treat Linux code. The big difference from Linux is that here you can ask for a commercial license and stop thinking about legal implications. Here is a practical summary of what dealing with GPLv3 means:","title":"GPLv3 License"},{"location":"elasticsearch/#you-can","text":"Distribute for free or commercially a version (partial or total) of this software (along with its license and attributions) as part of a product or solution that is also released under GPL-compatible license . Please notify us if you do so. Use a modified version internally to your company without making your changes available under the GPLv3 license. Distribute for free or commercially a modified version (partial or total) of this software, provided that the source is contributed back as pull request to the original project or publicly made available under the GPLv3 or compatible license.","title":"You CAN"},{"location":"elasticsearch/#you-cannot","text":"Sell or give away a modified version of the plugin (or parts of it, or any derived work) without publishing the modified source under GPLv3 compatible licenses. Modify the code for a paying client without immediately contributing your changes back to this project's GitHub as a pull request, or alternatively publicly release said fork under GPLv3 or compatible license.","title":"You CANNOT"},{"location":"elasticsearch/#gplv3-license-faq","text":"1. Q : I sell a proprietary software solution that already includes many other OSS components (i.e. Elasticsearch). Can I bundle also ReadonlyREST into it? A : No, GPLv3 does not allow it. But hey, no problem, just go for the Enterprise subscription . 2. Q : I have a SaaS and we want to use a version of ReadonlyREST for Elasticsearch (as is, or modified), do I need a commercial license? A : No, you don't. Go for it! However if you are using Kibana, consider the Enterprise offer which includes multi-tenancy. 3. Q : I'm a consultant and I will charge my customer for modifying this software and they will not sell it as a product or part of their product. A : This is fine with GPLv3.","title":"GPLv3 license FAQ"},{"location":"elasticsearch/#dual-license","text":"Please don't hesitate to contact us for a re-licensed copy of this source. Your success is what makes this project worthwhile, don't let legal issues slow you down. See commercial license FAQ page for more information.","title":"Dual-license"},{"location":"elasticsearch/#installation","text":"Download the binary release of the latest version of ReadonlyREST from the download page cd to the Elasticsearch home Install the plugin Elasticsearch 5.x bin/elasticsearch-plugin install file:///download-folder/readonlyrest-1.13.2_es5.1.2.zip Elasticsearch 2.x bin/plugin install file:///download-folder/readonlyrest-1.13.2_es5.1.2.zip Edit config/readonlyrest.yml and add your configuration as seen in examples.","title":"Installation"},{"location":"elasticsearch/#build-from-source","text":"You need to have installed: git, maven, Java 8 JDK, zip. So use apt-get or brew to get them. Clone the repo git clone https://github.com/sscarduzio/elasticsearch-readonlyrest-plugin cd elasticsearch-readonlyrest-plugin Launch the build script bin/build.sh You should find the plugin's zip files under /target (Elasticsearch 2.x) or build/releases/ (Elasticsearch 5.x).","title":"Build from Source"},{"location":"elasticsearch/#examples","text":"A small library of typical use cases.","title":"Examples"},{"location":"elasticsearch/#secure-logstash","text":"We have a Logstash agent installed somewhere and we want to ship the logs to our Elasticsearch cluster securely.","title":"Secure Logstash"},{"location":"elasticsearch/#elasticsearch-side","text":"Step 1: Bring Elasticsearch HTTP interface (port 9200) to HTTPS When you get SSL certificates (i.e. from your IT department, or from LetsEncrypt), you should obtain a private key and a certificate chain. In order to use them with ReadonlyREST, we need to wrap them into a JKS (Java key store) file. For the sake of this example, or for your testing, we won't use real SSL certificates, we are going to create a self signed certificate. Remember, we'll do with a self-signed certificate for example convenience, but if you deploy this to a server, use a real one! keytool -genkey -keyalg RSA -alias selfsigned -keystore keystore.jks -storepass readonlyrest -validity 360 -keysize 2048 Now copy the keystore.jks inside the plugin directory inside the Elasticsearch home. cp keystore.jks /elasticsearch/config/ IMPORTANT: to enable ReadonlyREST's SSL stack, open elasticsearch.yml and append this one line: http.type: ssl_netty4 Step 3 Now We need to create some credentials for logstash to login, let's say user = logstash password = logstash Step 4 Hash the credentials string logstash:logstash using SHA256. The simplest way is to paste the string in an online tool You should have obtained \"280ac6f756a64a80143447c980289e7e4c6918b92588c8095c7c3f049a13fbf9\". Step 5 Let's add some configuration to our Elasticsearch: edit conf/readonlyrest.yml and append the following lines: readonlyrest: ssl: enable: true # keystore in the same dir with readonlyrest.yml keystore_file: \"keystore.jks\" keystore_pass: readonlyrest key_pass: readonlyrest response_if_req_forbidden: Forbidden by ReadonlyREST ES plugin access_control_rules: - name: \"::LOGSTASH::\" auth_key_sha256: \"280ac6f756a64a80143447c980289e7e4c6918b92588c8095c7c3f049a13fbf9\" #logstash:logstash actions: [\"cluster:monitor/main\",\"indices:admin/types/exists\",\"indices:data/read/*\",\"indices:data/write/*\",\"indices:admin/template/*\",\"indices:admin/create\"] indices: [\"logstash-*\"]","title":"Elasticsearch side"},{"location":"elasticsearch/#logstash-side","text":"Edit the logstash configuration file and fix the output block as follows: output { elasticsearch { ssl => true ssl_certificate_verification => false hosts => [\"YOUR_ELASTICSEARCH_HOST:9200\"] user => logstash password => logstash } } The ssl_certificate_verification bit is necessary for accepting self-signed SSL certificates. You might also need to add cacert parameter to provide the path to your .cer or .pem file.","title":"Logstash side"},{"location":"elasticsearch/#secure-metricbeats","text":"Very similarly to Logstaash, here's a snippet of configuration for Metricbeats logging agent configuration of metricbeat - elasticsearch section","title":"Secure Metricbeats"},{"location":"elasticsearch/#on-the-metricbeats-side","text":"output.elasticsearch: output.elasticsearch: username: metricbeat password: hereyourpasswordformetricbeat protocol: https hosts: [\"xx.xx.xx.xx:9200\"] worker: 1 index: \"log_metricbeat-%{+yyyy.MM}\" template.enabled: false template.versions.2x.enabled: false ssl.enabled: true ssl.certificate_authorities: [\"./certs/your-rootca_cert.pem\"] ssl.certificate: \"./certs/your_srv_cert.pem\" ssl.key: \"./certs/your_srv_key.pem\" Of course, if you do not use ssl, disable it.","title":"On the Metricbeats side"},{"location":"elasticsearch/#on-the-elasticsearch-side","text":"readonlyrest: ssl: enable: true # keystore in the same dir with elasticsearch.yml keystore_file: \"keystore.jks\" keystore_pass: readonlyrest key_pass: readonlyrest access_control_rules: - name: \"metricbeat can write and create its own indices\" auth_key_sha1: fd2e44724a234234454324253094080986e8fda actions: [\"indices:data/read/*\",\"indices:data/write/*\",\"indices:admin/template/*\",\"indices:admin/create\"] indices: [\"metricbeat-*\", \"log_metricbeat*\"]","title":"On the Elasticsearch side"},{"location":"kibana/","text":"For Kibana \ud83e\uddd9 Are you using Kibana version 7.8.x or older? Go to the old platform manual page . Kibana Plugin overview ReadonlyREST plugin for Kibana is not open source, and it's offered as part of the ReadonlyREST PRO and ReadonlyREST ENTERPRISE , and ReadonlyREST Free packages. See product descriptions and a comparison chart in the official ReadonlyREST website ReadonlyREST plugins for Kibana always require ReadonlyREST Free to be installed in the Elasticsearch nodes your Kibana instance(s) will connect to. It's not mandatory to install ReadonlyREST Free in all Elasticsearch nodes, but only in the ones in where you need the HTTP interface to be secured. After purchasing You will receive a link to the plugin zip file in an email. Download your zip. You will be able to download it also in the future as long as your subscription is active. Version strings All our plugins include in their file name a version string. For example the file readonlyrest-1.16.26_es6.4.0.zip has a version string 1.16.26_es6.4.0 . Reading version strings Given the version string 1.16.26_es6.4.0 ReadonlyREST plugin code version 1.16.26 Works only with Elasticsearch/Kibana version 6.4.0 The \"es\" stands for \"Elastic stack\" which used to mean the family of products made by Elastic which get released at the same time under the same version number. This was chosen before Elastic renamed their X-Pack commercial offer to Elastic Stack. To be clear, there is no affiliation between ReadonlyREST and Elastic, or their commercial products. Trial builds version strings Trial builds are valid for 30 days after they were built, and they will stop working soon after the time is elapsed. Trial builds have a special version string which includes a build-time timestamp. I.e. readonlyrest_kbn_pro-1.16.26-20180911_es6.0.0.zip ReadonlyREST PRO plugin version 1.16.26 Build date 11th September 2018, expiring on the 11th of October 2018. Works only with Kibana version 6.0.0 When an update is out You will receive another email notification that a new deliverable is available. If the update contains a security fix, it is very important that you take action and update the plugin immediately . Installation You can install this as a normal Kibana plugin using the bin/kibana-plugin utility. Let's see a two ways to use this utility with ReadonlyREST. {% hint style=\"warning\" %} Don't forget After Kibana 7.9.x, it's necessary to patch Kibana after you install, otherwise ReadonlyREST will NOT work. {% endhint %} Installing via URL This installation method is more practical if your Kibana server is connected to the internet. According to what edition of ReadonlyREST you want to install, from your Kibana installation, launch one of the commands: Please note that this will always download the latest version of Kibana plugin available for the current supported Elasticsearch version. # ReadonlyREST Free edition $ bin/kibana-plugin install \"https://api.beshu.tech/download/kbn?edition=kbn_free&email=<your_email_address>\" # ReadonlyREST PRO (30 days trial) edition $ bin/kibana-plugin install \"https://api.beshu.tech/download/trial?edition=kbn_pro&email=<your_email_address>\" # ReadonlyREST Enterprise (30 days trial) edition $ bin/kibana-plugin install \"https://api.beshu.tech/download/trial?edition=kbn_enterprise&email=<your_email_address>\" If you want to download the latest version of plugin for a specific version of Elasticsearch, then use query parameter esVersion to specify your required Elasticsearch version. # ReadonlyREST Free edition for Elasticsearch 7.6.1 $ bin/kibana-plugin install \"https://api.beshu.tech/download/kbn?edition=kbn_free&esVersion=7.6.1&email=<your_email_address>\" # ReadonlyREST PRO (30 days trial) edition for Elasticsearch 7.6.1 $ bin/kibana-plugin install \"https://api.beshu.tech/download/trial?edition=kbn_pro&esVersion=7.6.1&email=<your_email_address>\" # ReadonlyREST Enterprise (30 days trial) edition for Elasticsearch 7.6.1 $ bin/kibana-plugin install \"https://api.beshu.tech/download/trial?edition=kbn_enterprise&esVersion=7.6.1&email=<your_email_address>\" If you want to download an older version of plugin for a specific version of Elasticsearch, then use query parameter pluginVersion along with esVersion . # ReadonlyREST Free edition - version 1.22.0 for Elasticsearch 7.6.1 $ bin/kibana-plugin install \"https://api.beshu.tech/download/kbn?edition=kbn_free&esVersion=7.6.1&pluginVersion=1.22.0&email=<your_email_address>\" # ReadonlyREST PRO (30 days trial) edition - version 1.22.0 for Elasticsearch 7.6.1 $ bin/kibana-plugin install \"https://api.beshu.tech/download/trial?edition=kbn_pro&esVersion=7.6.1&pluginVersion=1.22.0&email=<your_email_address>\" # ReadonlyREST Enterprise (30 days trial) edition - version 1.22.0 for Elasticsearch 7.6.1 $ bin/kibana-plugin install \"https://api.beshu.tech/download/trial?edition=kbn_enterprise&esVersion=7.6.1&pluginVersion=1.22.0&email=<your_email_address>\" If you are a PRO or Enterprise subscriber, the link will include an extra parameter \"token\" which can only be used in association with the provided email address. You can append required plugin version and Elasticsearch version query parameters to download specific version as described above. NB: This URL is personal, and should be handled as a secret. # ReadonlyREST PRO (Official) edition $ bin/kibana-plugin install \"https://api.beshu.tech/download/trial?edition=kbn_pro&email=<your_email_address>&token=<your_secret_token>\" # ReadonlyREST Enterprise (30 days trial) edition $ bin/kibana-plugin install \"https://api.beshu.tech/download/trial?edition=kbn_enterprise&email=<your_email_address>&token=<your_secret_token>\" You can obtain official links with personal secret tokens using our self service download form , once your email address has been recognized as active subscriber. Now you are ready to patch Kibana . Installing from zip file $ bin/kibana-plugin install file:///home/user/downloads/readonlyrest_kbn-X.Y.Z_esW.Q.U.zip Notice how we need to type in the format file:// + absolute path (yes, with three slashes). Patching Kibana If you are using Kibana 7.9.x or newer, you need an extra post-installation step . This will slightly modify some core Kibana files. # Patch Kibana core files $ node/bin/node plugins/readonlyrestkbn/ror-tools.js patch Unpatching Kibana If you are using Kibana 7.9.x or newer, you need an extra pre-uninstallation step . This will restore the core Kibana files to the original state. # Unpatch Kibana core files $ node/bin/node plugins/readonlyrestkbn/ror-tools.js unpatch Uninstalling {% hint style=\"info\" %} To uninstall, you should unpatch Kibana first, then uninstall ReadonlyREST plugin. However the Kibana plugin system uninstallation process is highly unreliable . So we highly recomend to throw away the entire Kibana directory, and start from scratch. Ideally, use ephemeral docker containers. Need inspiration? Try ROR Docker demo ! {% endhint %} To bring Kibana to its pre-patching original state, it's possible to unpatch. # Un-patch Kibana core files $ node/bin/node plugins/readonlyrestkbn/ror-tools.js unpatch # Uninstall normally $ bin/kibana-plugin remove readonlyrestkbn And the classic uninstall command... $ bin/kibana-plugin remove readonlyrest_kbn Upgrading To upgrade to a new version of a ReadonlyREST plugins for Kibana, you should: Unpatch Kibana Uninstall the old plugin Delete all the content of \"optimize\" directory (in the main Kibana installation directory) rm -rf optimize/ Install the new one Patch Kibana Restart Kibana. Using RoR with a reverse proxy RoR - just like Kibana itself - is meant to be used either with a proxy or without one. If you decide to set the server.basePath property in kibana.yml and set server.rewriteBasePath into a true , RoR will be accessed directly and via a reverse proxy, If you decided to rewrite the base path manually by your reverse proxy and set the server.rewriteBasePath property in kibana.yml into a false , be sure to access RoR via a proxy, as it will not work properly when accessed directly. Configuration ReadonlyREST for Kibana is completely remote-controlled from the Elasticsearch configuration. Login credentials, hidden Kibana apps, etc. are all going to be configured from the Elasticearch side via the usual \"rules\". This means the configuration will be kept all in one place and if you used ReadonlyREST before , it will be also very familiar. In this document, every time you will encounter references to \"readonlyrest.yml\" or \"elasticsearch.yml\", we will be referring to the configuration files in the Elasticsearch plugin (our Kibana plugins do not need a \"readonlyrest.yml\"). In general, by design, we tend to concentrate all configuration within the main plugin (the Elasticsearch one) as much as possible. Clusterwide Settings VS readonlyrest.yml This feature is available in Free and PRO editions Our Kibana plugins introduce a \"ReadonlyREST\" Kibana app. From here, you can edit the security settings of the whole Elasticsearch cluster, and they will take effect within 10 seconds in all Elasticsearch cluster nodes without the need to restart them. When you change the security settings from the Kibana app, they will be saved in a special index called \".readonlyrest\", so all the Elasticsearch nodes will pick them up. You can customize a name of the index by setting readonlyrest.settings_index: .my_custom_readonlyrest in elasticsearch.yml file (remember to set the same value for all your ES nodes). When an Elasticsearch node restarts, the order of settings evaluation is the following: 1. Attempt to find valid settings in readonlyrest.yml 2. If none is found, look inside elasticsearch.yml 3. Once successfully bootstrapped using file-based settings, attempt to read \".readonlyrest\" index 4. If the index exists and contains valid settings, override file based settings with the ones from the index. 5. Pressing \"save\" in the cluster wide settings app, will not overwrite the readonlyrest.yml file. Best practices: Build and update your production security settings from the Kibana app (will be saved in index) Protect the \".readonlyrest\" Kibana index with an ACL rule Loading settings: order of precedence As you read, there are two possible places where the settings can be read from: readonlyrest.yml a file the user needs to create in the same directory where elasticsearch.yml is found. .readonlyrest index. Our Kibana plugins' GUI (PRO/Enterprise) is programmed to write this index. When the ES plugin boots up, it follows some logic to evaluate where to read the YAML settings from. The following diagram shows how that works. Malformed in-index settings If for some reason the in-index settings get corrupted and ROR can't parse them, then neither settings from file or in-index settings can be loaded, so ES can't start. In this case ES would print message like: Loading ReadonlyREST settings from index failed: Settings config content is malformed. Details: while scanning a quoted scalar in 'reader', line 9, column 17: auth_key: \"admin:container ^ To recover from this state, set readonlyrest.force_load_from_file: true in elasticsearch.yaml on one node es1 . Example recovery settings: elasticsearch.yaml [...] readonlyrest: force_load_from_file: true readonlyrest.yaml readonlyrest: access_control_rules: - name: \"::ADMIN recover::\" auth_key: admin:dev indices: [\"*\"] Then remove in-index settings index manually. curl -X DELETE \"admin:dev@es1:9200/.readonlyrest?pretty\" Now you can restore your settings to readonlyrest.yml , remove readonlyrest.force_load_from_file: true from elasticsearch.yaml and restart node. Example: multiuser ELK This configuration will work in PRO and Enterprise editions Make sure X-Pack is uninstalled or disabled from elasticsearch.yml (on the Elasticsearch side) and kibana.yml (on the Kibana side): This is how you disable X-pack modules: # For X-Pack users: you may only leave monitoring on. # Don't add this if X-Pack is not installed at all, or Kibana won't start. xpack.monitoring.enabled: true xpack.security.enabled: false xpack.watcher.enabled: false xpack.telemetry.enabled: false This is a typical example of configuration snippet to add at the end of your readonlyrest.yml (the settings file of the Elasticsearch plugin), to support ReadonlyREST PRO. readonlyrest: access_control_rules: - name: \"::LOGSTASH::\" auth_key: logstash:logstash actions: [\"indices:data/read/*\",\"indices:data/write/*\",\"indices:admin/template/*\",\"indices:admin/create\"] indices: [\"logstash-*\"] - name: \"::KIBANA-SRV::\" auth_key: kibana:kibana - name: \"::RO::\" auth_key: ro:dev kibana_access: ro indices: [ \".kibana\", \"logstash-*\"] kibana_hide_apps: [ \"Security\", \"Enterprise Search\"] - name: \"::RW::\" auth_key: rw:dev kibana_access: rw indices: [\".kibana\", \"logstash-*\"] kibana_hide_apps: [ \"Security\", \"Enterprise Search\"] - name: \"::ADMIN::\" auth_key: admin:dev # KIBANA ADMIN ACCESS NEEDED TO EDIT SECURITY SETTINGS IN ROR KIBANA APP! kibana_access: admin - name: \"::WEBSITE SEARCH BOX::\" indices: [\"public\"] actions: [\"indices:data/read/*\"] Very important ACL blocks ordering matters Blocks related to the authentication of the users should be at the top of the ACL One of the most common mistakes is forgetting that the ACL blocks are evaluated in order from the first to the last. So, some request with credentials can be let through from one of the first blocks and come back to Kibana with no user identity metadata associated. Take this example of troublesome ACL: # PROBLEMATIC SETTINGS (EXAMPLE) \u26a0\ufe0f access_control_rules: - name: \"::FIRST BLOCK::\" hosts: [\"127.0.0.1\"] actions: [...] - name: \"::ADMIN::\" auth_key: admin:dev kibana_access: admin The user will be able to login because the login request will be allowed by the first ACL block. But the ACL will not have resolved any metadata about the user identity (credentials checking was ignored)! This means the response to the Kibana login request will contain no user identity metadata (username, hidden apps, etc) and ReadonlyREST for Kibana won't be able to function correctly. The solution to this is to reorder the ACL blocks, so the ones that authenticate Kibana users are on the top. # SOLUTION: KIBANA USER AUTH RELATED BLOCKS GO FIRST! \u2705\ud83d\udc4d access_control_rules: - name: \"::ADMIN::\" auth_key: admin:dev kibana_access: admin - name: \"::FIRST BLOCK::\" hosts: [\"127.0.0.1\"] actions: [...] Session cookie expiration When a user logs in, ReadonlyREST will write an encrypted cookie in the browser. This cookie has an time to live that can be tweaked with the following configuration key in kibana.yml . readonlyrest_kbn.session_timeout_minutes: 600 # defaults to 4320 (3 days) Clearing Session History By default, all the session data like search history, dev tool commands history, etc, will be wiped out from the browser whenever a new user is logged in, or a user changes tenancy. To override this behaviour, use this setting: readonlyrest_kbn.clearSessionOnEvents: [\"never\"] Possible values: \"login\", \"tenancyHop\", \"never\" . Hiding Kibana Apps This feature will work in ReadonlyREST PRO and Enteprise. Previously we needed to keep track and document all Kibana apps IDs, and you had to look them up all the time. Now we made it simpler by letting you type the apps and submenu titles exactly as you see them in the UI. For example, this is how you hide the whole Enterprise Search submenu. And this is how you hide only one app from the Enterprise Search menu: More generally, either of these two ways will work: kibana_hide_apps: [ \"<submenu-title>\" ] kibana_hide_apps: [ \"<submenu-title|app-title>\" ] For example the following is a valid rule: kibana_hide_apps: [ \"Security\", \"Management|Stack Management\", \"Enterprise Search\" ] Hiding ReadonlyREST menu elements This feature will work in ReadonlyREST PRO and Enteprise. To hide the Manage kibana button for the specific user you need to provide ROR Manage Kibana value into a kibana_hide_apps kibana_hide_apps: [ \"ROR Manage Kibana\" ] To hide the Edit security settings button for the specific user you need to provide ROR Security Settings or readonlyrest_kbn value into a kibana_hide_apps kibana_hide_apps: [ \"ROR Security Settings\" ] Kibana configuration Activate authentication for the Kibana server: let the Kibana daemon connect to Elasticsearch using a pair of credentials we just defined in readonlyrest.yml (see above, the ::KIBANA-SRV:: block). Open up conf/kibana.yml and add the following: # This is kibana.yml, but copy the exact same in elasticsearch.yml if you have to use some X-pack features. xpack.graph.enabled: false xpack.ml.enabled: false xpack.monitoring.enabled: true xpack.security.enabled: false # this is fundamental! xpack.watcher.enabled: false # Kibana server use ::KIBANA-SRV:: credentials elasticsearch.username: \"kibana\" elasticsearch.password: \"kibana\" And of course also make sure elasticsearch.url points to the designated Elasticsearch instance (check also the http or https) Proxy Auth This feature will work in all ReadonlyREST editions. ROR for Elasticsearch can delegate authentication to a reverse proxy which will enforce some kind of authentication, and pass the successfully authenticated user's name inside a X-Forwarded-User header. Today, it's possible to skip the regular ROR login form and use the \"delegated authentication\" technique in ROR for Kibana as well. Configure ROR for ES to expect delegated authentication (see proxy_auth rule ) in ROR for ES documentation. Open up conf/kibana.yml and add readonlyrest_kbn.proxy_auth_passthrough: true Now ROR for Kibana will skip the login form entirely , and will only require that all incoming requests must carry a X-Forwarded-User header containing the user's name. Based on this identity, ROR for Kibana will build an encrypted cookie and handle your session normally. Custom Logout link This feature will work in all ReadonlyREST editions. Normally, when a user presses the logout button in ROR for Kibana, it deletes the encrypted cookie that represents the users identity and the login form is shown. However, when the authentication is delegated to a proxy, the logout button needs to become a link to some URL capable to unregister the session a user initiated within the proxy. For this, ROR for Kibana offers a way to customize the logout button's URL: Find a link that will delete the reverse proxy's user session Open up conf/kibana.yml and add readonlyrest_kbn.custom_logout_link: https://..../logout Now users that gained a session through delegated auth, can also click on the logout button in ROR for kibana and actually exit their session. Custom Login link This feature will work in all ReadonlyREST editions. When you delegate authentication to an external service, you can tell ReadonlyREST to skip the classic login form entirely and redirect users to your proxy or identity provider's login screen. To enable this: Find your authentication proxy or identity provider login URL for the ROR app Open up conf/kibana.yml and add readonlyrest_kbn.custom_login_link: \"https://../login\" The advantage of this approach is a streamlined user experience for users that login with an external IdP. The disadvantage is that you give up the possibility to login as a local user in ROR, as the login form will be always skipped. Caveat Enabling proxy auth passthrough will relax the requirement to provide a password. Therefore, don't enable this option if you don't make sure Kibana can only be accessed through the reverse proxy* . JWT Token Forwarding as URL Query Parameter This feature will work in all ReadonlyREST editions. Alternatively to typing in credentials in the standard login form, it is possible to create an authenticated Kibana session by passing a JWT token as a query parameter in a URL. Configuration To enable this feature in ReadonlyREST, you need to: Have JWT authentication configured in ReadonlyREST (modifying readonlyrest.yml or the cluster wide settings UI in the Kibana plugin). See how . Specify the query parameter name in kibana.yml by adding the line readonlyrest_kbn.jwt_query_param: \"jwt\" as a string, in our case \"jwt\". In Action Once Kibana is restarted, you will be able to navigate to a link like this: http://kibana:5601/login?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzdWIiOiIxMjM0NTY3ODkwIiwibmFtZSI6IkpvaG4gRG9lIiwiYWRtaW4iOnRydWV9.TJVA95OrM7E2cBab30RMHrHDcEfxjoYZgeFONFh7HgQ The following will happen: The Kibana plugin will forward the JWT token found in the query parameter into the Authorization header in a request to Elasticsearch. Elasticsearch will cryptographically authenticate and resolve the user's identity from the JWT claims. Kibana will write an encrypted cookie in your browser and use that from now on for the length of the authenticated session. From here onwards, the session management will be identical to the normal login form flow. When the user presses logout, Kibana will delete the cookie and redirect you to the login form, or whatever link you configured as readonlyrest_kbn.custom_logout_link . Deep linking with JWT Because the identity is embedded in the link, and ReadonlyREST is able to authenticate the call on the fly, the JWT authentication can be used in conjunction with nextUrl query parameter for sharing deep links inside Kibana apps, or embedding visualizations and dashboards inside I-Frames. Anatomy of a JWT deep link http://kibana:5601/login?jwt=<the-token>&nextUrl=urlEncode(<kibana-path>) In Javascript one can compose a JWT deep link as follows: var absoluteKibanaPath = '/app/kibana#/visualize/edit/28dcde30-2258-11e8-82a3-af58d04b3c02?_g=()'; var url = 'http://kibana:5601/login?jwt=' + jwtToken + '&nextUrl=' + encodeURI(absoluteKibanaPath); console.log(\"Final JWT deep link: \" + url) The result may look something like this: http://localhost:5601/login?nextUrl=%2Fapp%2Fkibana%23%2Fvisualize%2Fedit%2F28dcde30-2258-11e8-82a3-af58d04b3c02%3F_g%3D%28%29&jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzdWIiOiIxMjM0NTY3ODkwIiwibmFtZSI6IkpvaG4gRG9lIiwiYWRtaW4iOnRydWV9.TJVA95OrM7E2cBab30RMHrHDcEfxjoYZgeFONFh7HgQ SSL/TLS server You can configure Kibana with ReadonlyREST plugin to accept SSL connection the same way you would with vanilla Kibana configuration. For example, in kibana.yml : server.ssl.enabled: true server.ssl.keystore.path: \"/usr/share/kibana/config/certificates/kibana-server.p12\" server.ssl.keystore.password: \"\" server.ssl.supportedProtocols: [\"TLSv1.2\", \"TLSv1.3\"] Secure cookies ReadonlyREST will set the \"secure\" flag to its Kibana session cookie (\"ror-cookie\") automatically when SSL is enabled in Kibana.\\ \\ This is because modern browsers like Chrome won't accept \"secure\"-flagged cookies if the website is not HTTPS). However, a common situation is when SSL is configured in a reverse proxy (SSL termination): so the browser will interact with Kibana using HTTPS. But because ROR doesn't know it, it will still serve session cookies without the \"secure\" flag.\\ \\ In this case, you can force ReadonlyREST to create \"secure\"-flagged cookies by adding this line in kibana.yml : xpack.security.secureCookies: true Audit log This feature will work in all ReadonlyREST editions. The audit log feature is widely described in \ud83d\udcd6docs for Elasticsearch plugin . Kibana plugin has predefined dashboard representing collected audit data. Loading visualization In the Audit tab of the ReadonlyREST Kibana app, there is a button that automatically creates a dashboard with some audit log specific visualizations. Click the Load button to load the dashboard and visualizations. An Override checkbox allows to reload the default dashboard and visualizations. It will override any previously loaded audit log dashboard. In detail, this feature creates three Kibana \"saved objects\": an index pattern for readonlyrest_audit-* a dashboard called ReadonlyREST Audit Log some visualizations Dashboard The audit log dashboard, by default, has only a few basic visualizations. They cover security, access logs, and performance metrics. SAML This feature will work in ReadonlyREST Enterprise. ReadonlyREST Enterprise supports service provider initiated via SAML. This connector supports both SSO (single sign on) and SLO (single log out). Here is how to configure it. Configure ror_kbn_auth bridge In order for the user identity information to flow securely from Kibana to Elasticsearch, we need to set up the two plugin with a shared secret, that is: an arbitrarily long string. Elasticsearch side Edit readonlyrest.yml readonlyrest: access_control_rules: - name: \"::KIBANA-SRV::\" auth_key: kibana:kibana ... all usual blocks of rules... - name: \"ReadonlyREST Enterprise instance #1\" ror_kbn_auth: name: \"kbn1\" ror_kbn: - name: kbn1 signature_key: \"my_shared_secret_kibana1_(min 256 chars)\" # <- use environmental variables for better security! \u26a0\ufe0fIMPORTANT the Basic HTTP auth credentials for the Kibana server are still needed for now, due to how Kibana works. Kibana side Edit kibana.yml and append: readonlyrest_kbn.auth: signature_key: \"my_shared_secret_kibana1(min 256 chars)\" saml_serv1: enabled: true type: saml issuer: ror buttonName: \"Partner's SSO Login\" entryPoint: 'https://my-saml-idp/saml2/http-post/sso' # <-- identity Provider's URL, to request to sign on kibanaExternalHost: 'my.public.hostname.com' # <-- public URL used by the Identity Provider to call back Kibana with the \"assertion\" message protocol: http # <-- is the Kibana server listening for \"http\" \"https\" connections? Default: http usernameParameter: 'nameID' groupsParameter: 'memberOf' logoutUrl: 'https://my-saml-idp/saml2/http-post/slo' cert: /etc/ror/integration/certs/dag.crt # <-- It can be also provided a string value # OPTIONAL, advanced parameters # decryptionCert: /etc/ror/integration/certs/pub.crt # decryptionPvk: /etc/ror/integration/certs/decrypt_pvk.crt # issuer: saml_sso_idp issuer : issuer string to supply to identity provider during sign on request. Defaults to 'ror' disableRequestedAuthnContext : if truthy, do not request a specific authentication context. This is known to help when authenticating against Active Directory (AD FS) servers. decryptionPvk : Service Provider Private Key. Private key that will be used to attempt to decrypt any encrypted assertions that are received. cert : The downloadable certificate in IDP Metadata (file, absolute path) or single line string value For advanced SAML options, see passport-saml documentation . Identity provider side Enter the settings of your identity provider, create a new app. Configure it using the information found by connecting to http://my.public.hostname.com/ror_kbn_saml_serv1/metadata.xml Example response: <?xml version=\"1.0\"?> <EntityDescriptor xmlns=\"urn:oasis:names:tc:SAML:2.0:metadata\" xmlns:ds=\"http://www.w3.org/2000/09/xmldsig#\" entityID=\"onelogin_saml\" ID=\"onelogin_saml\"> <SPSSODescriptor protocolSupportEnumeration=\"urn:oasis:names:tc:SAML:2.0:protocol\"> <SingleLogoutService Binding=\"urn:oasis:names:tc:SAML:2.0:bindings:HTTP-POST\" Location=\"http://my.public.hostname.com/ror_kbn/notifylogout\"/> <NameIDFormat>urn:oasis:names:tc:SAML:1.1:nameid-format:emailAddress</NameIDFormat> <AssertionConsumerService index=\"1\" isDefault=\"true\" Binding=\"urn:oasis:names:tc:SAML:2.0:bindings:HTTP-POST\" Location=\"http://my.public.hostname.com/ror_kbn/assert\"/> </SPSSODescriptor> </EntityDescriptor> Create some users and some groups in the identity provider app Check the user profile parameter names that the identity provider uses during the assertion callback ( TIP : set kibana in debug mode so ReadonlyREST will print the user profile). Match the name of the parameter used by the identity provider to carry the unique user ID (in the assertion message) to the usernameParameter kibana YAML setting. If you want to use SAML for authorization, take care of matching also the groupsParameter to the parameter name found in the assertion message to the kibana YAML setting. OpenID Connect (OIDC) This feature will work in ReadonlyREST Enterprise. ReadonlyREST Enterprise support OpenID Connect for both authentication and authorization. Here is how to configure it. Configure ror_kbn_auth bridge This part is identical as seen in SAML connectors. In order for the user identity information to flow securely from Kibana to Elasticsearch, we need to set up the two plugin with a shared secret, that is: an arbitrarily long string. Elasticsearch side Edit readonlyrest.yml readonlyrest: access_control_rules: - name: \"::KIBANA-SRV::\" auth_key: kibana:kibana ... all usual blocks of rules... - name: \"ReadonlyREST Enterprise instance #1\" ror_kbn_auth: name: \"kbn1\" ror_kbn: - name: kbn1 signature_key: \"my_shared_secret_kibana1_(min 256 chars)\" # <- use environmental variables for better security! \u26a0\ufe0fIMPORTANT the Basic HTTP auth credentials for the Kibana server are still needed for now, due to how Kibana works. If you have configured OIDC with the groupsParameter ( See below ), you can also restrict ACL to specific groups: readonlyrest: access_control_rules: - name: \"::KIBANA-SRV::\" auth_key: kibana:kibana ... all usual blocks of rules... - name: \"ReadonlyREST Enterprise instance #1 for group 1\" ror_kbn_auth: name: \"kbn1\" groups: [\"group1\"] - name: \"ReadonlyREST Enterprise instance #1 for group 2\" ror_kbn_auth: name: \"kbn1\" groups: [\"group2\"] ror_kbn: - name: kbn1 signature_key: \"my_shared_secret_kibana1_(min 256 chars)\" # <- use environmental variables for better security! You may also use any custom claim from the OIDC userinfo token in ACL rules by using {{jwt:assertion.<path_to_your_claim>}} syntax. See the dedicated section for more information. ( TIP : Do not forget the assertion prefix in front of you jsonpath. ) Kibana side We will assume the OpenID identity provider responds to port 8080 of localhost. In our example, we used Keycloak, an open source implementation of OpenID Connect identity provide. Edit kibana.yml and append: readonlyrest_kbn.auth: signature_key: \"my_shared_secret_kibana1(min 256 chars)\" oidc_kc: buttonName: \"KeyCloak OpenID\" type: \"oidc\" issuer: 'http://localhost:8080/auth/realms/ror' authorizationURL: 'http://localhost:8080/auth/realms/ror/protocol/openid-connect/auth' tokenURL: 'http://localhost:8080/auth/realms/ror/protocol/openid-connect/token' userInfoURL: 'http://localhost:8080/auth/realms/ror/protocol/openid-connect/userinfo' clientID: 'ror_oidc' clientSecret: '9f1d39c8-a211-460a-84b6-0a4a1499c455' scope: 'openid profile roles role_list email' usernameParameter: 'preferred_username' groupsParameter: 'groups' kibanaExternalHost: 'localhost:5601' logoutUrl: 'http://localhost:8080/auth/realms/ror/protocol/openid-connect/logout' jwksURL: 'http://localhost:8080/auth/realms/ror/protocol/openid-connect/certs' Identity provider side Enter the settings interface of your identity provider, and create a new OpenID app . The redirect URL should be configured as http://localhost:5601/* assuming kibana is listening on localhost and on the default port. Create some users and some groups in the identity provider if not present. Check the user profile parameter names that the identity provider uses during the assertion callback ( TIP : set readonlyrest_kbn.logLevel: debug` in kibana.yml, so you will see the user profile how it's received from the identity provider right in the logs). Match the name of the parameter used by the identity provider to carry the unique user ID (in the assertion message) to the usernameParameter kibana YAML setting. If you want to use OpenID for authorization, take care of matching also the groupsParameter to the parameter name found in the assertion message to the kibana YAML setting. ( TIP : the groupsParameter must be present in the userinfo token of your OIDC provider.) If kibana is accessed through a reverse proxy, kibanaExternalHost should be configured with the external hostname. if omitted, the default value is equals to server.host:server.port defined in kibana.yml. ( This parameter can be used also when kibana is bound to 0.0.0.0, for example, if using docker.) Load balancers These features will work with all ReadonlyREST Editions Enable health check endpoint Normally a load balancer needs a health check URL to see if the instance is still running, you can whitelist this Kibana path so the load balancer avoids a redirection to /login . Edit kibana.yml readonlyrest_kbn.whitelistedPaths: [\".*/api/status$\"] Session management with multiple Kibana instances Each Kibana node stores user sessions in-memory. This will cause problems when using multiple Kibana instances behind a load balancer (especially without sticky sessions), as there would be no synchronization between nodes' sessions cache. To avoid this, session synchronization via an Elasticsearch index should be enabled. Follow these steps: Come up with a string of at least 32 characters length or more to be used as the shared cookie encryption key, called cookiePass . Open up conf/kibana.yml and add: readonlyrest_kbn.cookiePass: \"generatedStringIn1step\" (example: \"12345678901234567890123456789012\") readonlyrest_kbn.cookieName (custom cookie name - this property is optional, if not specified default cookie name would be rorCookie ) readonlyrest_kbn.store_sessions_in_index: true (enable session storage in index) readonlyrest_kbn.sessions_index_name: \"someCustomIndexName\" (index name - this property is optional, if not specified default index would be .readonlyrest_kbn_sessions ) readonlyrest_kbn.sessions_refresh_after: 5000 (time in milliseconds, describes how often sessions should be fetched from ES and refreshed for each node - optional, by default 2 seconds) readonlyrest_kbn.sessions_probe_interval_seconds: 120 (default 60s) how often should the browser poll Kibana to check if their session is still valid. Raise this value if you connect to Kibana through slow networks (i.e. VPN), or have very slow loading dashboards. Add the above config in all Kibana nodes behind the load balancer, and restart them. Login screen tweaking These features will work with ReadonlyREST PRO and Enterprise. It is possible to customize the look of the login screen. Two column layout By default,the login form appears in a single column view. But once title and subtitle are configured, it will switch to two columns for making room to the new text. readonlyrest_kbn.login_title: \"Some Title\" readonlyrest_kbn.login_subtitle: \"Longer text <b>any HTML is supported<b/> including ifrmaes\" Add your company logo It's recommended to use a transparent PNG, negative logo. Ideally a white foreground, and transparent background. Open config/kibana.yml and append the following: readonlyrest_kbn.login_custom_logo: 'https://.../logo.png' Add custom CSS/JS You have the opportunity to inject HTML code right before the closing head tag ( </head> ). Open config/kibana.yml and append the following: readonlyrest_kbn.login_html_head_inject: '<style> * { color:red; }</style>' Kibana UI tweaking This feature will work with Readonlyrest Enterprise It's possible to inject custom CSS and Javascript to achieve a customised user experience for your users/tenants. Inject custom CSS in Kibana Open config/kibana.yml and append the following: readonlyrest_kbn.kibana_custom_css_inject: '.global-nav, kbnGlobalNav { background-color: green }' Alternatively, it's possible to load the CSS from a file in the filesystem: readonlyrest_kbn.kibana_custom_css_inject_file: '/tmp/custom.css' \u26a0\ufe0fIMPORTANT If you use relative paths, you end up pointing to kibana home, i.e. readonlyrest_kbn.kibana_custom_css_inject_file: 'config/custom.css' will refer to $KBN_HOME/config/custom.css which is the same directory where kibana.yml can normally be found. Inject custom JS in Kibana readonlyrest_kbn.kibana_custom_js_inject: '$(\".global-nav__logo\").hide(); alert(\"hello!\")' Alternatively, it's possible to load the JS from a file in the filesystem: readonlyrest_kbn.kibana_custom_js_inject_file: '/tmp/custom.js' \u26a0\ufe0fIMPORTANT If you use relative paths, you end up pointing to kibana home, i.e. readonlyrest_kbn.kibana_custom_js_inject: 'config/custom.js' will refer to $KBN_HOME/config/custom.js which is the same directory where kibana.yml can normally be found. Map groups to aliases You can provide a function, mapping group names to aliases of your choosing. To do so, add the following line to config/kibana.yml : readonlyrest_kbn.groupsMapping: '(group) => group.toLowerCase()' \u26a0\ufe0fIMPORTANT The mapping function has to return a string. Otherwise, an error will be printed in kibana logs and the original group name will be used as fallback. Also, if the mapping function is not specified, the original group name value will be used. Tenancy index templating This feature will work only with ReadonlyREST Enterprise When a tenants logs in for the first time, ReadonlyREST Enterprise will create the \".kibana\" index associated to the tenancy. For example, it will create and initialize the \".kibana_user1\" index, where \"user1\" will store all the visualizations, dashboards, settings and index-patterns. The issue is that \"user1\"'s user experience will be really raw as they will see a completely blank Kibana tenancy. Not even a default index pattern will be present. And this is particularly challenging if the tenant is supposed to be read-only (i.e. kibana_access: \"ro\") because they won't even have privileges to create their own index-pattern, let alone any dashboards. To fix this, ReadonlyREST Enterprise offers the possibility for administrators to create a template kibana index from which all the Kibana objects will be copied over to the newly initialised tenancy. How to use tenancy templating An administrator will need to create the template tenancy, populate it with the default Kibana objects (index-patterns, dashboards) and configure ReadonlyREST Enterprise to take the index template it in use. Let's see this step by step: Create the template tenancy Let's start to add to our access control list (found in $ES_PATH_CONF/config/readonlyrest.yml, or ReadonlyREST App in Kibana) a local user \"administrator\" that will belong to two tenancies: the default one (stored in .kibana index), and the template one (stored in .kibana_template index). readonlyrest: audit_collector: true access_control_rules: - name: \"::KIBANA-SRV::\" auth_key: kibana:kibana verbosity: error - name: \"Admin Tenancy\" groups: [\"Admins\"] verbosity: error kibana_access: admin kibana_index: \".kibana\" - name: \"Template Tenancy\" groups: [\"Template\"] verbosity: error kibana_access: admin kibana_index: \".kibana_template\" users: - username: administrator auth_key: administrator:dev groups: [\"Admins\", \"Template\"] # can hop between two tenancies with top-left drop-down menu NB: If you know what you are doing, you can add a tenancy with kibana_index: \".kibana_template\" adding a LDAP/SAML group to your administrative user. Configure the template tenancy Now login as administrator in Kibana, hop into the \"Template\" tenancy, and start configuring the default UX for your future tenants. Add all the index patterns, create or import all the dashboards you want. Configure the template tenancy index in ReadonlyREST Enterprise Open kibana.yml and add the following line: readonlyrest_kbn.kibanaIndexTemplate: \".kibana_template\" Now, ReadonlyREST Enterprise will look for the \".kibana_template\" index, and try to copy over all its documents every time a new kibana index is initialised to support a new tenancy. Try it out Restart Kibana with the new setting. Add a new tenancy to the ACL: readonlyrest: audit_collector: true access_control_rules: - name: \"::KIBANA-SRV::\" auth_key: kibana:kibana verbosity: error - name: \"Admin Tenancy\" groups: [\"Admins\"] verbosity: error kibana_access: admin kibana_index: \".kibana\" - name: \"Template Tenancy\" groups: [\"Template\"] verbosity: error kibana_access: admin kibana_index: \".kibana_template\" # Newly added tenant! - name: user1 auth_key: user1:passwd kibana_access: rw kibana_index: \".kibana_user1\" users: - username: administrator auth_key: administrator:dev groups: [\"Admins\", \"Template\"] # can hop between two tenancies with top-left drop-down menu ` Now try to login as user1, and ReadonlyREST Enterprise should initialise the index \".kibana_user1\" with all the index patterns and dashboards contained in the template tenancy. Impersonation According to Wikipedia : An impersonator is someone who imitates or copies the behavior or actions of another. So, an impersonation can be understood as imitating behaviors or actions. In the context of ReadonlyREST: one user could imitate an action of another user. Why would we want it? Let's suppose the first user is an admin, who has just configured access for a new user. They would like to know if the rule(s) are configured correctly. And here comes the impersonation feature. The admin can impersonate given user in Kibana and see what the user would see if they logged in themselves. ROR plugins support impersonation and provide UI for configuring cluster before using it. Visit the impersonation details page to know more.","title":"For Kibana"},{"location":"kibana/#for-kibana","text":"\ud83e\uddd9 Are you using Kibana version 7.8.x or older? Go to the old platform manual page .","title":"For Kibana"},{"location":"kibana/#kibana-plugin-overview","text":"ReadonlyREST plugin for Kibana is not open source, and it's offered as part of the ReadonlyREST PRO and ReadonlyREST ENTERPRISE , and ReadonlyREST Free packages. See product descriptions and a comparison chart in the official ReadonlyREST website ReadonlyREST plugins for Kibana always require ReadonlyREST Free to be installed in the Elasticsearch nodes your Kibana instance(s) will connect to. It's not mandatory to install ReadonlyREST Free in all Elasticsearch nodes, but only in the ones in where you need the HTTP interface to be secured.","title":"Kibana Plugin overview"},{"location":"kibana/#after-purchasing","text":"You will receive a link to the plugin zip file in an email. Download your zip. You will be able to download it also in the future as long as your subscription is active.","title":"After purchasing"},{"location":"kibana/#version-strings","text":"All our plugins include in their file name a version string. For example the file readonlyrest-1.16.26_es6.4.0.zip has a version string 1.16.26_es6.4.0 .","title":"Version strings"},{"location":"kibana/#reading-version-strings","text":"Given the version string 1.16.26_es6.4.0 ReadonlyREST plugin code version 1.16.26 Works only with Elasticsearch/Kibana version 6.4.0 The \"es\" stands for \"Elastic stack\" which used to mean the family of products made by Elastic which get released at the same time under the same version number. This was chosen before Elastic renamed their X-Pack commercial offer to Elastic Stack. To be clear, there is no affiliation between ReadonlyREST and Elastic, or their commercial products.","title":"Reading version strings"},{"location":"kibana/#trial-builds-version-strings","text":"Trial builds are valid for 30 days after they were built, and they will stop working soon after the time is elapsed. Trial builds have a special version string which includes a build-time timestamp. I.e. readonlyrest_kbn_pro-1.16.26-20180911_es6.0.0.zip ReadonlyREST PRO plugin version 1.16.26 Build date 11th September 2018, expiring on the 11th of October 2018. Works only with Kibana version 6.0.0","title":"Trial builds version strings"},{"location":"kibana/#when-an-update-is-out","text":"You will receive another email notification that a new deliverable is available. If the update contains a security fix, it is very important that you take action and update the plugin immediately .","title":"When an update is out"},{"location":"kibana/#installation","text":"You can install this as a normal Kibana plugin using the bin/kibana-plugin utility. Let's see a two ways to use this utility with ReadonlyREST. {% hint style=\"warning\" %} Don't forget After Kibana 7.9.x, it's necessary to patch Kibana after you install, otherwise ReadonlyREST will NOT work. {% endhint %}","title":"Installation"},{"location":"kibana/#installing-via-url","text":"This installation method is more practical if your Kibana server is connected to the internet. According to what edition of ReadonlyREST you want to install, from your Kibana installation, launch one of the commands: Please note that this will always download the latest version of Kibana plugin available for the current supported Elasticsearch version. # ReadonlyREST Free edition $ bin/kibana-plugin install \"https://api.beshu.tech/download/kbn?edition=kbn_free&email=<your_email_address>\" # ReadonlyREST PRO (30 days trial) edition $ bin/kibana-plugin install \"https://api.beshu.tech/download/trial?edition=kbn_pro&email=<your_email_address>\" # ReadonlyREST Enterprise (30 days trial) edition $ bin/kibana-plugin install \"https://api.beshu.tech/download/trial?edition=kbn_enterprise&email=<your_email_address>\" If you want to download the latest version of plugin for a specific version of Elasticsearch, then use query parameter esVersion to specify your required Elasticsearch version. # ReadonlyREST Free edition for Elasticsearch 7.6.1 $ bin/kibana-plugin install \"https://api.beshu.tech/download/kbn?edition=kbn_free&esVersion=7.6.1&email=<your_email_address>\" # ReadonlyREST PRO (30 days trial) edition for Elasticsearch 7.6.1 $ bin/kibana-plugin install \"https://api.beshu.tech/download/trial?edition=kbn_pro&esVersion=7.6.1&email=<your_email_address>\" # ReadonlyREST Enterprise (30 days trial) edition for Elasticsearch 7.6.1 $ bin/kibana-plugin install \"https://api.beshu.tech/download/trial?edition=kbn_enterprise&esVersion=7.6.1&email=<your_email_address>\" If you want to download an older version of plugin for a specific version of Elasticsearch, then use query parameter pluginVersion along with esVersion . # ReadonlyREST Free edition - version 1.22.0 for Elasticsearch 7.6.1 $ bin/kibana-plugin install \"https://api.beshu.tech/download/kbn?edition=kbn_free&esVersion=7.6.1&pluginVersion=1.22.0&email=<your_email_address>\" # ReadonlyREST PRO (30 days trial) edition - version 1.22.0 for Elasticsearch 7.6.1 $ bin/kibana-plugin install \"https://api.beshu.tech/download/trial?edition=kbn_pro&esVersion=7.6.1&pluginVersion=1.22.0&email=<your_email_address>\" # ReadonlyREST Enterprise (30 days trial) edition - version 1.22.0 for Elasticsearch 7.6.1 $ bin/kibana-plugin install \"https://api.beshu.tech/download/trial?edition=kbn_enterprise&esVersion=7.6.1&pluginVersion=1.22.0&email=<your_email_address>\" If you are a PRO or Enterprise subscriber, the link will include an extra parameter \"token\" which can only be used in association with the provided email address. You can append required plugin version and Elasticsearch version query parameters to download specific version as described above. NB: This URL is personal, and should be handled as a secret. # ReadonlyREST PRO (Official) edition $ bin/kibana-plugin install \"https://api.beshu.tech/download/trial?edition=kbn_pro&email=<your_email_address>&token=<your_secret_token>\" # ReadonlyREST Enterprise (30 days trial) edition $ bin/kibana-plugin install \"https://api.beshu.tech/download/trial?edition=kbn_enterprise&email=<your_email_address>&token=<your_secret_token>\" You can obtain official links with personal secret tokens using our self service download form , once your email address has been recognized as active subscriber. Now you are ready to patch Kibana .","title":"Installing via URL"},{"location":"kibana/#installing-from-zip-file","text":"$ bin/kibana-plugin install file:///home/user/downloads/readonlyrest_kbn-X.Y.Z_esW.Q.U.zip Notice how we need to type in the format file:// + absolute path (yes, with three slashes).","title":"Installing from zip file"},{"location":"kibana/#patching-kibana","text":"If you are using Kibana 7.9.x or newer, you need an extra post-installation step . This will slightly modify some core Kibana files. # Patch Kibana core files $ node/bin/node plugins/readonlyrestkbn/ror-tools.js patch","title":"Patching Kibana"},{"location":"kibana/#unpatching-kibana","text":"If you are using Kibana 7.9.x or newer, you need an extra pre-uninstallation step . This will restore the core Kibana files to the original state. # Unpatch Kibana core files $ node/bin/node plugins/readonlyrestkbn/ror-tools.js unpatch","title":"Unpatching Kibana"},{"location":"kibana/#uninstalling","text":"{% hint style=\"info\" %} To uninstall, you should unpatch Kibana first, then uninstall ReadonlyREST plugin. However the Kibana plugin system uninstallation process is highly unreliable . So we highly recomend to throw away the entire Kibana directory, and start from scratch. Ideally, use ephemeral docker containers. Need inspiration? Try ROR Docker demo ! {% endhint %} To bring Kibana to its pre-patching original state, it's possible to unpatch. # Un-patch Kibana core files $ node/bin/node plugins/readonlyrestkbn/ror-tools.js unpatch # Uninstall normally $ bin/kibana-plugin remove readonlyrestkbn And the classic uninstall command... $ bin/kibana-plugin remove readonlyrest_kbn","title":"Uninstalling"},{"location":"kibana/#upgrading","text":"To upgrade to a new version of a ReadonlyREST plugins for Kibana, you should: Unpatch Kibana Uninstall the old plugin Delete all the content of \"optimize\" directory (in the main Kibana installation directory) rm -rf optimize/ Install the new one Patch Kibana Restart Kibana.","title":"Upgrading"},{"location":"kibana/#using-ror-with-a-reverse-proxy","text":"RoR - just like Kibana itself - is meant to be used either with a proxy or without one. If you decide to set the server.basePath property in kibana.yml and set server.rewriteBasePath into a true , RoR will be accessed directly and via a reverse proxy, If you decided to rewrite the base path manually by your reverse proxy and set the server.rewriteBasePath property in kibana.yml into a false , be sure to access RoR via a proxy, as it will not work properly when accessed directly.","title":"Using RoR with a reverse proxy"},{"location":"kibana/#configuration","text":"ReadonlyREST for Kibana is completely remote-controlled from the Elasticsearch configuration. Login credentials, hidden Kibana apps, etc. are all going to be configured from the Elasticearch side via the usual \"rules\". This means the configuration will be kept all in one place and if you used ReadonlyREST before , it will be also very familiar. In this document, every time you will encounter references to \"readonlyrest.yml\" or \"elasticsearch.yml\", we will be referring to the configuration files in the Elasticsearch plugin (our Kibana plugins do not need a \"readonlyrest.yml\"). In general, by design, we tend to concentrate all configuration within the main plugin (the Elasticsearch one) as much as possible.","title":"Configuration"},{"location":"kibana/#clusterwide-settings-vs-readonlyrestyml","text":"This feature is available in Free and PRO editions Our Kibana plugins introduce a \"ReadonlyREST\" Kibana app. From here, you can edit the security settings of the whole Elasticsearch cluster, and they will take effect within 10 seconds in all Elasticsearch cluster nodes without the need to restart them. When you change the security settings from the Kibana app, they will be saved in a special index called \".readonlyrest\", so all the Elasticsearch nodes will pick them up. You can customize a name of the index by setting readonlyrest.settings_index: .my_custom_readonlyrest in elasticsearch.yml file (remember to set the same value for all your ES nodes). When an Elasticsearch node restarts, the order of settings evaluation is the following: 1. Attempt to find valid settings in readonlyrest.yml 2. If none is found, look inside elasticsearch.yml 3. Once successfully bootstrapped using file-based settings, attempt to read \".readonlyrest\" index 4. If the index exists and contains valid settings, override file based settings with the ones from the index. 5. Pressing \"save\" in the cluster wide settings app, will not overwrite the readonlyrest.yml file. Best practices: Build and update your production security settings from the Kibana app (will be saved in index) Protect the \".readonlyrest\" Kibana index with an ACL rule","title":"Clusterwide Settings VS readonlyrest.yml"},{"location":"kibana/#loading-settings-order-of-precedence","text":"As you read, there are two possible places where the settings can be read from: readonlyrest.yml a file the user needs to create in the same directory where elasticsearch.yml is found. .readonlyrest index. Our Kibana plugins' GUI (PRO/Enterprise) is programmed to write this index. When the ES plugin boots up, it follows some logic to evaluate where to read the YAML settings from. The following diagram shows how that works.","title":"Loading settings: order of precedence"},{"location":"kibana/#malformed-in-index-settings","text":"If for some reason the in-index settings get corrupted and ROR can't parse them, then neither settings from file or in-index settings can be loaded, so ES can't start. In this case ES would print message like: Loading ReadonlyREST settings from index failed: Settings config content is malformed. Details: while scanning a quoted scalar in 'reader', line 9, column 17: auth_key: \"admin:container ^ To recover from this state, set readonlyrest.force_load_from_file: true in elasticsearch.yaml on one node es1 . Example recovery settings: elasticsearch.yaml [...] readonlyrest: force_load_from_file: true readonlyrest.yaml readonlyrest: access_control_rules: - name: \"::ADMIN recover::\" auth_key: admin:dev indices: [\"*\"] Then remove in-index settings index manually. curl -X DELETE \"admin:dev@es1:9200/.readonlyrest?pretty\" Now you can restore your settings to readonlyrest.yml , remove readonlyrest.force_load_from_file: true from elasticsearch.yaml and restart node.","title":"Malformed in-index settings"},{"location":"kibana/#example-multiuser-elk","text":"This configuration will work in PRO and Enterprise editions Make sure X-Pack is uninstalled or disabled from elasticsearch.yml (on the Elasticsearch side) and kibana.yml (on the Kibana side): This is how you disable X-pack modules: # For X-Pack users: you may only leave monitoring on. # Don't add this if X-Pack is not installed at all, or Kibana won't start. xpack.monitoring.enabled: true xpack.security.enabled: false xpack.watcher.enabled: false xpack.telemetry.enabled: false This is a typical example of configuration snippet to add at the end of your readonlyrest.yml (the settings file of the Elasticsearch plugin), to support ReadonlyREST PRO. readonlyrest: access_control_rules: - name: \"::LOGSTASH::\" auth_key: logstash:logstash actions: [\"indices:data/read/*\",\"indices:data/write/*\",\"indices:admin/template/*\",\"indices:admin/create\"] indices: [\"logstash-*\"] - name: \"::KIBANA-SRV::\" auth_key: kibana:kibana - name: \"::RO::\" auth_key: ro:dev kibana_access: ro indices: [ \".kibana\", \"logstash-*\"] kibana_hide_apps: [ \"Security\", \"Enterprise Search\"] - name: \"::RW::\" auth_key: rw:dev kibana_access: rw indices: [\".kibana\", \"logstash-*\"] kibana_hide_apps: [ \"Security\", \"Enterprise Search\"] - name: \"::ADMIN::\" auth_key: admin:dev # KIBANA ADMIN ACCESS NEEDED TO EDIT SECURITY SETTINGS IN ROR KIBANA APP! kibana_access: admin - name: \"::WEBSITE SEARCH BOX::\" indices: [\"public\"] actions: [\"indices:data/read/*\"]","title":"Example: multiuser ELK"},{"location":"kibana/#very-important","text":"","title":"Very important"},{"location":"kibana/#acl-blocks-ordering-matters","text":"Blocks related to the authentication of the users should be at the top of the ACL One of the most common mistakes is forgetting that the ACL blocks are evaluated in order from the first to the last. So, some request with credentials can be let through from one of the first blocks and come back to Kibana with no user identity metadata associated. Take this example of troublesome ACL: # PROBLEMATIC SETTINGS (EXAMPLE) \u26a0\ufe0f access_control_rules: - name: \"::FIRST BLOCK::\" hosts: [\"127.0.0.1\"] actions: [...] - name: \"::ADMIN::\" auth_key: admin:dev kibana_access: admin The user will be able to login because the login request will be allowed by the first ACL block. But the ACL will not have resolved any metadata about the user identity (credentials checking was ignored)! This means the response to the Kibana login request will contain no user identity metadata (username, hidden apps, etc) and ReadonlyREST for Kibana won't be able to function correctly. The solution to this is to reorder the ACL blocks, so the ones that authenticate Kibana users are on the top. # SOLUTION: KIBANA USER AUTH RELATED BLOCKS GO FIRST! \u2705\ud83d\udc4d access_control_rules: - name: \"::ADMIN::\" auth_key: admin:dev kibana_access: admin - name: \"::FIRST BLOCK::\" hosts: [\"127.0.0.1\"] actions: [...]","title":"ACL blocks ordering matters"},{"location":"kibana/#session-cookie-expiration","text":"When a user logs in, ReadonlyREST will write an encrypted cookie in the browser. This cookie has an time to live that can be tweaked with the following configuration key in kibana.yml . readonlyrest_kbn.session_timeout_minutes: 600 # defaults to 4320 (3 days)","title":"Session cookie expiration"},{"location":"kibana/#clearing-session-history","text":"By default, all the session data like search history, dev tool commands history, etc, will be wiped out from the browser whenever a new user is logged in, or a user changes tenancy. To override this behaviour, use this setting: readonlyrest_kbn.clearSessionOnEvents: [\"never\"] Possible values: \"login\", \"tenancyHop\", \"never\" .","title":"Clearing Session History"},{"location":"kibana/#hiding-kibana-apps","text":"This feature will work in ReadonlyREST PRO and Enteprise. Previously we needed to keep track and document all Kibana apps IDs, and you had to look them up all the time. Now we made it simpler by letting you type the apps and submenu titles exactly as you see them in the UI. For example, this is how you hide the whole Enterprise Search submenu. And this is how you hide only one app from the Enterprise Search menu: More generally, either of these two ways will work: kibana_hide_apps: [ \"<submenu-title>\" ] kibana_hide_apps: [ \"<submenu-title|app-title>\" ] For example the following is a valid rule: kibana_hide_apps: [ \"Security\", \"Management|Stack Management\", \"Enterprise Search\" ]","title":"Hiding Kibana Apps"},{"location":"kibana/#hiding-readonlyrest-menu-elements","text":"This feature will work in ReadonlyREST PRO and Enteprise. To hide the Manage kibana button for the specific user you need to provide ROR Manage Kibana value into a kibana_hide_apps kibana_hide_apps: [ \"ROR Manage Kibana\" ] To hide the Edit security settings button for the specific user you need to provide ROR Security Settings or readonlyrest_kbn value into a kibana_hide_apps kibana_hide_apps: [ \"ROR Security Settings\" ]","title":"Hiding ReadonlyREST menu elements"},{"location":"kibana/#kibana-configuration","text":"Activate authentication for the Kibana server: let the Kibana daemon connect to Elasticsearch using a pair of credentials we just defined in readonlyrest.yml (see above, the ::KIBANA-SRV:: block). Open up conf/kibana.yml and add the following: # This is kibana.yml, but copy the exact same in elasticsearch.yml if you have to use some X-pack features. xpack.graph.enabled: false xpack.ml.enabled: false xpack.monitoring.enabled: true xpack.security.enabled: false # this is fundamental! xpack.watcher.enabled: false # Kibana server use ::KIBANA-SRV:: credentials elasticsearch.username: \"kibana\" elasticsearch.password: \"kibana\" And of course also make sure elasticsearch.url points to the designated Elasticsearch instance (check also the http or https)","title":"Kibana configuration"},{"location":"kibana/#proxy-auth","text":"This feature will work in all ReadonlyREST editions. ROR for Elasticsearch can delegate authentication to a reverse proxy which will enforce some kind of authentication, and pass the successfully authenticated user's name inside a X-Forwarded-User header. Today, it's possible to skip the regular ROR login form and use the \"delegated authentication\" technique in ROR for Kibana as well. Configure ROR for ES to expect delegated authentication (see proxy_auth rule ) in ROR for ES documentation. Open up conf/kibana.yml and add readonlyrest_kbn.proxy_auth_passthrough: true Now ROR for Kibana will skip the login form entirely , and will only require that all incoming requests must carry a X-Forwarded-User header containing the user's name. Based on this identity, ROR for Kibana will build an encrypted cookie and handle your session normally.","title":"Proxy Auth"},{"location":"kibana/#custom-logout-link","text":"This feature will work in all ReadonlyREST editions. Normally, when a user presses the logout button in ROR for Kibana, it deletes the encrypted cookie that represents the users identity and the login form is shown. However, when the authentication is delegated to a proxy, the logout button needs to become a link to some URL capable to unregister the session a user initiated within the proxy. For this, ROR for Kibana offers a way to customize the logout button's URL: Find a link that will delete the reverse proxy's user session Open up conf/kibana.yml and add readonlyrest_kbn.custom_logout_link: https://..../logout Now users that gained a session through delegated auth, can also click on the logout button in ROR for kibana and actually exit their session.","title":"Custom Logout link"},{"location":"kibana/#custom-login-link","text":"This feature will work in all ReadonlyREST editions. When you delegate authentication to an external service, you can tell ReadonlyREST to skip the classic login form entirely and redirect users to your proxy or identity provider's login screen. To enable this: Find your authentication proxy or identity provider login URL for the ROR app Open up conf/kibana.yml and add readonlyrest_kbn.custom_login_link: \"https://../login\" The advantage of this approach is a streamlined user experience for users that login with an external IdP. The disadvantage is that you give up the possibility to login as a local user in ROR, as the login form will be always skipped.","title":"Custom Login link"},{"location":"kibana/#caveat","text":"Enabling proxy auth passthrough will relax the requirement to provide a password. Therefore, don't enable this option if you don't make sure Kibana can only be accessed through the reverse proxy* .","title":"Caveat"},{"location":"kibana/#jwt-token-forwarding-as-url-query-parameter","text":"This feature will work in all ReadonlyREST editions. Alternatively to typing in credentials in the standard login form, it is possible to create an authenticated Kibana session by passing a JWT token as a query parameter in a URL.","title":"JWT Token Forwarding as URL Query Parameter"},{"location":"kibana/#configuration_1","text":"To enable this feature in ReadonlyREST, you need to: Have JWT authentication configured in ReadonlyREST (modifying readonlyrest.yml or the cluster wide settings UI in the Kibana plugin). See how . Specify the query parameter name in kibana.yml by adding the line readonlyrest_kbn.jwt_query_param: \"jwt\" as a string, in our case \"jwt\".","title":"Configuration"},{"location":"kibana/#in-action","text":"Once Kibana is restarted, you will be able to navigate to a link like this: http://kibana:5601/login?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzdWIiOiIxMjM0NTY3ODkwIiwibmFtZSI6IkpvaG4gRG9lIiwiYWRtaW4iOnRydWV9.TJVA95OrM7E2cBab30RMHrHDcEfxjoYZgeFONFh7HgQ The following will happen: The Kibana plugin will forward the JWT token found in the query parameter into the Authorization header in a request to Elasticsearch. Elasticsearch will cryptographically authenticate and resolve the user's identity from the JWT claims. Kibana will write an encrypted cookie in your browser and use that from now on for the length of the authenticated session. From here onwards, the session management will be identical to the normal login form flow. When the user presses logout, Kibana will delete the cookie and redirect you to the login form, or whatever link you configured as readonlyrest_kbn.custom_logout_link . Deep linking with JWT Because the identity is embedded in the link, and ReadonlyREST is able to authenticate the call on the fly, the JWT authentication can be used in conjunction with nextUrl query parameter for sharing deep links inside Kibana apps, or embedding visualizations and dashboards inside I-Frames. Anatomy of a JWT deep link http://kibana:5601/login?jwt=<the-token>&nextUrl=urlEncode(<kibana-path>) In Javascript one can compose a JWT deep link as follows: var absoluteKibanaPath = '/app/kibana#/visualize/edit/28dcde30-2258-11e8-82a3-af58d04b3c02?_g=()'; var url = 'http://kibana:5601/login?jwt=' + jwtToken + '&nextUrl=' + encodeURI(absoluteKibanaPath); console.log(\"Final JWT deep link: \" + url) The result may look something like this: http://localhost:5601/login?nextUrl=%2Fapp%2Fkibana%23%2Fvisualize%2Fedit%2F28dcde30-2258-11e8-82a3-af58d04b3c02%3F_g%3D%28%29&jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzdWIiOiIxMjM0NTY3ODkwIiwibmFtZSI6IkpvaG4gRG9lIiwiYWRtaW4iOnRydWV9.TJVA95OrM7E2cBab30RMHrHDcEfxjoYZgeFONFh7HgQ","title":"In Action"},{"location":"kibana/#ssltls-server","text":"You can configure Kibana with ReadonlyREST plugin to accept SSL connection the same way you would with vanilla Kibana configuration. For example, in kibana.yml : server.ssl.enabled: true server.ssl.keystore.path: \"/usr/share/kibana/config/certificates/kibana-server.p12\" server.ssl.keystore.password: \"\" server.ssl.supportedProtocols: [\"TLSv1.2\", \"TLSv1.3\"]","title":"SSL/TLS server"},{"location":"kibana/#secure-cookies","text":"ReadonlyREST will set the \"secure\" flag to its Kibana session cookie (\"ror-cookie\") automatically when SSL is enabled in Kibana.\\ \\ This is because modern browsers like Chrome won't accept \"secure\"-flagged cookies if the website is not HTTPS). However, a common situation is when SSL is configured in a reverse proxy (SSL termination): so the browser will interact with Kibana using HTTPS. But because ROR doesn't know it, it will still serve session cookies without the \"secure\" flag.\\ \\ In this case, you can force ReadonlyREST to create \"secure\"-flagged cookies by adding this line in kibana.yml : xpack.security.secureCookies: true","title":"Secure cookies"},{"location":"kibana/#audit-log","text":"This feature will work in all ReadonlyREST editions. The audit log feature is widely described in \ud83d\udcd6docs for Elasticsearch plugin . Kibana plugin has predefined dashboard representing collected audit data.","title":"Audit log"},{"location":"kibana/#loading-visualization","text":"In the Audit tab of the ReadonlyREST Kibana app, there is a button that automatically creates a dashboard with some audit log specific visualizations. Click the Load button to load the dashboard and visualizations. An Override checkbox allows to reload the default dashboard and visualizations. It will override any previously loaded audit log dashboard. In detail, this feature creates three Kibana \"saved objects\": an index pattern for readonlyrest_audit-* a dashboard called ReadonlyREST Audit Log some visualizations","title":"Loading visualization"},{"location":"kibana/#dashboard","text":"The audit log dashboard, by default, has only a few basic visualizations. They cover security, access logs, and performance metrics.","title":"Dashboard"},{"location":"kibana/#saml","text":"This feature will work in ReadonlyREST Enterprise. ReadonlyREST Enterprise supports service provider initiated via SAML. This connector supports both SSO (single sign on) and SLO (single log out). Here is how to configure it.","title":"SAML"},{"location":"kibana/#configure-ror_kbn_auth-bridge","text":"In order for the user identity information to flow securely from Kibana to Elasticsearch, we need to set up the two plugin with a shared secret, that is: an arbitrarily long string.","title":"Configure ror_kbn_auth bridge"},{"location":"kibana/#elasticsearch-side","text":"Edit readonlyrest.yml readonlyrest: access_control_rules: - name: \"::KIBANA-SRV::\" auth_key: kibana:kibana ... all usual blocks of rules... - name: \"ReadonlyREST Enterprise instance #1\" ror_kbn_auth: name: \"kbn1\" ror_kbn: - name: kbn1 signature_key: \"my_shared_secret_kibana1_(min 256 chars)\" # <- use environmental variables for better security! \u26a0\ufe0fIMPORTANT the Basic HTTP auth credentials for the Kibana server are still needed for now, due to how Kibana works.","title":"Elasticsearch side"},{"location":"kibana/#kibana-side","text":"Edit kibana.yml and append: readonlyrest_kbn.auth: signature_key: \"my_shared_secret_kibana1(min 256 chars)\" saml_serv1: enabled: true type: saml issuer: ror buttonName: \"Partner's SSO Login\" entryPoint: 'https://my-saml-idp/saml2/http-post/sso' # <-- identity Provider's URL, to request to sign on kibanaExternalHost: 'my.public.hostname.com' # <-- public URL used by the Identity Provider to call back Kibana with the \"assertion\" message protocol: http # <-- is the Kibana server listening for \"http\" \"https\" connections? Default: http usernameParameter: 'nameID' groupsParameter: 'memberOf' logoutUrl: 'https://my-saml-idp/saml2/http-post/slo' cert: /etc/ror/integration/certs/dag.crt # <-- It can be also provided a string value # OPTIONAL, advanced parameters # decryptionCert: /etc/ror/integration/certs/pub.crt # decryptionPvk: /etc/ror/integration/certs/decrypt_pvk.crt # issuer: saml_sso_idp issuer : issuer string to supply to identity provider during sign on request. Defaults to 'ror' disableRequestedAuthnContext : if truthy, do not request a specific authentication context. This is known to help when authenticating against Active Directory (AD FS) servers. decryptionPvk : Service Provider Private Key. Private key that will be used to attempt to decrypt any encrypted assertions that are received. cert : The downloadable certificate in IDP Metadata (file, absolute path) or single line string value For advanced SAML options, see passport-saml documentation .","title":"Kibana side"},{"location":"kibana/#identity-provider-side","text":"Enter the settings of your identity provider, create a new app. Configure it using the information found by connecting to http://my.public.hostname.com/ror_kbn_saml_serv1/metadata.xml Example response: <?xml version=\"1.0\"?> <EntityDescriptor xmlns=\"urn:oasis:names:tc:SAML:2.0:metadata\" xmlns:ds=\"http://www.w3.org/2000/09/xmldsig#\" entityID=\"onelogin_saml\" ID=\"onelogin_saml\"> <SPSSODescriptor protocolSupportEnumeration=\"urn:oasis:names:tc:SAML:2.0:protocol\"> <SingleLogoutService Binding=\"urn:oasis:names:tc:SAML:2.0:bindings:HTTP-POST\" Location=\"http://my.public.hostname.com/ror_kbn/notifylogout\"/> <NameIDFormat>urn:oasis:names:tc:SAML:1.1:nameid-format:emailAddress</NameIDFormat> <AssertionConsumerService index=\"1\" isDefault=\"true\" Binding=\"urn:oasis:names:tc:SAML:2.0:bindings:HTTP-POST\" Location=\"http://my.public.hostname.com/ror_kbn/assert\"/> </SPSSODescriptor> </EntityDescriptor> Create some users and some groups in the identity provider app Check the user profile parameter names that the identity provider uses during the assertion callback ( TIP : set kibana in debug mode so ReadonlyREST will print the user profile). Match the name of the parameter used by the identity provider to carry the unique user ID (in the assertion message) to the usernameParameter kibana YAML setting. If you want to use SAML for authorization, take care of matching also the groupsParameter to the parameter name found in the assertion message to the kibana YAML setting.","title":"Identity provider side"},{"location":"kibana/#openid-connect-oidc","text":"This feature will work in ReadonlyREST Enterprise. ReadonlyREST Enterprise support OpenID Connect for both authentication and authorization. Here is how to configure it.","title":"OpenID Connect (OIDC)"},{"location":"kibana/#configure-ror_kbn_auth-bridge_1","text":"This part is identical as seen in SAML connectors. In order for the user identity information to flow securely from Kibana to Elasticsearch, we need to set up the two plugin with a shared secret, that is: an arbitrarily long string.","title":"Configure ror_kbn_auth bridge"},{"location":"kibana/#elasticsearch-side_1","text":"Edit readonlyrest.yml readonlyrest: access_control_rules: - name: \"::KIBANA-SRV::\" auth_key: kibana:kibana ... all usual blocks of rules... - name: \"ReadonlyREST Enterprise instance #1\" ror_kbn_auth: name: \"kbn1\" ror_kbn: - name: kbn1 signature_key: \"my_shared_secret_kibana1_(min 256 chars)\" # <- use environmental variables for better security! \u26a0\ufe0fIMPORTANT the Basic HTTP auth credentials for the Kibana server are still needed for now, due to how Kibana works. If you have configured OIDC with the groupsParameter ( See below ), you can also restrict ACL to specific groups: readonlyrest: access_control_rules: - name: \"::KIBANA-SRV::\" auth_key: kibana:kibana ... all usual blocks of rules... - name: \"ReadonlyREST Enterprise instance #1 for group 1\" ror_kbn_auth: name: \"kbn1\" groups: [\"group1\"] - name: \"ReadonlyREST Enterprise instance #1 for group 2\" ror_kbn_auth: name: \"kbn1\" groups: [\"group2\"] ror_kbn: - name: kbn1 signature_key: \"my_shared_secret_kibana1_(min 256 chars)\" # <- use environmental variables for better security! You may also use any custom claim from the OIDC userinfo token in ACL rules by using {{jwt:assertion.<path_to_your_claim>}} syntax. See the dedicated section for more information. ( TIP : Do not forget the assertion prefix in front of you jsonpath. )","title":"Elasticsearch side"},{"location":"kibana/#kibana-side_1","text":"We will assume the OpenID identity provider responds to port 8080 of localhost. In our example, we used Keycloak, an open source implementation of OpenID Connect identity provide. Edit kibana.yml and append: readonlyrest_kbn.auth: signature_key: \"my_shared_secret_kibana1(min 256 chars)\" oidc_kc: buttonName: \"KeyCloak OpenID\" type: \"oidc\" issuer: 'http://localhost:8080/auth/realms/ror' authorizationURL: 'http://localhost:8080/auth/realms/ror/protocol/openid-connect/auth' tokenURL: 'http://localhost:8080/auth/realms/ror/protocol/openid-connect/token' userInfoURL: 'http://localhost:8080/auth/realms/ror/protocol/openid-connect/userinfo' clientID: 'ror_oidc' clientSecret: '9f1d39c8-a211-460a-84b6-0a4a1499c455' scope: 'openid profile roles role_list email' usernameParameter: 'preferred_username' groupsParameter: 'groups' kibanaExternalHost: 'localhost:5601' logoutUrl: 'http://localhost:8080/auth/realms/ror/protocol/openid-connect/logout' jwksURL: 'http://localhost:8080/auth/realms/ror/protocol/openid-connect/certs'","title":"Kibana side"},{"location":"kibana/#identity-provider-side_1","text":"Enter the settings interface of your identity provider, and create a new OpenID app . The redirect URL should be configured as http://localhost:5601/* assuming kibana is listening on localhost and on the default port. Create some users and some groups in the identity provider if not present. Check the user profile parameter names that the identity provider uses during the assertion callback ( TIP : set readonlyrest_kbn.logLevel: debug` in kibana.yml, so you will see the user profile how it's received from the identity provider right in the logs). Match the name of the parameter used by the identity provider to carry the unique user ID (in the assertion message) to the usernameParameter kibana YAML setting. If you want to use OpenID for authorization, take care of matching also the groupsParameter to the parameter name found in the assertion message to the kibana YAML setting. ( TIP : the groupsParameter must be present in the userinfo token of your OIDC provider.) If kibana is accessed through a reverse proxy, kibanaExternalHost should be configured with the external hostname. if omitted, the default value is equals to server.host:server.port defined in kibana.yml. ( This parameter can be used also when kibana is bound to 0.0.0.0, for example, if using docker.)","title":"Identity provider side"},{"location":"kibana/#load-balancers","text":"These features will work with all ReadonlyREST Editions","title":"Load balancers"},{"location":"kibana/#enable-health-check-endpoint","text":"Normally a load balancer needs a health check URL to see if the instance is still running, you can whitelist this Kibana path so the load balancer avoids a redirection to /login . Edit kibana.yml readonlyrest_kbn.whitelistedPaths: [\".*/api/status$\"]","title":"Enable health check endpoint"},{"location":"kibana/#session-management-with-multiple-kibana-instances","text":"Each Kibana node stores user sessions in-memory. This will cause problems when using multiple Kibana instances behind a load balancer (especially without sticky sessions), as there would be no synchronization between nodes' sessions cache. To avoid this, session synchronization via an Elasticsearch index should be enabled. Follow these steps: Come up with a string of at least 32 characters length or more to be used as the shared cookie encryption key, called cookiePass . Open up conf/kibana.yml and add: readonlyrest_kbn.cookiePass: \"generatedStringIn1step\" (example: \"12345678901234567890123456789012\") readonlyrest_kbn.cookieName (custom cookie name - this property is optional, if not specified default cookie name would be rorCookie ) readonlyrest_kbn.store_sessions_in_index: true (enable session storage in index) readonlyrest_kbn.sessions_index_name: \"someCustomIndexName\" (index name - this property is optional, if not specified default index would be .readonlyrest_kbn_sessions ) readonlyrest_kbn.sessions_refresh_after: 5000 (time in milliseconds, describes how often sessions should be fetched from ES and refreshed for each node - optional, by default 2 seconds) readonlyrest_kbn.sessions_probe_interval_seconds: 120 (default 60s) how often should the browser poll Kibana to check if their session is still valid. Raise this value if you connect to Kibana through slow networks (i.e. VPN), or have very slow loading dashboards. Add the above config in all Kibana nodes behind the load balancer, and restart them.","title":"Session management with multiple Kibana instances"},{"location":"kibana/#login-screen-tweaking","text":"These features will work with ReadonlyREST PRO and Enterprise. It is possible to customize the look of the login screen.","title":"Login screen tweaking"},{"location":"kibana/#two-column-layout","text":"By default,the login form appears in a single column view. But once title and subtitle are configured, it will switch to two columns for making room to the new text. readonlyrest_kbn.login_title: \"Some Title\" readonlyrest_kbn.login_subtitle: \"Longer text <b>any HTML is supported<b/> including ifrmaes\"","title":"Two column layout"},{"location":"kibana/#add-your-company-logo","text":"It's recommended to use a transparent PNG, negative logo. Ideally a white foreground, and transparent background. Open config/kibana.yml and append the following: readonlyrest_kbn.login_custom_logo: 'https://.../logo.png'","title":"Add your company logo"},{"location":"kibana/#add-custom-cssjs","text":"You have the opportunity to inject HTML code right before the closing head tag ( </head> ). Open config/kibana.yml and append the following: readonlyrest_kbn.login_html_head_inject: '<style> * { color:red; }</style>'","title":"Add custom CSS/JS"},{"location":"kibana/#kibana-ui-tweaking","text":"This feature will work with Readonlyrest Enterprise It's possible to inject custom CSS and Javascript to achieve a customised user experience for your users/tenants.","title":"Kibana UI tweaking"},{"location":"kibana/#inject-custom-css-in-kibana","text":"Open config/kibana.yml and append the following: readonlyrest_kbn.kibana_custom_css_inject: '.global-nav, kbnGlobalNav { background-color: green }' Alternatively, it's possible to load the CSS from a file in the filesystem: readonlyrest_kbn.kibana_custom_css_inject_file: '/tmp/custom.css' \u26a0\ufe0fIMPORTANT If you use relative paths, you end up pointing to kibana home, i.e. readonlyrest_kbn.kibana_custom_css_inject_file: 'config/custom.css' will refer to $KBN_HOME/config/custom.css which is the same directory where kibana.yml can normally be found.","title":"Inject custom CSS in Kibana"},{"location":"kibana/#inject-custom-js-in-kibana","text":"readonlyrest_kbn.kibana_custom_js_inject: '$(\".global-nav__logo\").hide(); alert(\"hello!\")' Alternatively, it's possible to load the JS from a file in the filesystem: readonlyrest_kbn.kibana_custom_js_inject_file: '/tmp/custom.js' \u26a0\ufe0fIMPORTANT If you use relative paths, you end up pointing to kibana home, i.e. readonlyrest_kbn.kibana_custom_js_inject: 'config/custom.js' will refer to $KBN_HOME/config/custom.js which is the same directory where kibana.yml can normally be found.","title":"Inject custom JS in Kibana"},{"location":"kibana/#map-groups-to-aliases","text":"You can provide a function, mapping group names to aliases of your choosing. To do so, add the following line to config/kibana.yml : readonlyrest_kbn.groupsMapping: '(group) => group.toLowerCase()' \u26a0\ufe0fIMPORTANT The mapping function has to return a string. Otherwise, an error will be printed in kibana logs and the original group name will be used as fallback. Also, if the mapping function is not specified, the original group name value will be used.","title":"Map groups to aliases"},{"location":"kibana/#tenancy-index-templating","text":"This feature will work only with ReadonlyREST Enterprise When a tenants logs in for the first time, ReadonlyREST Enterprise will create the \".kibana\" index associated to the tenancy. For example, it will create and initialize the \".kibana_user1\" index, where \"user1\" will store all the visualizations, dashboards, settings and index-patterns. The issue is that \"user1\"'s user experience will be really raw as they will see a completely blank Kibana tenancy. Not even a default index pattern will be present. And this is particularly challenging if the tenant is supposed to be read-only (i.e. kibana_access: \"ro\") because they won't even have privileges to create their own index-pattern, let alone any dashboards. To fix this, ReadonlyREST Enterprise offers the possibility for administrators to create a template kibana index from which all the Kibana objects will be copied over to the newly initialised tenancy.","title":"Tenancy index templating"},{"location":"kibana/#how-to-use-tenancy-templating","text":"An administrator will need to create the template tenancy, populate it with the default Kibana objects (index-patterns, dashboards) and configure ReadonlyREST Enterprise to take the index template it in use. Let's see this step by step:","title":"How to use tenancy templating"},{"location":"kibana/#create-the-template-tenancy","text":"Let's start to add to our access control list (found in $ES_PATH_CONF/config/readonlyrest.yml, or ReadonlyREST App in Kibana) a local user \"administrator\" that will belong to two tenancies: the default one (stored in .kibana index), and the template one (stored in .kibana_template index). readonlyrest: audit_collector: true access_control_rules: - name: \"::KIBANA-SRV::\" auth_key: kibana:kibana verbosity: error - name: \"Admin Tenancy\" groups: [\"Admins\"] verbosity: error kibana_access: admin kibana_index: \".kibana\" - name: \"Template Tenancy\" groups: [\"Template\"] verbosity: error kibana_access: admin kibana_index: \".kibana_template\" users: - username: administrator auth_key: administrator:dev groups: [\"Admins\", \"Template\"] # can hop between two tenancies with top-left drop-down menu NB: If you know what you are doing, you can add a tenancy with kibana_index: \".kibana_template\" adding a LDAP/SAML group to your administrative user.","title":"Create the template tenancy"},{"location":"kibana/#configure-the-template-tenancy","text":"Now login as administrator in Kibana, hop into the \"Template\" tenancy, and start configuring the default UX for your future tenants. Add all the index patterns, create or import all the dashboards you want.","title":"Configure the template tenancy"},{"location":"kibana/#configure-the-template-tenancy-index-in-readonlyrest-enterprise","text":"Open kibana.yml and add the following line: readonlyrest_kbn.kibanaIndexTemplate: \".kibana_template\" Now, ReadonlyREST Enterprise will look for the \".kibana_template\" index, and try to copy over all its documents every time a new kibana index is initialised to support a new tenancy.","title":"Configure the template tenancy index in ReadonlyREST Enterprise"},{"location":"kibana/#try-it-out","text":"Restart Kibana with the new setting. Add a new tenancy to the ACL: readonlyrest: audit_collector: true access_control_rules: - name: \"::KIBANA-SRV::\" auth_key: kibana:kibana verbosity: error - name: \"Admin Tenancy\" groups: [\"Admins\"] verbosity: error kibana_access: admin kibana_index: \".kibana\" - name: \"Template Tenancy\" groups: [\"Template\"] verbosity: error kibana_access: admin kibana_index: \".kibana_template\" # Newly added tenant! - name: user1 auth_key: user1:passwd kibana_access: rw kibana_index: \".kibana_user1\" users: - username: administrator auth_key: administrator:dev groups: [\"Admins\", \"Template\"] # can hop between two tenancies with top-left drop-down menu ` Now try to login as user1, and ReadonlyREST Enterprise should initialise the index \".kibana_user1\" with all the index patterns and dashboards contained in the template tenancy.","title":"Try it out"},{"location":"kibana/#impersonation","text":"According to Wikipedia : An impersonator is someone who imitates or copies the behavior or actions of another. So, an impersonation can be understood as imitating behaviors or actions. In the context of ReadonlyREST: one user could imitate an action of another user. Why would we want it? Let's suppose the first user is an admin, who has just configured access for a new user. They would like to know if the rule(s) are configured correctly. And here comes the impersonation feature. The admin can impersonate given user in Kibana and see what the user would see if they logged in themselves. ROR plugins support impersonation and provide UI for configuring cluster before using it. Visit the impersonation details page to know more.","title":"Impersonation"},{"location":"actionstrings/","text":"List of Elasticsearch actions available in various Elasticsearch versions We automated the extraction from source code of all the action strings available in major Elasticsearch versions to your convenience when using the \"actions\" rule in ReadonlyREST ACL. For more information about the ACL and the actions rule, refer to our documentation . If your Elasticsearch version is not present? Please request us to add it: https://readonlyrest.com/contact-us/","title":"List of Elasticsearch actions available in various Elasticsearch versions"},{"location":"actionstrings/#list-of-elasticsearch-actions-available-in-various-elasticsearch-versions","text":"We automated the extraction from source code of all the action strings available in major Elasticsearch versions to your convenience when using the \"actions\" rule in ReadonlyREST ACL. For more information about the ACL and the actions rule, refer to our documentation .","title":"List of Elasticsearch actions available in various Elasticsearch versions"},{"location":"actionstrings/#if-your-elasticsearch-version-is-not-present","text":"Please request us to add it: https://readonlyrest.com/contact-us/","title":"If your Elasticsearch version is not present?"},{"location":"details/fips/","text":"FIPS mode What is FIPS? According to Wikipedia Federal Information Processing Standards (FIPS) are publicly announced standards developed by the National Institute of Standards and Technology for use in computer systems by non-military American government agencies and government contractors. FIPS standards are issued to establish requirements for various purposes such as ensuring computer security and interoperability and are intended for cases in which suitable industry standards do not already exist. In short it is a thoroughly tested and verified set of standards which could be used to implement high level of security. In terms of software we are usually speaking specifically about FIPS 140-2. ReadonlyREST uses OpenSource BouncyCastle library to provide FIPS 140-2 compliant algorithms. Is ReadonlyREST fully compliant to FIPS 140-2? At the moment, ReadonlyREST can be configured as FIPS compliant only from the \"data in transit\" standpoint. That is, the SSL encryption of the HTTP and transport interfaces. Other aspects remain to be covered: * Making all cryptographic algorithms FIPS compliant. * Enforcing more strict security policies across whole ROR plugin in FIPS mode. How to enable SSL FIPS compliance Prepare keystore and truststore in BCFKS format which is FIPS compliant. Your existing JKS or PKCS12 keystore could be easily converted to BCFKS. Process is described in this section . :warning: BCFKS format is supported only when FIPS mode is enabled. It won't be recognised otherwise. :warning: When using FIPS mode using different password for specific keystore elements is not supported and key_pass configuration field is ignored. Configure readonlyrest.yml to use new keystore and truststore. You will also need to add new configuration parameter fips_mode . Here's an example: readonlyrest: fips_mode: SSL_ONLY ssl: enable: true keystore_file: \"keystore.bcfks\" keystore_pass: readonlyrest truststore_file: \"truststore.bcfks\" truststore_pass: readonlyrest ssl_internode: enable: true keystore_file: \"keystore.bcfks\" keystore_pass: readonlyrest truststore_file: \"truststore.bcfks\" truststore_pass: readonlyrest In case you are using ES >= 7.10 you need to modify $JAVA_HOME/conf/security/java.policy file and add this section at the end of it. This is required because otherwise Elasticsearch will not be able grant to our plugin all these permissions at the JVM level. grant { permission org.bouncycastle.crypto.CryptoServicesPermission \"exportSecretKey\"; permission org.bouncycastle.crypto.CryptoServicesPermission \"exportPrivateKey\"; permission java.security.SecurityPermission \"getProperty.jdk.tls.disabledAlgorithms\"; permission java.security.SecurityPermission \"getProperty.jdk.certpath.disabledAlgorithms\"; permission java.security.SecurityPermission \"getProperty.keystore.type.compat\"; permission java.security.SecurityPermission \"removeProvider.SunRsaSign\"; permission java.security.SecurityPermission \"removeProvider.SunJSSE\"; permission java.io.FilePermission \"${java.home}/lib/security/jssecacerts\", \"read\"; permission java.io.FilePermission \"${java.home}/lib/security/cacerts\", \"read\"; permission java.security.SecurityPermission \"getProperty.jdk.tls.server.defaultDHEParameters\"; permission org.bouncycastle.crypto.CryptoServicesPermission \"defaultRandomConfig\"; }; How to convert JKS/PKCS12 keystore files into BCFKS Download the jar with bc-fips library and place it preferably in the same directory where you store keystore files to convert. Open your terminal and go to directory with the keystore to convert Use keytool with following parameters to perform the conversion: keytool \\ -importkeystore \\ -srckeystore SOURCE_KEYSTORE_FILENAME \\ -destkeystore DEST_KEYSTORE_FILENAME \\ -srcstoretype SOURCE_KEYSTORE_TYPE \\ -deststoretype DEST_KEYSTORE_TYPE \\ -srcstorepass SOURCE_KEYSTORE_PASSWORD \\ -deststorepass DEST_KEYSTORE_PASSWORD \\ -providerpath ./bc-fips-1.0.2.1.jar \\ -provider org.bouncycastle.jcajce.provider.BouncyCastleFipsProvider where: SOURCE_KEYSTORE_FILENAME - filename of the keystore(or truststore) that you want to convert. DEST_KEYSTORE_FILENAME - name of the output file. SOURCE_KEYSTORE_TYPE - type of keystore to convert. Must be JKS or PKCS12. DEST_KEYSTORE_TYPE - type of output keystore. Must be BCFKS. SOURCE_KEYSTORE_PASSWORD - password protecting keystore to convert. DEST_KEYSTORE_PASSWORD - password protecting output file. If you saved the bc-fips jar in a different path, remember to run it using the appropriate path instead of ./bc-fips-1.0.2.1.jar","title":"FIPS mode"},{"location":"details/fips/#fips-mode","text":"","title":"FIPS mode"},{"location":"details/fips/#what-is-fips","text":"According to Wikipedia Federal Information Processing Standards (FIPS) are publicly announced standards developed by the National Institute of Standards and Technology for use in computer systems by non-military American government agencies and government contractors. FIPS standards are issued to establish requirements for various purposes such as ensuring computer security and interoperability and are intended for cases in which suitable industry standards do not already exist. In short it is a thoroughly tested and verified set of standards which could be used to implement high level of security. In terms of software we are usually speaking specifically about FIPS 140-2. ReadonlyREST uses OpenSource BouncyCastle library to provide FIPS 140-2 compliant algorithms.","title":"What is FIPS?"},{"location":"details/fips/#is-readonlyrest-fully-compliant-to-fips-140-2","text":"At the moment, ReadonlyREST can be configured as FIPS compliant only from the \"data in transit\" standpoint. That is, the SSL encryption of the HTTP and transport interfaces. Other aspects remain to be covered: * Making all cryptographic algorithms FIPS compliant. * Enforcing more strict security policies across whole ROR plugin in FIPS mode.","title":"Is ReadonlyREST fully compliant to FIPS 140-2?"},{"location":"details/fips/#how-to-enable-ssl-fips-compliance","text":"Prepare keystore and truststore in BCFKS format which is FIPS compliant. Your existing JKS or PKCS12 keystore could be easily converted to BCFKS. Process is described in this section . :warning: BCFKS format is supported only when FIPS mode is enabled. It won't be recognised otherwise. :warning: When using FIPS mode using different password for specific keystore elements is not supported and key_pass configuration field is ignored. Configure readonlyrest.yml to use new keystore and truststore. You will also need to add new configuration parameter fips_mode . Here's an example: readonlyrest: fips_mode: SSL_ONLY ssl: enable: true keystore_file: \"keystore.bcfks\" keystore_pass: readonlyrest truststore_file: \"truststore.bcfks\" truststore_pass: readonlyrest ssl_internode: enable: true keystore_file: \"keystore.bcfks\" keystore_pass: readonlyrest truststore_file: \"truststore.bcfks\" truststore_pass: readonlyrest In case you are using ES >= 7.10 you need to modify $JAVA_HOME/conf/security/java.policy file and add this section at the end of it. This is required because otherwise Elasticsearch will not be able grant to our plugin all these permissions at the JVM level. grant { permission org.bouncycastle.crypto.CryptoServicesPermission \"exportSecretKey\"; permission org.bouncycastle.crypto.CryptoServicesPermission \"exportPrivateKey\"; permission java.security.SecurityPermission \"getProperty.jdk.tls.disabledAlgorithms\"; permission java.security.SecurityPermission \"getProperty.jdk.certpath.disabledAlgorithms\"; permission java.security.SecurityPermission \"getProperty.keystore.type.compat\"; permission java.security.SecurityPermission \"removeProvider.SunRsaSign\"; permission java.security.SecurityPermission \"removeProvider.SunJSSE\"; permission java.io.FilePermission \"${java.home}/lib/security/jssecacerts\", \"read\"; permission java.io.FilePermission \"${java.home}/lib/security/cacerts\", \"read\"; permission java.security.SecurityPermission \"getProperty.jdk.tls.server.defaultDHEParameters\"; permission org.bouncycastle.crypto.CryptoServicesPermission \"defaultRandomConfig\"; };","title":"How to enable SSL FIPS compliance"},{"location":"details/fips/#how-to-convert-jkspkcs12-keystore-files-into-bcfks","text":"Download the jar with bc-fips library and place it preferably in the same directory where you store keystore files to convert. Open your terminal and go to directory with the keystore to convert Use keytool with following parameters to perform the conversion: keytool \\ -importkeystore \\ -srckeystore SOURCE_KEYSTORE_FILENAME \\ -destkeystore DEST_KEYSTORE_FILENAME \\ -srcstoretype SOURCE_KEYSTORE_TYPE \\ -deststoretype DEST_KEYSTORE_TYPE \\ -srcstorepass SOURCE_KEYSTORE_PASSWORD \\ -deststorepass DEST_KEYSTORE_PASSWORD \\ -providerpath ./bc-fips-1.0.2.1.jar \\ -provider org.bouncycastle.jcajce.provider.BouncyCastleFipsProvider where: SOURCE_KEYSTORE_FILENAME - filename of the keystore(or truststore) that you want to convert. DEST_KEYSTORE_FILENAME - name of the output file. SOURCE_KEYSTORE_TYPE - type of keystore to convert. Must be JKS or PKCS12. DEST_KEYSTORE_TYPE - type of output keystore. Must be BCFKS. SOURCE_KEYSTORE_PASSWORD - password protecting keystore to convert. DEST_KEYSTORE_PASSWORD - password protecting output file. If you saved the bc-fips jar in a different path, remember to run it using the appropriate path instead of ./bc-fips-1.0.2.1.jar","title":"How to convert JKS/PKCS12 keystore files into BCFKS"},{"location":"details/fls-engine/","text":"FLS engine Applicable in context of fields rule FLS engine specifies how ROR handles field level security internally. Previously FLS was based entirely on Lucene - that's why ROR needed to be installed on all nodes to make fields rule work properly. Now fields rule is more flexible and part of FLS responsibilities is handled solely by ES. Increasing ES usage and reducing Lucene exploitation in FLS implementation makes rule more efficient. Unfortunately, a few FLS functionalities still have to be handled at Lucene level, and cannot benefit of the new ES level implementation (see supported at ES level requests ) Lucene is still used by fields rule when ES is not able to handle request properly (as kind of a fallback). Configuration FLS engine can be configured with global, optional property fls_engine set under readonlyrest: section. There are two engines available: es_with_lucene (default) \u26a0\ufe0fIMPORTANT As Lucene is part of this engine, ReadonlyREST plugin still needs to be installed in all the cluster nodes that contain data. Default hybrid approach - major part of FLS is handled by ES. Corner cases are passed to Lucene. This solution handles all requests properly being more performant than old full Lucene based approach. es FLS is handled only by ES, without fallback to Lucene. When ES is not able to handle FLS properly, fields rule is not matched. In es engine FLS is not available for some type of requests (requirements listed below). Major advantage of this approach is not relying on Lucene, so ROR doesn't need to be installed on all nodes . If lack of full FLS support is unacceptable and all type of requests needs to be handled properly (rule matching, no rejection) it's advised to use more reliable es_with_lucene engine. ES limitations Supported by es fls engine requests are: all Get/MGet API requests Search/MSearch/AsyncSearch API requests with following restrictions: not using script fields used query is one of: common terms match bool match match phrase match phrase prefix exists fuzzy prefix range regexp term wildcard terms set bool boosting constant score dis max defined query is not using wildcards in field names defined compound queries using only listed above supported queries as inner queries If the request doesn't meet above requirements (e.g. it's using query_string or script fields), the es engine would reject it. Example configuration (ROR using es fls engine): ```yaml readonlyrest: fls_engine: \"es\" access_control_rules: - name: \"user_using_fields\" auth_key: user:pass fields: [\"~someNotAllowedField\"] ``` Property fls_engine can be omitted, then by default ROR uses es_with_lucene fls engine.","title":"FLS engine"},{"location":"details/fls-engine/#fls-engine","text":"Applicable in context of fields rule FLS engine specifies how ROR handles field level security internally. Previously FLS was based entirely on Lucene - that's why ROR needed to be installed on all nodes to make fields rule work properly. Now fields rule is more flexible and part of FLS responsibilities is handled solely by ES. Increasing ES usage and reducing Lucene exploitation in FLS implementation makes rule more efficient. Unfortunately, a few FLS functionalities still have to be handled at Lucene level, and cannot benefit of the new ES level implementation (see supported at ES level requests ) Lucene is still used by fields rule when ES is not able to handle request properly (as kind of a fallback).","title":"FLS engine"},{"location":"details/fls-engine/#configuration","text":"FLS engine can be configured with global, optional property fls_engine set under readonlyrest: section. There are two engines available: es_with_lucene (default) \u26a0\ufe0fIMPORTANT As Lucene is part of this engine, ReadonlyREST plugin still needs to be installed in all the cluster nodes that contain data. Default hybrid approach - major part of FLS is handled by ES. Corner cases are passed to Lucene. This solution handles all requests properly being more performant than old full Lucene based approach. es FLS is handled only by ES, without fallback to Lucene. When ES is not able to handle FLS properly, fields rule is not matched. In es engine FLS is not available for some type of requests (requirements listed below). Major advantage of this approach is not relying on Lucene, so ROR doesn't need to be installed on all nodes . If lack of full FLS support is unacceptable and all type of requests needs to be handled properly (rule matching, no rejection) it's advised to use more reliable es_with_lucene engine.","title":"Configuration"},{"location":"details/fls-engine/#es-limitations","text":"Supported by es fls engine requests are: all Get/MGet API requests Search/MSearch/AsyncSearch API requests with following restrictions: not using script fields used query is one of: common terms match bool match match phrase match phrase prefix exists fuzzy prefix range regexp term wildcard terms set bool boosting constant score dis max defined query is not using wildcards in field names defined compound queries using only listed above supported queries as inner queries If the request doesn't meet above requirements (e.g. it's using query_string or script fields), the es engine would reject it. Example configuration (ROR using es fls engine): ```yaml readonlyrest: fls_engine: \"es\" access_control_rules: - name: \"user_using_fields\" auth_key: user:pass fields: [\"~someNotAllowedField\"] ``` Property fls_engine can be omitted, then by default ROR uses es_with_lucene fls engine.","title":"ES limitations"},{"location":"details/groups-rule-mapping/","text":"External to local groups mapping The groups ACL rule accepts a list of group names. This rule will match on a requests in which the resolved username belongs at least to one of the listed groups. The association between usernames and groups is explicitly declared in the users section of the ACL. This is a list of usernames, and today, full wildcard patterns are also supported. In the users section, each entry requires: * an authentication rule: (I.e. one of the auth_key_* rules for local credentials, or ldap_authentication , external_authentication , etc) * a list of groups within the ones precendently inserted in the groups rules of the ACL blocks * optionally, an authorization rule ( ldap_authorization , groups_provider_authorization , etc.) When the users section's groups rule and the authorization rule are used together, we obtain \"group mapping\". That is: we are effectively mapping remote groups to local groups. There are two types of mapping available: common and detailed group mappings. Note: the rule ldap_auth is the composition of ldap_authentication and ldap_authorization . So it can be used as a shortcut for both. Example readonlyrest: access_control_rules: - name: \"Viewer block\" indices: [\"logstash-viewers*\"] groups: [\"viewers\"] - name: \"DevOps block\" indices: [\"logstash-devops*\"] groups: [\"devops\"] [...] users: # PLAIN LOCAL GROUPS EXAMPLE # Local user \"joe\" is associated to local group \"editors\" - username: \"joe\" groups: [\"editors\"] auth_key: joe:password # COMMON GROUP MAPPING EXAMPLE # Externally authenticated user + authorization via external groups provider + groups common mapping # Users belonging to \"external_group1\" OR \"external_group2\" are authorized as \"viewers\" AND \"editors\" in the ACL. - username: \"*\" groups: [\"viewers\", \"editors\"] external_authentication: \"ext1\" groups_provider_authorization: user_groups_provider: \"ext2\" groups: [\"external_group1\", \"external_group2\"] # DETAILED GROUP MAPPING EXAMPLE # LDAP authenticated user + authorization via LDAP + groups detailed mapping (any LDAP user is valid; groups from `ldap1` are mapped to local groups) # Users belonging to LDAP `ldap_role_devops` OR `ldap_role_ops` are mapped to \"devops\" local group # AND # Users belonging to LDAP `ldap_role_dev` are mapped to \"developers\" local group - username: \"*\" groups: - devops: [\"ldap_role_devops\", \"ldap_role_ops\"] - developers: [\"ldap_role_dev\"] ldap_auth: name: \"ldap1\" groups: [\"ldap_role_devops\", \"ldap_role_ops\", \"ldap_role_dev\"] external_authentication_service_configs: - name: \"ext1\" [...] user_groups_providers: - name: ext2 [...] ldaps: - name: ldap1 [...] As we can see, there are two blocks in our ACL: Viewer block allows all users, which belong to viewers group, to access indices matching pattern logstash-viewers* DevOps block allows all users, which belong to devops group, to access indices matching pattern logstash-devops* Common mapping example - username: \"*\" groups: [\"viewers\", \"editors\"] external_authentication: \"ext1\" groups_provider_authorization: user_groups_provider: \"ext2\" groups: [\"external_group1\", \"external_group2\"] viewers , devops , (unused in the ACL example), editors and developers are local groups. That is, they exist only at ROR's configuration level. But ROR can also integrate with external authorization systems like an LDAP or some REST service, where we can find similar concepts to ROR groups (eg. users in LDAP can have roles assigned). And sometimes we'd like to fulfil a requirement such as: Users having usernames defined by a given pattern, and having a given set of roles, should have certain given ROR internal groups assigned. You can think about it as a mapping external groups to local ones. Let's go back to our example. In the second element of the users array, we declare that: any user can be taken into consideration by this user definition a user should be authenticated by an external_authentication rule which uses the ext1 service a user should be authorized by a groups_provider_authorization rule which uses the ext2 service and such user belongs to at least one of external_group1 , external_group2 external groups. if all the above conditions are true, we can assign viewers , editors groups to the user We have just \"mapped\" the external groups external_group1 , external_group2 returned by service ext2 to the local ROR groups viewers , editors . Detailed mapping example - username: \"*\" groups: - devops: [\"ldap_role_devops\", \"ldap_role_ops\"] - developers: [\"ldap_role_dev\"] ldap_auth: name: \"ldap1\" groups: [\"ldap_role_devops\", \"ldap_role_ops\", \"ldap_role_dev\"] The third element of users array (in the example above) is similar, but we use one rule which is authentication and authorization rule at the same time (it can authenticate a user and then authorize him). And that's how we defined the following mappings: * LDAP roles ldap_role_devops , ldap_role_ops are mapped to devops ROR's local group * LDAP role ldap_role_dev is mapped to developers ROR's local group The \"detailed\" mapping offers a bit more structured approach to group mapping, and although less intuitive at first sight, it's more powerful and concise.","title":"External to local groups mapping"},{"location":"details/groups-rule-mapping/#external-to-local-groups-mapping","text":"The groups ACL rule accepts a list of group names. This rule will match on a requests in which the resolved username belongs at least to one of the listed groups. The association between usernames and groups is explicitly declared in the users section of the ACL. This is a list of usernames, and today, full wildcard patterns are also supported. In the users section, each entry requires: * an authentication rule: (I.e. one of the auth_key_* rules for local credentials, or ldap_authentication , external_authentication , etc) * a list of groups within the ones precendently inserted in the groups rules of the ACL blocks * optionally, an authorization rule ( ldap_authorization , groups_provider_authorization , etc.) When the users section's groups rule and the authorization rule are used together, we obtain \"group mapping\". That is: we are effectively mapping remote groups to local groups. There are two types of mapping available: common and detailed group mappings. Note: the rule ldap_auth is the composition of ldap_authentication and ldap_authorization . So it can be used as a shortcut for both.","title":"External to local groups mapping"},{"location":"details/groups-rule-mapping/#example","text":"readonlyrest: access_control_rules: - name: \"Viewer block\" indices: [\"logstash-viewers*\"] groups: [\"viewers\"] - name: \"DevOps block\" indices: [\"logstash-devops*\"] groups: [\"devops\"] [...] users: # PLAIN LOCAL GROUPS EXAMPLE # Local user \"joe\" is associated to local group \"editors\" - username: \"joe\" groups: [\"editors\"] auth_key: joe:password # COMMON GROUP MAPPING EXAMPLE # Externally authenticated user + authorization via external groups provider + groups common mapping # Users belonging to \"external_group1\" OR \"external_group2\" are authorized as \"viewers\" AND \"editors\" in the ACL. - username: \"*\" groups: [\"viewers\", \"editors\"] external_authentication: \"ext1\" groups_provider_authorization: user_groups_provider: \"ext2\" groups: [\"external_group1\", \"external_group2\"] # DETAILED GROUP MAPPING EXAMPLE # LDAP authenticated user + authorization via LDAP + groups detailed mapping (any LDAP user is valid; groups from `ldap1` are mapped to local groups) # Users belonging to LDAP `ldap_role_devops` OR `ldap_role_ops` are mapped to \"devops\" local group # AND # Users belonging to LDAP `ldap_role_dev` are mapped to \"developers\" local group - username: \"*\" groups: - devops: [\"ldap_role_devops\", \"ldap_role_ops\"] - developers: [\"ldap_role_dev\"] ldap_auth: name: \"ldap1\" groups: [\"ldap_role_devops\", \"ldap_role_ops\", \"ldap_role_dev\"] external_authentication_service_configs: - name: \"ext1\" [...] user_groups_providers: - name: ext2 [...] ldaps: - name: ldap1 [...] As we can see, there are two blocks in our ACL: Viewer block allows all users, which belong to viewers group, to access indices matching pattern logstash-viewers* DevOps block allows all users, which belong to devops group, to access indices matching pattern logstash-devops*","title":"Example"},{"location":"details/groups-rule-mapping/#common-mapping-example","text":"- username: \"*\" groups: [\"viewers\", \"editors\"] external_authentication: \"ext1\" groups_provider_authorization: user_groups_provider: \"ext2\" groups: [\"external_group1\", \"external_group2\"] viewers , devops , (unused in the ACL example), editors and developers are local groups. That is, they exist only at ROR's configuration level. But ROR can also integrate with external authorization systems like an LDAP or some REST service, where we can find similar concepts to ROR groups (eg. users in LDAP can have roles assigned). And sometimes we'd like to fulfil a requirement such as: Users having usernames defined by a given pattern, and having a given set of roles, should have certain given ROR internal groups assigned. You can think about it as a mapping external groups to local ones. Let's go back to our example. In the second element of the users array, we declare that: any user can be taken into consideration by this user definition a user should be authenticated by an external_authentication rule which uses the ext1 service a user should be authorized by a groups_provider_authorization rule which uses the ext2 service and such user belongs to at least one of external_group1 , external_group2 external groups. if all the above conditions are true, we can assign viewers , editors groups to the user We have just \"mapped\" the external groups external_group1 , external_group2 returned by service ext2 to the local ROR groups viewers , editors .","title":"Common mapping example"},{"location":"details/groups-rule-mapping/#detailed-mapping-example","text":"- username: \"*\" groups: - devops: [\"ldap_role_devops\", \"ldap_role_ops\"] - developers: [\"ldap_role_dev\"] ldap_auth: name: \"ldap1\" groups: [\"ldap_role_devops\", \"ldap_role_ops\", \"ldap_role_dev\"] The third element of users array (in the example above) is similar, but we use one rule which is authentication and authorization rule at the same time (it can authenticate a user and then authorize him). And that's how we defined the following mappings: * LDAP roles ldap_role_devops , ldap_role_ops are mapped to devops ROR's local group * LDAP role ldap_role_dev is mapped to developers ROR's local group The \"detailed\" mapping offers a bit more structured approach to group mapping, and although less intuitive at first sight, it's more powerful and concise.","title":"Detailed mapping example"},{"location":"details/impersonation/","text":"Impersonation After describing what the impersonation is , it's high time to see how ROR supports it and who and when could be interested in using this feature. Let's start with the latter. Use cases The impersonation feature is intended for ROR administrators, rather than users. We can point out the two most obvious use cases when the admin could take advantage of the feature: Debugging users' problems: Let's imagine that some user has a problem with their ROR configuration (eg. the user doesn't have access to some feature that was blocked at ROR's level by you, the admin). And they are not able to clearly describe what the issue is (sounds familiar?). As an administrator, it would be extremely beneficial if you could see what the user sees. Thanks to the impersonation feature, an admin is allowed to impersonate the user and experience exactly what the user experiences. Configuring a new user: When an admin configures a new user in ROR settings, they face two problems: Will the updated configuration break the production cluster? How do I know that the new user is correctly configured? Did I configure all their permissions correctly?? Both of the problems can be solved using the ROR's impersonation. Thanks to the fact that the impersonation feature always uses its own Test Settings, that is completely independent from the main production settings, the admin can alter it without worries that their actions will break something and users won't be able to do their job. Admin can add the new user configuration without worrying and then test it by impersonating the user. They can check if the user can log in without problems and if the user has access only to the Kibana features the admin wanted to grant. When the admin is sure that everything is configured correctly, they can promote the settings (test) to production. Impersonation configuration Before an admin will be able to impersonate a user, they have to configure ROR properly. The configuration consists of several parts: creating ROR's Test Settings, defining mocks of the external services (like LDAP , External Basic Auth or Custom groups provider ), impersonating a chosen user. Creating ROR's Test Settings When you call Elasticsearch directly or through ROR Kibana, ROR ACL is defined by Settings (we can assume they are Main Settings). The Test Settings define another ACL, that is taken into consideration by ROR ES only when a proper impersonation header is passed. The header is managed by ROR internally. The Test Settings are active only for a strictly defined amount of time (by default it's 30 minutes , but the admin can change it before applying Test Settings). After the time has expired, they are automatically invalidated (for security reasons). Obviously, the admin is allowed to invalidate the configured Test Settings in any time. There is no way to have more than one Test Settings configured at time. ROR Kibana plugin provides a dedicated Test Settings UI. See our Test Settings management guide for more information. But copying Main Settings as Test Settings is not enough. We also have to instruct ROR which users can be considered as impersonators (the ones, who are allowed to impersonate other users). The list of allowed impersonators and users they can impersonate are defined in the impersonation section in ROR Settings: readonlyrest: access_control_rules: [...] impersonation: - impersonator: admin1 // Who can impersonate? (user name or pattern) users: [\"*\"] // Who can be impersonated? (user names or patterns) auth_key: admin1:pass // Authentication rule required to impersonate (any authentication rule can be used here) - impersonator: admin2 users: [\"dev2\"] ldap_authentication: \"ldap1\" In the example above, we see that we have two impersonators: admin1 and admin2 . The first one can impersonate any user ( * ) and they are able to authenticate using basic auth ( admin1:pass ). The second impersonator can impersonate only dev2 user. They will be authenticated using ldap1 connector. When an impersonator passes wrong credentials ROR will tell Kibana that impersonation is not allowed. Defining mocks of the external services (optional) ROR has many sophisticated authentication & authorization methods. Some of them are based on external systems like LDAP. The problem with such systems, in regard to to the impersonation feature, is that those systems either don't support it by default or don't support it at all and even if they do - the configuration is complex. That's why we decided to solve it totally differently - using mocks. Wikipedia defines mock as an imitation, usually of lesser quality. And in the case of external authentication systems we are going provide an imitation of it that will tell ACL which users should be successfully authenticated by it. When we consider an authorization service, a mock of it will return the ACL users with their roles in the service. And this is enough for ROR to support impersonation. How does ROR use the mocks? Let's suppose we have an ldap_auth rule. When ROR processes the rule, it: * asks the given LDAP service if the username can be authenticated with a given password, and if they can ... * asks LDAP to list what groups the user belongs to In the impersonation case, it looks pretty much the same. The difference being that ROR won't call any LDAP server - the mock will provide the required information instead (no password required). During impersonating, when ROR processes an LDAP rule, it: * asks the mock if the username exists, and if it does ... * asks the mock to tell what groups the user belongs to \u26a0\ufe0f IMPORTANT: If one or more of the external services are not mocked, ROR might inform Kibana that the impersonation is not supported. It's better to always define all mocks, to avoid the \"Impersonation not supported\" Elasticsearch response. ROR Kibana plugin helps administrators to visually create and edit service mocks with a dedicated graphical UI. Follow our service mock configuration guide for more. Impersonating a chosen user Now that we have configured Test Settings and External Services Mocks, we can try to impersonate a user. In Elasticsearch ROR Settings, user can be: * provided statically (defined in the settings), * provided dynamically: * from external, dependant systems (like LDAP) - we mock them * from upstream systems (eg. through headers) - they are not known upfront It means that we pick the users defined in Settings or Mocks, but also we can enter the username and try to impersonate such user. Follow the instructions on how to impersonate a user using the ROR Kibana plugin UI . Logs & audit In Elasticsearch logs, in USR field, if an admin user finds something like this: admin1 as (user1) - it means that admin1 was authenticated and they are the impersonator who is impersonating user1 . All logs of impersonated user in Kibana will have this format [<log level>][plugins][ReadonlyREST][<filename>][impersonating <impersonated user username>] When auditing is enabled, the audit document is going to contain an impersonated_by field. Impersonation limitations Impersonation mode has some limitations. Please check if they have an impact on your use cases: Not all features available in the ROR configuration are testable with impersonation mode. Some rules used in ROR ACL do not support impersonation. For example, auth rule with hashed credentials (e.g. auth_key_sha512 ) can be used in impersonation mode only when credentials follow the format USER_NAME: HASH(PASSWORD) ; A fully hashed username and password don't allow fetching a username. The auth rule in such a format won't match during impersonation. In the rules description section you can find information about each rules impersonation support. Test Settings are stored in the memory of the node that handled the saving request sent by ROR Kibana plugin. Impersonation support will be limited to this node. We are going to improve it in the future, but for now your Kibana should only communicate with one Elasticsearch node. Sometimes it is impossible to fetch usernames defined in the Test Settings. If a users rule contains a username pattern with a wildcard, to impersonate a user matching the pattern, you need to enter the username manually. ```yaml readonlyrest: access_control_rules: - name: \"LDAP group g1\" type: allow groups: [\"g1\"] users: - username: \"admin*\" // To impersonate a user with a username matching 'admin*' you need to enter the username manually, like 'admin123' groups: - g1: group1 ldap_auth: name: \"ldap1\" groups: [\"group1\"] ldaps: - name: ldap1 [..] impersonation: [...] ``` Glossary Impersonator - someone who imitates or copies the behavior or actions of another, Impersonation - imitating behaviors or actions of a given user, Main Settings - the ROR's settings that apply to ACL that handles requests during regular sessions (not the impersonation ones), Test Settings - the ROR's settings that apply to ACL that handles impersonating requests (the ones during impersonation session), External Service Mock - an imitation of an external service (the supported ones: LDAP, an external authentication service, an external authorization service).","title":"Impersonation"},{"location":"details/impersonation/#impersonation","text":"After describing what the impersonation is , it's high time to see how ROR supports it and who and when could be interested in using this feature. Let's start with the latter.","title":"Impersonation"},{"location":"details/impersonation/#use-cases","text":"The impersonation feature is intended for ROR administrators, rather than users. We can point out the two most obvious use cases when the admin could take advantage of the feature:","title":"Use cases"},{"location":"details/impersonation/#debugging-users-problems","text":"Let's imagine that some user has a problem with their ROR configuration (eg. the user doesn't have access to some feature that was blocked at ROR's level by you, the admin). And they are not able to clearly describe what the issue is (sounds familiar?). As an administrator, it would be extremely beneficial if you could see what the user sees. Thanks to the impersonation feature, an admin is allowed to impersonate the user and experience exactly what the user experiences.","title":"Debugging users' problems:"},{"location":"details/impersonation/#configuring-a-new-user","text":"When an admin configures a new user in ROR settings, they face two problems: Will the updated configuration break the production cluster? How do I know that the new user is correctly configured? Did I configure all their permissions correctly?? Both of the problems can be solved using the ROR's impersonation. Thanks to the fact that the impersonation feature always uses its own Test Settings, that is completely independent from the main production settings, the admin can alter it without worries that their actions will break something and users won't be able to do their job. Admin can add the new user configuration without worrying and then test it by impersonating the user. They can check if the user can log in without problems and if the user has access only to the Kibana features the admin wanted to grant. When the admin is sure that everything is configured correctly, they can promote the settings (test) to production.","title":"Configuring a new user:"},{"location":"details/impersonation/#impersonation-configuration","text":"Before an admin will be able to impersonate a user, they have to configure ROR properly. The configuration consists of several parts: creating ROR's Test Settings, defining mocks of the external services (like LDAP , External Basic Auth or Custom groups provider ), impersonating a chosen user.","title":"Impersonation configuration"},{"location":"details/impersonation/#creating-rors-test-settings","text":"When you call Elasticsearch directly or through ROR Kibana, ROR ACL is defined by Settings (we can assume they are Main Settings). The Test Settings define another ACL, that is taken into consideration by ROR ES only when a proper impersonation header is passed. The header is managed by ROR internally. The Test Settings are active only for a strictly defined amount of time (by default it's 30 minutes , but the admin can change it before applying Test Settings). After the time has expired, they are automatically invalidated (for security reasons). Obviously, the admin is allowed to invalidate the configured Test Settings in any time. There is no way to have more than one Test Settings configured at time. ROR Kibana plugin provides a dedicated Test Settings UI. See our Test Settings management guide for more information. But copying Main Settings as Test Settings is not enough. We also have to instruct ROR which users can be considered as impersonators (the ones, who are allowed to impersonate other users). The list of allowed impersonators and users they can impersonate are defined in the impersonation section in ROR Settings: readonlyrest: access_control_rules: [...] impersonation: - impersonator: admin1 // Who can impersonate? (user name or pattern) users: [\"*\"] // Who can be impersonated? (user names or patterns) auth_key: admin1:pass // Authentication rule required to impersonate (any authentication rule can be used here) - impersonator: admin2 users: [\"dev2\"] ldap_authentication: \"ldap1\" In the example above, we see that we have two impersonators: admin1 and admin2 . The first one can impersonate any user ( * ) and they are able to authenticate using basic auth ( admin1:pass ). The second impersonator can impersonate only dev2 user. They will be authenticated using ldap1 connector. When an impersonator passes wrong credentials ROR will tell Kibana that impersonation is not allowed.","title":"Creating ROR's Test Settings"},{"location":"details/impersonation/#defining-mocks-of-the-external-services-optional","text":"ROR has many sophisticated authentication & authorization methods. Some of them are based on external systems like LDAP. The problem with such systems, in regard to to the impersonation feature, is that those systems either don't support it by default or don't support it at all and even if they do - the configuration is complex. That's why we decided to solve it totally differently - using mocks. Wikipedia defines mock as an imitation, usually of lesser quality. And in the case of external authentication systems we are going provide an imitation of it that will tell ACL which users should be successfully authenticated by it. When we consider an authorization service, a mock of it will return the ACL users with their roles in the service. And this is enough for ROR to support impersonation. How does ROR use the mocks? Let's suppose we have an ldap_auth rule. When ROR processes the rule, it: * asks the given LDAP service if the username can be authenticated with a given password, and if they can ... * asks LDAP to list what groups the user belongs to In the impersonation case, it looks pretty much the same. The difference being that ROR won't call any LDAP server - the mock will provide the required information instead (no password required). During impersonating, when ROR processes an LDAP rule, it: * asks the mock if the username exists, and if it does ... * asks the mock to tell what groups the user belongs to \u26a0\ufe0f IMPORTANT: If one or more of the external services are not mocked, ROR might inform Kibana that the impersonation is not supported. It's better to always define all mocks, to avoid the \"Impersonation not supported\" Elasticsearch response. ROR Kibana plugin helps administrators to visually create and edit service mocks with a dedicated graphical UI. Follow our service mock configuration guide for more.","title":"Defining mocks of the external services (optional)"},{"location":"details/impersonation/#impersonating-a-chosen-user","text":"Now that we have configured Test Settings and External Services Mocks, we can try to impersonate a user. In Elasticsearch ROR Settings, user can be: * provided statically (defined in the settings), * provided dynamically: * from external, dependant systems (like LDAP) - we mock them * from upstream systems (eg. through headers) - they are not known upfront It means that we pick the users defined in Settings or Mocks, but also we can enter the username and try to impersonate such user. Follow the instructions on how to impersonate a user using the ROR Kibana plugin UI .","title":"Impersonating a chosen user"},{"location":"details/impersonation/#logs-audit","text":"In Elasticsearch logs, in USR field, if an admin user finds something like this: admin1 as (user1) - it means that admin1 was authenticated and they are the impersonator who is impersonating user1 . All logs of impersonated user in Kibana will have this format [<log level>][plugins][ReadonlyREST][<filename>][impersonating <impersonated user username>] When auditing is enabled, the audit document is going to contain an impersonated_by field.","title":"Logs &amp; audit"},{"location":"details/impersonation/#impersonation-limitations","text":"Impersonation mode has some limitations. Please check if they have an impact on your use cases: Not all features available in the ROR configuration are testable with impersonation mode. Some rules used in ROR ACL do not support impersonation. For example, auth rule with hashed credentials (e.g. auth_key_sha512 ) can be used in impersonation mode only when credentials follow the format USER_NAME: HASH(PASSWORD) ; A fully hashed username and password don't allow fetching a username. The auth rule in such a format won't match during impersonation. In the rules description section you can find information about each rules impersonation support. Test Settings are stored in the memory of the node that handled the saving request sent by ROR Kibana plugin. Impersonation support will be limited to this node. We are going to improve it in the future, but for now your Kibana should only communicate with one Elasticsearch node. Sometimes it is impossible to fetch usernames defined in the Test Settings. If a users rule contains a username pattern with a wildcard, to impersonate a user matching the pattern, you need to enter the username manually. ```yaml readonlyrest: access_control_rules: - name: \"LDAP group g1\" type: allow groups: [\"g1\"] users: - username: \"admin*\" // To impersonate a user with a username matching 'admin*' you need to enter the username manually, like 'admin123' groups: - g1: group1 ldap_auth: name: \"ldap1\" groups: [\"group1\"] ldaps: - name: ldap1 [..] impersonation: [...] ```","title":"Impersonation limitations"},{"location":"details/impersonation/#glossary","text":"Impersonator - someone who imitates or copies the behavior or actions of another, Impersonation - imitating behaviors or actions of a given user, Main Settings - the ROR's settings that apply to ACL that handles requests during regular sessions (not the impersonation ones), Test Settings - the ROR's settings that apply to ACL that handles impersonating requests (the ones during impersonation session), External Service Mock - an imitation of an external service (the supported ones: LDAP, an external authentication service, an external authorization service).","title":"Glossary"},{"location":"details/index-not-found-examples/","text":"\"Index not found\" scenario Examples: Let's assume that our ES cluster has 2 indices: index_a and index_b . At the same time we have two users: userA and userB . We'd like to give userA access to index index_a , and userB to index_b . userA should not see or be even aware of index_b and vice versa. We'd like to give each of them a feeling that they are alone on the cluster. ROR readonlyrest.yml configuration may look like this: ```yaml readonlyrest: enable: true access_control_rules: - name: \"user A indices\" indices: [\"index_a\"] auth_key: userA:secret - name: \"user B indices\" indices: [\"indexB\"] auth_key: userB:secret ``` We can test if userA is able to reach index_a : ```text $ curl -v -u userA:secret \"http://127.0.0.1:9200/index_a?pretty\" HTTP/1.1 200 OK content-type: application/json; charset=UTF-8 content-length: 611 { \"index_a\" : { \"aliases\" : { }, \"mappings\" : { ... } \"settings\" : { ... } } } ``` It looks like he is. So far, so good. Let's try to access nonexistent index (we know, that index with name nonexistent for sure doesn't exist on our cluster): ```text $ curl -i -u userA:secret \"http://127.0.0.1:9200/nonexistent?pretty\" 18:15:28 HTTP/1.1 404 Not Found content-type: application/json; charset=UTF-8 content-length: 634 { \"error\" : { \"root_cause\" : [ ... ], \"type\" : \"index_not_found_exception\", \"reason\" : \"no such index [nonexistent_ROR_ZA1FXDsR7M]\", \"resource.type\" : \"index_or_alias\", \"resource.id\" : \"nonexistent_ROR_ZA1FXDsR7M\", \"index_uuid\" : \" na \", \"index\" : \"nonexistent_ROR_ZA1FXDsR7M\" }, \"status\" : 404 } ``` The response is pretty straight forward - the index doesn't exist. But, let's see what happens, when the same user, userA , will try to get index_b : ```text $ curl -v -u userA:secret \"http://127.0.0.1:9200/index_b?pretty\" HTTP/1.1 404 Not Found content-type: application/json; charset=UTF-8 content-length: 610 { \"error\" : { \"root_cause\" : [ ... ], \"type\" : \"index_not_found_exception\", \"reason\" : \"no such index [index_b_ROR_QcskliAl8A]\", \"resource.type\" : \"index_or_alias\", \"resource.id\" : \"index_b_ROR_QcskliAl8A\", \"index_uuid\" : \" na \", \"index\" : \"index_b_ROR_QcskliAl8A\" }, \"status\" : 404 } ``` As we can see userA is not able to get index_b . But the response is HTTP 404 Not Found - it means that the index doesn't exist. So, the response is the same as we get if the called index really doesn't exist. Thanks to the described behaviour, userA is not aware that on the cluster there are any other indices but the ones he was given access to. note: Careful reader may notice that, in example above, userA was getting index_b , but the response says that there is no index_b_ROR_QcskliAl8Aindex_b_ROR_QcskliAl8A index. It's the trick ROR does to fool ES and be sure that asking index, which the user should not be allowed to see, won't be reached by him. But we should also consider the other case - using an index name with wildcard. So, userA will try to get all indices which names match index* pattern: ```text $ curl -i -u userA:secret \"http://127.0.0.1:9200/index*?pretty\" 19:58:29 HTTP/1.1 200 OK content-type: application/json; charset=UTF-8 content-length: 611 { \"index_a\" : { \"aliases\" : { }, \"mappings\" : { ... }, \"settings\" : { ... } } } ``` Response is exactly like we'd expect - only index_a was returned. But what if nothing matches our index name pattern? ```text $ curl -i -u userA:secret \"http://127.0.0.1:9200/index_userA*?pretty\" 20:05:10 HTTP/1.1 200 OK content-type: application/json; charset=UTF-8 content-length: 4 { } ``` Response is empty list. Now, let's see what happens when an index name pattern matches an index which is not authorized for a user who asks about it. ```text $ curl -i -u userA:secret \"http://127.0.0.1:9200/index_b*?pretty\" 20:14:34 HTTP/1.1 200 OK content-type: application/json; charset=UTF-8 content-length: 4 { } ``` As we see, response is the same as we have experienced when there was really no index matching the pattern. Also here a user has a feeling that only his indices are present on a cluster.","title":"\"Index not found\" scenario"},{"location":"details/index-not-found-examples/#index-not-found-scenario","text":"Examples: Let's assume that our ES cluster has 2 indices: index_a and index_b . At the same time we have two users: userA and userB . We'd like to give userA access to index index_a , and userB to index_b . userA should not see or be even aware of index_b and vice versa. We'd like to give each of them a feeling that they are alone on the cluster. ROR readonlyrest.yml configuration may look like this: ```yaml readonlyrest: enable: true access_control_rules: - name: \"user A indices\" indices: [\"index_a\"] auth_key: userA:secret - name: \"user B indices\" indices: [\"indexB\"] auth_key: userB:secret ``` We can test if userA is able to reach index_a : ```text $ curl -v -u userA:secret \"http://127.0.0.1:9200/index_a?pretty\" HTTP/1.1 200 OK content-type: application/json; charset=UTF-8 content-length: 611 { \"index_a\" : { \"aliases\" : { }, \"mappings\" : { ... } \"settings\" : { ... } } } ``` It looks like he is. So far, so good. Let's try to access nonexistent index (we know, that index with name nonexistent for sure doesn't exist on our cluster): ```text $ curl -i -u userA:secret \"http://127.0.0.1:9200/nonexistent?pretty\" 18:15:28 HTTP/1.1 404 Not Found content-type: application/json; charset=UTF-8 content-length: 634 { \"error\" : { \"root_cause\" : [ ... ], \"type\" : \"index_not_found_exception\", \"reason\" : \"no such index [nonexistent_ROR_ZA1FXDsR7M]\", \"resource.type\" : \"index_or_alias\", \"resource.id\" : \"nonexistent_ROR_ZA1FXDsR7M\", \"index_uuid\" : \" na \", \"index\" : \"nonexistent_ROR_ZA1FXDsR7M\" }, \"status\" : 404 } ``` The response is pretty straight forward - the index doesn't exist. But, let's see what happens, when the same user, userA , will try to get index_b : ```text $ curl -v -u userA:secret \"http://127.0.0.1:9200/index_b?pretty\" HTTP/1.1 404 Not Found content-type: application/json; charset=UTF-8 content-length: 610 { \"error\" : { \"root_cause\" : [ ... ], \"type\" : \"index_not_found_exception\", \"reason\" : \"no such index [index_b_ROR_QcskliAl8A]\", \"resource.type\" : \"index_or_alias\", \"resource.id\" : \"index_b_ROR_QcskliAl8A\", \"index_uuid\" : \" na \", \"index\" : \"index_b_ROR_QcskliAl8A\" }, \"status\" : 404 } ``` As we can see userA is not able to get index_b . But the response is HTTP 404 Not Found - it means that the index doesn't exist. So, the response is the same as we get if the called index really doesn't exist. Thanks to the described behaviour, userA is not aware that on the cluster there are any other indices but the ones he was given access to. note: Careful reader may notice that, in example above, userA was getting index_b , but the response says that there is no index_b_ROR_QcskliAl8Aindex_b_ROR_QcskliAl8A index. It's the trick ROR does to fool ES and be sure that asking index, which the user should not be allowed to see, won't be reached by him. But we should also consider the other case - using an index name with wildcard. So, userA will try to get all indices which names match index* pattern: ```text $ curl -i -u userA:secret \"http://127.0.0.1:9200/index*?pretty\" 19:58:29 HTTP/1.1 200 OK content-type: application/json; charset=UTF-8 content-length: 611 { \"index_a\" : { \"aliases\" : { }, \"mappings\" : { ... }, \"settings\" : { ... } } } ``` Response is exactly like we'd expect - only index_a was returned. But what if nothing matches our index name pattern? ```text $ curl -i -u userA:secret \"http://127.0.0.1:9200/index_userA*?pretty\" 20:05:10 HTTP/1.1 200 OK content-type: application/json; charset=UTF-8 content-length: 4 { } ``` Response is empty list. Now, let's see what happens when an index name pattern matches an index which is not authorized for a user who asks about it. ```text $ curl -i -u userA:secret \"http://127.0.0.1:9200/index_b*?pretty\" 20:14:34 HTTP/1.1 200 OK content-type: application/json; charset=UTF-8 content-length: 4 { } ``` As we see, response is the same as we have experienced when there was really no index matching the pattern. Also here a user has a feeling that only his indices are present on a cluster.","title":"\"Index not found\" scenario"},{"location":"details/indices-rule-templates/","text":"Templates handling in indices rule A ROR configuration for all examples below (click to expand) ```yaml readonlyrest: prompt_for_basic_auth: false access_control_rules: - name: \"admin block\" verbosity: error type: allow auth_key: admin:admin - name: \"dev1 block\" indices: [\"idev1\", \"idev1_*\"] auth_key: dev1:test - name: \"dev2 block\" indices: [\"idev2\", \"idev2_*\"] auth_key: dev2:test ``` Index templates An indices rule takes into consideration index patterns and aliases which are a part of a template definition. We should consider four types of template related requests: Create an index template The request will be allowed when all of following conditions are met: * a template with requested name does not exist (if it does, it's rather a template modification, than a creation), * all index patterns of the new, requested template are allowed, * all aliases of the new, requested template are allowed. Example (click to expand) Let's try to add an index template. We can see, using `admin` account, that there are no templates defined yet. $ curl -vk -u admin:admin \"http://localhost:9200/_index_template?pretty\" HTTP/1.1 200 OK content-type: application/json; charset=UTF-8 { \"index_templates\" : [ ] } Now, let's use `dev1` user account to create an index template `temp1`: $ curl -vk -u dev1:test -XPUT \"http://127.0.0.1:9200/_index_template/test?pretty\" -H \"Content-Type: application/json\" -d \\ '{ \"index_patterns\":[\"index*\"], \"template\": { \"aliases\": { \"dev1_index\": {}, \"dev2_index\": {} } } }' HTTP/1.1 403 Forbidden content-type: application/json; charset=UTF-8 { \"error\" : { \"root_cause\" : [ { \"reason\" : \"forbidden\", \"due_to\" : [\"OPERATION_NOT_ALLOWED\"] } ], \"reason\" : \"forbidden\", \"due_to\" : [\"OPERATION_NOT_ALLOWED\"], \"status\" : 403 } } Oh, something went wrong. It seems that, a user `dev1` is not allowed to add this template. Let's check ROR logs to figure out why: > FORBIDDEN by default req={ ID:193441275-173645661#8, TYP:PutComposableIndexTemplateAction$Request, CGR:N/A, USR:dev1 (attempted), BRS:true, KDX:null, ACT:indices:admin/index_template/put, OA:127.0.0.1/32, XFF:null, DA:127.0.0.1/32, `IDX:index*,dev2_index,dev1_index`, MET:PUT, `PTH:/_index_template/test`, CNT: , HDR:Accept=*/*, Authorization= , Content-Length=157, Content-Type=application/json, Host=127.0.0.1:9200, User-Agent=curl/7.64.1, HIS:[CONTAINER ADMIN-> RULES:[auth_key->false] RESOLVED:[indices=index*,dev2_index,dev1_index;template=ADD(test:index*:dev2_index,dev1_index)]], `[dev1 block-> RULES:[auth_key->true, indices->false]` RESOLVED:[user=dev1;indices=index*,dev2_index,dev1_index;template=ADD(test:index*:dev2_index,dev1_index)]], [dev2 block-> RULES:[auth_key->false] RESOLVED:[indices=index*,dev2_index,dev1_index;template=ADD(test:index*:dev2_index,dev1_index)]], } We can see that our request was forbidden - credentials were OK, but `indices` rule was not matched in `dev1 block`. We can see also that ROR found 3 indices which are related to the request: * `index*` - an index pattern from our request * `dev1_index` - a first alias from out request * `dev2_index` - a second alias from out request When we take a look at indices configured in `indices` rule for our user, we can see that, he has an access only to `idev1` and `idev1_*` indices. Now, it's pretty much obvious why the request was blocked - the user has no access to index pattern and aliases used in the request. Let's try to fix that: $ curl -vk -u dev1:test -XPUT \"http://127.0.0.1:9200/_index_template/test?pretty\" -H \"Content-Type: application/json\" -d \\ '{ \"index_patterns\":[\"idev1_test*\"], \"template\": { \"aliases\": { \"idev1\": {}, \"idev1_test\": {} } } }' HTTP/1.1 200 OK content-type: application/json; charset=UTF-8 { \"acknowledged\" : true } Hooray! The index template was added. This time ROR allowed us to do so. It's because `dev1` user has an access to index pattern `idev1_test*`, because it is contained in `idev1_*`. Used aliases are also allowed. Modify an index template The request will be allowed when all of following conditions are met: * a template with requested name does exist, * all index patterns of the existing template are allowed, * all aliases of the existing template are allowed, * all index patterns of the requested template are allowed, * all aliases of the requested template are allowed. Example (click to expand) Let's assume the user `dev1` would like to modify the previously created template, because the index pattern is too detailed: $ curl -vk -u dev1:test -XPUT \"http://127.0.0.1:9200/_index_template/test?pretty\" -H \"Content-Type: application/json\" -d \\ '{ \"index_patterns\":[\"idev*\"], \"template\": { \"aliases\": { \"idev1\": {}, \"idev1_test\": {} } } }' HTTP/1.1 403 Forbidden content-type: application/json; charset=UTF-8 { \"error\" : { \"root_cause\" : [ { \"reason\" : \"forbidden\", \"due_to\" : [\"OPERATION_NOT_ALLOWED\"] } ], \"reason\" : \"forbidden\", \"due_to\" : [\"OPERATION_NOT_ALLOWED\"], \"status\" : 403 } } Ups! Something is wrong. Let's check the ROR forbidden log: > FORBIDDEN by default req={ ID:918326057-1726421783#75, TYP:PutComposableIndexTemplateAction$Request, CGR:N/A, USR:dev1 (attempted), BRS:true, KDX:null, ACT:indices:admin/index_template/put, OA:127.0.0.1/32, XFF:null, DA:127.0.0.1/32, `IDX:idev*,idev1,idev1_test`, MET:PUT, PTH:/_index_template/test, CNT: , HDR:Accept=*/*, Authorization= , Content-Length=151, Content-Type=application/json, Host=127.0.0.1:9200, User-Agent=curl/7.64.1, HIS:[CONTAINER ADMIN-> RULES:[auth_key->false] RESOLVED:[indices=idev*,idev1,idev1_test;template=ADD(test:idev*:idev1,idev1_test)]], `[dev1 block-> RULES:[auth_key->true, indices->false]` RESOLVED:[user=dev1;indices=idev*,idev1,idev1_test;template=ADD(test:idev*:idev1,idev1_test)]], [dev2 block-> RULES:[auth_key->false] RESOLVED:[indices=idev*,idev1,idev1_test;template=ADD(test:idev*:idev1,idev1_test)]], } We can see that `indices` rule hasn't not been matched. Looking at the IDX section, we can figure out that the index pattern we requested `idev*`, cannot be allowed. `idev*` is too generic, because in the `indices` list we have `[\"idev1\", \"idev1_*\"]`. Let's try to fix that: $ curl -vk -u dev1:test -XPUT \"http://127.0.0.1:9200/_index_template/test?pretty\" -H \"Content-Type: application/json\" -d \\ '{ \"index_patterns\":[\"idev1_*\"], \"template\": { \"aliases\": { \"idev1\": {}, \"idev1_test\": {} } } }' HTTP/1.1 200 OK content-type: application/json; charset=UTF-8 { \"acknowledged\" : true } Yeah, now it works. Let's check if the template is modified (we will use `admin` user to do so): $ curl -vk -u admin:admin \"http://127.0.0.1:9200/_index_template?pretty\" HTTP/1.1 200 OK content-type: application/json; charset=UTF-8 { \"error\" : { \"root_cause\" : [ { \"reason\" : \"forbidden\", \"due_to\" : [\"OPERATION_NOT_ALLOWED\"] } ], \"reason\" : \"forbidden\", \"due_to\" : [\"OPERATION_NOT_ALLOWED\"], \"status\" : 403 } } All is good. We have only one template and the modifications was applied. So far, so good. But we can wonder what happens if `dev2` will try to modify (or override) template `temp`? Let's check: $ curl -vk -u dev2:test -XPUT \"http://127.0.0.1:9200/_index_template/test?pretty\" -H \"Content-Type: application/json\" -d \\ '{ \"index_patterns\":[\"idev2_*\"], \"template\": { \"aliases\": { \"idev2\": {}, \"idev2_test\": {} } } }' HTTP/1.1 403 Forbidden content-type: application/json; charset=UTF-8 { \"error\" : { \"root_cause\" : [ { \"reason\" : \"forbidden\", \"due_to\" : [\"OPERATION_NOT_ALLOWED\"] } ], \"reason\" : \"forbidden\", \"due_to\" : [\"OPERATION_NOT_ALLOWED\"], \"status\" : 403 } } Yes! This is something what we wanted like to see. Even if the request was correct and the user `dev2` has an access to the requested index pattern and aliases, the request was forbidden. Obviously, there is already existed template `temp` which has the index pattern and aliases, which are not allowed for `dev2`. ROR deduces that `dev2` cannot be considered as someone how can modify/overwrite it. Pretty awesome. Won't `dev2` also be able to remove it? We'll see in next section ... Delete an index template The request will be allowed when template does not exist OR all of the following conditions are met: * a template with requested name does exist, * all index patterns of the existing template are allowed, * all aliases of the existing template are allowed. Example (click to expand) In the last section we wondered, if ROR will be able to block removing the template `temp` by the user `dev2`. Let's recall, that we proved that the user is not able to modify this template, because ROR considers that he doesn't have permissions to change/remove it. $ curl -vk -u dev2:test -XDELETE \"http://127.0.0.1:9200/_index_template/test?pretty\" HTTP/1.1 403 Forbidden content-type: application/json; charset=UTF-8 { \"error\" : { \"root_cause\" : [ { \"reason\" : \"forbidden\", \"due_to\" : [\"OPERATION_NOT_ALLOWED\"] } ], \"reason\" : \"forbidden\", \"due_to\" : [\"OPERATION_NOT_ALLOWED\"], \"status\" : 403 } } Perfect! OK, but we also would like to know if `user1` will be able to remove his template. Let's check it: $ curl -vk -u dev1:test -XDELETE \"http://127.0.0.1:9200/_index_template/test?pretty\" HTTP/1.1 200 OK content-type: application/json; charset=UTF-8 { \"acknowledged\" : true } Great! Everything works. Get index templates At the moment ROR doesn't have templates rule (similar to snapshots or repositories ), which allows to restrict which templates can be visible to the user (it is going to change in the future). But the indices rule is enough to filter templates based on index patterns in their definitions. An index template is considered to be visible for a user, when the user has access to AT LEAST ONE index pattern of the template's index pattern list. ROR is going to show the template but to hide the information about not allowed index patterns and not allowed aliases. Example (click to expand) In previous sections we proved that ROR gets along with index templates adding, modifying and removing pretty well. Now, we'd like check what index templates are supposed to be visible for users. Let's assume we have 4 index templates: $ curl -vk -u admin:admin \"http://127.0.0.1:9200/_index_template?pretty\" HTTP/1.1 200 OK content-type: application/json; charset=UTF-8 { \"index_templates\" : [ { \"name\" : \"t1\", \"index_template\" : { \"index_patterns\" : [\"i*\"], \"template\" : { \"aliases\" : { \"idev2\" : { }, \"idev3\" : { }, \"idev1\" : { } } }, \"composed_of\" : [ ] } }, { \"name\" : \"t2\", \"index_template\" : { \"index_patterns\" : [\"idev1_*\"], \"template\" : { \"aliases\" : { \"admin_idev\" : { }, \"idev1\" : { } } }, \"composed_of\" : [ ], \"priority\" : 1 } }, { \"name\" : \"t3\", \"index_template\" : { \"index_patterns\" : [\"idev2_*\"], \"template\" : { \"aliases\" : { \"idev2\" : { }, \"admin_idev\" : { } } }, \"composed_of\" : [ ], \"priority\" : 1 } }, { \"name\" : \"t4\", \"index_template\" : { \"index_patterns\" : [\"idev1_*\", \"idev2_*\"], \"template\" : { \"aliases\" : { \"idev2\" : { }, \"admin_idev\" : { }, \"idev1\" : { } } }, \"composed_of\" : [ ], \"priority\" : 2 } } ] } `admin` has unrestricted access to all templates. Now, let's check which templates `dev` are supposed to see: $ curl -vk -u dev1:test \"http://127.0.0.1:9200/_index_template?pretty\" HTTP/1.1 200 OK content-type: application/json; charset=UTF-8 { \"index_templates\" : [ { \"name\" : \"t1\", \"index_template\" : { \"index_patterns\" : [\"i*\"], \"template\" : { \"aliases\" : { \"idev1\" : { } } }, \"composed_of\" : [ ] } }, { \"name\" : \"t2\", \"index_template\" : { \"index_patterns\" : [\"idev1_*\"], \"template\" : { \"aliases\" : { \"idev1\" : { } } }, \"composed_of\" : [ ], \"priority\" : 1 } }, { \"name\" : \"t4\", \"index_template\" : { \"index_patterns\" : [\"idev1_*\"], \"template\" : { \"aliases\" : { \"idev1\" : { } } }, \"composed_of\" : [ ], \"priority\" : 2 } } ] } Hmm, we can see many weird things here. Let's start with the simplest case: index template `t2` is allowed for the user, because the used index pattern is allowed by `indices` rule. But we can also see that user `dev1` is not aware of existence the `admin_idev` alias - it was filter out from the aliases list. The user has no access to the alias, so he should not be able to see it. What about the index template `t3`? `dev1` is not allowed to see it because the index pattern `idev2_*` is not allowed for him. It was also pretty much obvious! The next is `t4`. When `admin` had listed index templates, we saw that template `t4` has 2 index patterns. But `dev1` can see only one. This is great, because he has an access to a part of that template, so he definitely should be able to see it. ROR behaviour here is pretty neat - it allows the user to see a template with filtered, not allowed parts of it, but at the same time, the user doesn't have permissions to modify/remove the template (Don't believe me? Go ahead and check!) And the last one to explain - `t1`. The index pattern of the template is `i*`. Obviously user `dev1` has no access to it, because his allowed indices are `idev1, idev1_*`. But if we imagine all possible values generated from pattern `i*` and all possible values generated from `idev1, idev1_*`, we can notice that the latter will be a subset of the first. It means that this template can be interesting for the user `dev1`, because it will ba applied to indices created by him. That's why ROR decides to show it. Component templates Component templates doesn't have index patterns but could have aliases. So, in this case, we should also consider four types of template related requests: Create a component template The request will be allowed when all of following conditions are met: * a template with requested name does not exist (if it does, it's rather a template modification, than a creation), * all aliases of the new, requested template are allowed. Example (click to expand) Unlike index templates, component templates don't have index patterns. But they still have aliases. So, their behaviour according to an aliases usage is quite similar, but there are several differences which are worth mentioning. Let's check if `dev1` user can create a component template: $ curl -vk -u dev1:test \"http://localhost:9200/_component_template/ctemp1?pretty\" -XPUT -H \"Content-Type: application/json\" -d \\ '{ \"template\": { \"settings\": { \"index.number_of_replicas\": 0 }, \"aliases\": { \"idev1\": {}, \"idev2\": {} } } }' HTTP/1.1 403 Forbidden content-type: application/json; charset=UTF-8 { \"error\" : { \"root_cause\" : [ { \"reason\" : \"forbidden\", \"due_to\" : [\"OPERATION_NOT_ALLOWED\"] } ], \"reason\" : \"forbidden\", \"due_to\" : [\"OPERATION_NOT_ALLOWED\"], \"status\" : 403 } } Oh, user `dev1` is not allowed to create this template. But wait! It looks like we have the same problem as had while creating index template. Alias `idev2` is not allowed. Let's try to do the same without this alias: $ curl -vk -u dev1:test \"http://localhost:9200/_component_template/ctemp1?pretty\" -XPUT -H \"Content-Type: application/json\" -d \\ '{ \"template\": { \"settings\": { \"index.number_of_replicas\": 0 }, \"aliases\": { \"idev1\": {} } } }' HTTP/1.1 200 OK content-type: application/json; charset=UTF-8 { \"acknowledged\" : true } Ha! As expected. A user has to have access to all aliases during adding a component template which has aliases defined. *Note* If a component template doesn't involve aliases, there is no restriction from ROR side to add one. It can be changed in future, when we add sth like `templates` rule. Modify a component template The request will be allowed when all of following conditions are met: * a template with requested name does exist, * all aliases of the existing template are allowed, * all aliases of the requested template are allowed. Example (click to expand) In the previous example, user `dev1` created the component template `ctemp1` with one alias `idev1`. Let's check if user `dev2` will be able to modify it: $ curl -vk -u dev2:test \"http://localhost:9200/_component_template/ctemp1?pretty\" -XPUT -H \"Content-Type: application/json\" -d \\ '{ \"template\": { \"settings\": { \"index.number_of_replicas\": 0 }, \"aliases\": { \"idev2\": {} } } }' HTTP/1.1 403 Forbidden content-type: application/json; charset=UTF-8 { \"error\" : { \"root_cause\" : [ { \"reason\" : \"forbidden\", \"due_to\" : [\"OPERATION_NOT_ALLOWED\"] } ], \"reason\" : \"forbidden\", \"due_to\" : [\"OPERATION_NOT_ALLOWED\"], \"status\" : 403 } } No. And this is a good behaviour, because `dev2` doesn't have an access to the alias `idev1` which the `ctemp1` has. ROR assumes, that he cannot modify the component template (please notice, that the same request will be allowed when a different, nonexistent component template name is used). I can assure you that `dev1` is able to modify the template (you can check if you want). Delete a component template The request will be allowed when template does not exist OR all of the following conditions are met: * a template with requested name does exist, * all aliases of the existing template are allowed. Example (click to expand) If you read the previous example, you won't find anything interesting here. A component template can be removed only by someone whom ROR considers to have modification rights of the template. See that `dev2` is not able to remove `ctemp1`: $ curl -vk -u dev2:test -XDELETE \"http://localhost:9200/_component_template/ctemp1?pretty\" HTTP/1.1 403 Forbidden content-type: application/json; charset=UTF-8 { \"error\" : { \"root_cause\" : [ { \"reason\" : \"forbidden\", \"due_to\" : [\"OPERATION_NOT_ALLOWED\"] } ], \"reason\" : \"forbidden\", \"due_to\" : [\"OPERATION_NOT_ALLOWED\"], \"status\" : 403 } } I told you. But please remember that only aliases are checked by ROR when it's trying to figure out modification rights of a component template. If a component template doesn't have any aliases, it can be modified or deleted by any user. Get component templates At the moment there is no way to restrict which component templates can be visible to the user (it is going to change in the future - see a corresponding index template section). But ROR is going to hide the information about not allowed aliases of returned component templates. Example (click to expand) A careful reader can guess that ROR won't forbid showing component templates. But similar to indices templates, ROR will filter out aliases list depending on an aliases accessability of current user. Let's see an example: $ curl -vk -u admin:admin \"http://localhost:9200/_component_template?pretty\" HTTP/1.1 200 OK content-type: application/json; charset=UTF-8 { \"component_templates\" : [ { \"name\" : \"ctemp2\", \"component_template\" : { \"template\" : { \"settings\" : { \"index\" : { \"number_of_replicas\" : \"0\" } }, \"aliases\" : { \"idev2\" : { } } } } }, { \"name\" : \"ctemp1\", \"component_template\" : { \"template\" : { \"settings\" : { \"index\" : { \"number_of_replicas\" : \"0\" } }, \"aliases\" : { \"idev1\" : { } } } } } ] } We can see that we have two component templates. `ctemp1` has alias `idev1` and `ctemp2` alias `idev2`. Let check what templates `dev1` user will be able to see: $ curl -vk -u dev1:test \"http://localhost:9200/_component_template?pretty\" HTTP/1.1 200 OK content-type: application/json; charset=UTF-8 { \"component_templates\" : [ { \"name\" : \"ctemp2\", \"component_template\" : { \"template\" : { \"settings\" : { \"index\" : { \"number_of_replicas\" : \"0\" } }, \"aliases\" : { } } } }, { \"name\" : \"ctemp1\", \"component_template\" : { \"template\" : { \"settings\" : { \"index\" : { \"number_of_replicas\" : \"0\" } }, \"aliases\" : { \"idev1\" : { } } } } } ] } We can see that he is able to see all component templates, but `ctemp2` doesn't have `idev2` alias. User `dev1` has no access to the alias, so response returned by ROR doesn't contain the alias. Similar behaviour we will observe when `dev2` user will try to get all templates. Troubleshooting To figure out why the template is not returned or/and cannot be altered, you should enable a DEBUG log level and check your logs. ROR logs each step of template request handling in the indices rule, so detailed description should explain the given template is not allowed.","title":"Templates handling in `indices` rule"},{"location":"details/indices-rule-templates/#templates-handling-in-indices-rule","text":"A ROR configuration for all examples below (click to expand) ```yaml readonlyrest: prompt_for_basic_auth: false access_control_rules: - name: \"admin block\" verbosity: error type: allow auth_key: admin:admin - name: \"dev1 block\" indices: [\"idev1\", \"idev1_*\"] auth_key: dev1:test - name: \"dev2 block\" indices: [\"idev2\", \"idev2_*\"] auth_key: dev2:test ```","title":"Templates handling in indices rule"},{"location":"details/indices-rule-templates/#index-templates","text":"An indices rule takes into consideration index patterns and aliases which are a part of a template definition. We should consider four types of template related requests:","title":"Index templates"},{"location":"details/indices-rule-templates/#create-an-index-template","text":"The request will be allowed when all of following conditions are met: * a template with requested name does not exist (if it does, it's rather a template modification, than a creation), * all index patterns of the new, requested template are allowed, * all aliases of the new, requested template are allowed. Example (click to expand) Let's try to add an index template. We can see, using `admin` account, that there are no templates defined yet. $ curl -vk -u admin:admin \"http://localhost:9200/_index_template?pretty\" HTTP/1.1 200 OK content-type: application/json; charset=UTF-8 { \"index_templates\" : [ ] } Now, let's use `dev1` user account to create an index template `temp1`: $ curl -vk -u dev1:test -XPUT \"http://127.0.0.1:9200/_index_template/test?pretty\" -H \"Content-Type: application/json\" -d \\ '{ \"index_patterns\":[\"index*\"], \"template\": { \"aliases\": { \"dev1_index\": {}, \"dev2_index\": {} } } }' HTTP/1.1 403 Forbidden content-type: application/json; charset=UTF-8 { \"error\" : { \"root_cause\" : [ { \"reason\" : \"forbidden\", \"due_to\" : [\"OPERATION_NOT_ALLOWED\"] } ], \"reason\" : \"forbidden\", \"due_to\" : [\"OPERATION_NOT_ALLOWED\"], \"status\" : 403 } } Oh, something went wrong. It seems that, a user `dev1` is not allowed to add this template. Let's check ROR logs to figure out why: > FORBIDDEN by default req={ ID:193441275-173645661#8, TYP:PutComposableIndexTemplateAction$Request, CGR:N/A, USR:dev1 (attempted), BRS:true, KDX:null, ACT:indices:admin/index_template/put, OA:127.0.0.1/32, XFF:null, DA:127.0.0.1/32, `IDX:index*,dev2_index,dev1_index`, MET:PUT, `PTH:/_index_template/test`, CNT: , HDR:Accept=*/*, Authorization= , Content-Length=157, Content-Type=application/json, Host=127.0.0.1:9200, User-Agent=curl/7.64.1, HIS:[CONTAINER ADMIN-> RULES:[auth_key->false] RESOLVED:[indices=index*,dev2_index,dev1_index;template=ADD(test:index*:dev2_index,dev1_index)]], `[dev1 block-> RULES:[auth_key->true, indices->false]` RESOLVED:[user=dev1;indices=index*,dev2_index,dev1_index;template=ADD(test:index*:dev2_index,dev1_index)]], [dev2 block-> RULES:[auth_key->false] RESOLVED:[indices=index*,dev2_index,dev1_index;template=ADD(test:index*:dev2_index,dev1_index)]], } We can see that our request was forbidden - credentials were OK, but `indices` rule was not matched in `dev1 block`. We can see also that ROR found 3 indices which are related to the request: * `index*` - an index pattern from our request * `dev1_index` - a first alias from out request * `dev2_index` - a second alias from out request When we take a look at indices configured in `indices` rule for our user, we can see that, he has an access only to `idev1` and `idev1_*` indices. Now, it's pretty much obvious why the request was blocked - the user has no access to index pattern and aliases used in the request. Let's try to fix that: $ curl -vk -u dev1:test -XPUT \"http://127.0.0.1:9200/_index_template/test?pretty\" -H \"Content-Type: application/json\" -d \\ '{ \"index_patterns\":[\"idev1_test*\"], \"template\": { \"aliases\": { \"idev1\": {}, \"idev1_test\": {} } } }' HTTP/1.1 200 OK content-type: application/json; charset=UTF-8 { \"acknowledged\" : true } Hooray! The index template was added. This time ROR allowed us to do so. It's because `dev1` user has an access to index pattern `idev1_test*`, because it is contained in `idev1_*`. Used aliases are also allowed.","title":"Create an index template"},{"location":"details/indices-rule-templates/#modify-an-index-template","text":"The request will be allowed when all of following conditions are met: * a template with requested name does exist, * all index patterns of the existing template are allowed, * all aliases of the existing template are allowed, * all index patterns of the requested template are allowed, * all aliases of the requested template are allowed. Example (click to expand) Let's assume the user `dev1` would like to modify the previously created template, because the index pattern is too detailed: $ curl -vk -u dev1:test -XPUT \"http://127.0.0.1:9200/_index_template/test?pretty\" -H \"Content-Type: application/json\" -d \\ '{ \"index_patterns\":[\"idev*\"], \"template\": { \"aliases\": { \"idev1\": {}, \"idev1_test\": {} } } }' HTTP/1.1 403 Forbidden content-type: application/json; charset=UTF-8 { \"error\" : { \"root_cause\" : [ { \"reason\" : \"forbidden\", \"due_to\" : [\"OPERATION_NOT_ALLOWED\"] } ], \"reason\" : \"forbidden\", \"due_to\" : [\"OPERATION_NOT_ALLOWED\"], \"status\" : 403 } } Ups! Something is wrong. Let's check the ROR forbidden log: > FORBIDDEN by default req={ ID:918326057-1726421783#75, TYP:PutComposableIndexTemplateAction$Request, CGR:N/A, USR:dev1 (attempted), BRS:true, KDX:null, ACT:indices:admin/index_template/put, OA:127.0.0.1/32, XFF:null, DA:127.0.0.1/32, `IDX:idev*,idev1,idev1_test`, MET:PUT, PTH:/_index_template/test, CNT: , HDR:Accept=*/*, Authorization= , Content-Length=151, Content-Type=application/json, Host=127.0.0.1:9200, User-Agent=curl/7.64.1, HIS:[CONTAINER ADMIN-> RULES:[auth_key->false] RESOLVED:[indices=idev*,idev1,idev1_test;template=ADD(test:idev*:idev1,idev1_test)]], `[dev1 block-> RULES:[auth_key->true, indices->false]` RESOLVED:[user=dev1;indices=idev*,idev1,idev1_test;template=ADD(test:idev*:idev1,idev1_test)]], [dev2 block-> RULES:[auth_key->false] RESOLVED:[indices=idev*,idev1,idev1_test;template=ADD(test:idev*:idev1,idev1_test)]], } We can see that `indices` rule hasn't not been matched. Looking at the IDX section, we can figure out that the index pattern we requested `idev*`, cannot be allowed. `idev*` is too generic, because in the `indices` list we have `[\"idev1\", \"idev1_*\"]`. Let's try to fix that: $ curl -vk -u dev1:test -XPUT \"http://127.0.0.1:9200/_index_template/test?pretty\" -H \"Content-Type: application/json\" -d \\ '{ \"index_patterns\":[\"idev1_*\"], \"template\": { \"aliases\": { \"idev1\": {}, \"idev1_test\": {} } } }' HTTP/1.1 200 OK content-type: application/json; charset=UTF-8 { \"acknowledged\" : true } Yeah, now it works. Let's check if the template is modified (we will use `admin` user to do so): $ curl -vk -u admin:admin \"http://127.0.0.1:9200/_index_template?pretty\" HTTP/1.1 200 OK content-type: application/json; charset=UTF-8 { \"error\" : { \"root_cause\" : [ { \"reason\" : \"forbidden\", \"due_to\" : [\"OPERATION_NOT_ALLOWED\"] } ], \"reason\" : \"forbidden\", \"due_to\" : [\"OPERATION_NOT_ALLOWED\"], \"status\" : 403 } } All is good. We have only one template and the modifications was applied. So far, so good. But we can wonder what happens if `dev2` will try to modify (or override) template `temp`? Let's check: $ curl -vk -u dev2:test -XPUT \"http://127.0.0.1:9200/_index_template/test?pretty\" -H \"Content-Type: application/json\" -d \\ '{ \"index_patterns\":[\"idev2_*\"], \"template\": { \"aliases\": { \"idev2\": {}, \"idev2_test\": {} } } }' HTTP/1.1 403 Forbidden content-type: application/json; charset=UTF-8 { \"error\" : { \"root_cause\" : [ { \"reason\" : \"forbidden\", \"due_to\" : [\"OPERATION_NOT_ALLOWED\"] } ], \"reason\" : \"forbidden\", \"due_to\" : [\"OPERATION_NOT_ALLOWED\"], \"status\" : 403 } } Yes! This is something what we wanted like to see. Even if the request was correct and the user `dev2` has an access to the requested index pattern and aliases, the request was forbidden. Obviously, there is already existed template `temp` which has the index pattern and aliases, which are not allowed for `dev2`. ROR deduces that `dev2` cannot be considered as someone how can modify/overwrite it. Pretty awesome. Won't `dev2` also be able to remove it? We'll see in next section ...","title":"Modify an index template"},{"location":"details/indices-rule-templates/#delete-an-index-template","text":"The request will be allowed when template does not exist OR all of the following conditions are met: * a template with requested name does exist, * all index patterns of the existing template are allowed, * all aliases of the existing template are allowed. Example (click to expand) In the last section we wondered, if ROR will be able to block removing the template `temp` by the user `dev2`. Let's recall, that we proved that the user is not able to modify this template, because ROR considers that he doesn't have permissions to change/remove it. $ curl -vk -u dev2:test -XDELETE \"http://127.0.0.1:9200/_index_template/test?pretty\" HTTP/1.1 403 Forbidden content-type: application/json; charset=UTF-8 { \"error\" : { \"root_cause\" : [ { \"reason\" : \"forbidden\", \"due_to\" : [\"OPERATION_NOT_ALLOWED\"] } ], \"reason\" : \"forbidden\", \"due_to\" : [\"OPERATION_NOT_ALLOWED\"], \"status\" : 403 } } Perfect! OK, but we also would like to know if `user1` will be able to remove his template. Let's check it: $ curl -vk -u dev1:test -XDELETE \"http://127.0.0.1:9200/_index_template/test?pretty\" HTTP/1.1 200 OK content-type: application/json; charset=UTF-8 { \"acknowledged\" : true } Great! Everything works.","title":"Delete an index template"},{"location":"details/indices-rule-templates/#get-index-templates","text":"At the moment ROR doesn't have templates rule (similar to snapshots or repositories ), which allows to restrict which templates can be visible to the user (it is going to change in the future). But the indices rule is enough to filter templates based on index patterns in their definitions. An index template is considered to be visible for a user, when the user has access to AT LEAST ONE index pattern of the template's index pattern list. ROR is going to show the template but to hide the information about not allowed index patterns and not allowed aliases. Example (click to expand) In previous sections we proved that ROR gets along with index templates adding, modifying and removing pretty well. Now, we'd like check what index templates are supposed to be visible for users. Let's assume we have 4 index templates: $ curl -vk -u admin:admin \"http://127.0.0.1:9200/_index_template?pretty\" HTTP/1.1 200 OK content-type: application/json; charset=UTF-8 { \"index_templates\" : [ { \"name\" : \"t1\", \"index_template\" : { \"index_patterns\" : [\"i*\"], \"template\" : { \"aliases\" : { \"idev2\" : { }, \"idev3\" : { }, \"idev1\" : { } } }, \"composed_of\" : [ ] } }, { \"name\" : \"t2\", \"index_template\" : { \"index_patterns\" : [\"idev1_*\"], \"template\" : { \"aliases\" : { \"admin_idev\" : { }, \"idev1\" : { } } }, \"composed_of\" : [ ], \"priority\" : 1 } }, { \"name\" : \"t3\", \"index_template\" : { \"index_patterns\" : [\"idev2_*\"], \"template\" : { \"aliases\" : { \"idev2\" : { }, \"admin_idev\" : { } } }, \"composed_of\" : [ ], \"priority\" : 1 } }, { \"name\" : \"t4\", \"index_template\" : { \"index_patterns\" : [\"idev1_*\", \"idev2_*\"], \"template\" : { \"aliases\" : { \"idev2\" : { }, \"admin_idev\" : { }, \"idev1\" : { } } }, \"composed_of\" : [ ], \"priority\" : 2 } } ] } `admin` has unrestricted access to all templates. Now, let's check which templates `dev` are supposed to see: $ curl -vk -u dev1:test \"http://127.0.0.1:9200/_index_template?pretty\" HTTP/1.1 200 OK content-type: application/json; charset=UTF-8 { \"index_templates\" : [ { \"name\" : \"t1\", \"index_template\" : { \"index_patterns\" : [\"i*\"], \"template\" : { \"aliases\" : { \"idev1\" : { } } }, \"composed_of\" : [ ] } }, { \"name\" : \"t2\", \"index_template\" : { \"index_patterns\" : [\"idev1_*\"], \"template\" : { \"aliases\" : { \"idev1\" : { } } }, \"composed_of\" : [ ], \"priority\" : 1 } }, { \"name\" : \"t4\", \"index_template\" : { \"index_patterns\" : [\"idev1_*\"], \"template\" : { \"aliases\" : { \"idev1\" : { } } }, \"composed_of\" : [ ], \"priority\" : 2 } } ] } Hmm, we can see many weird things here. Let's start with the simplest case: index template `t2` is allowed for the user, because the used index pattern is allowed by `indices` rule. But we can also see that user `dev1` is not aware of existence the `admin_idev` alias - it was filter out from the aliases list. The user has no access to the alias, so he should not be able to see it. What about the index template `t3`? `dev1` is not allowed to see it because the index pattern `idev2_*` is not allowed for him. It was also pretty much obvious! The next is `t4`. When `admin` had listed index templates, we saw that template `t4` has 2 index patterns. But `dev1` can see only one. This is great, because he has an access to a part of that template, so he definitely should be able to see it. ROR behaviour here is pretty neat - it allows the user to see a template with filtered, not allowed parts of it, but at the same time, the user doesn't have permissions to modify/remove the template (Don't believe me? Go ahead and check!) And the last one to explain - `t1`. The index pattern of the template is `i*`. Obviously user `dev1` has no access to it, because his allowed indices are `idev1, idev1_*`. But if we imagine all possible values generated from pattern `i*` and all possible values generated from `idev1, idev1_*`, we can notice that the latter will be a subset of the first. It means that this template can be interesting for the user `dev1`, because it will ba applied to indices created by him. That's why ROR decides to show it.","title":"Get index templates"},{"location":"details/indices-rule-templates/#component-templates","text":"Component templates doesn't have index patterns but could have aliases. So, in this case, we should also consider four types of template related requests:","title":"Component templates"},{"location":"details/indices-rule-templates/#create-a-component-template","text":"The request will be allowed when all of following conditions are met: * a template with requested name does not exist (if it does, it's rather a template modification, than a creation), * all aliases of the new, requested template are allowed. Example (click to expand) Unlike index templates, component templates don't have index patterns. But they still have aliases. So, their behaviour according to an aliases usage is quite similar, but there are several differences which are worth mentioning. Let's check if `dev1` user can create a component template: $ curl -vk -u dev1:test \"http://localhost:9200/_component_template/ctemp1?pretty\" -XPUT -H \"Content-Type: application/json\" -d \\ '{ \"template\": { \"settings\": { \"index.number_of_replicas\": 0 }, \"aliases\": { \"idev1\": {}, \"idev2\": {} } } }' HTTP/1.1 403 Forbidden content-type: application/json; charset=UTF-8 { \"error\" : { \"root_cause\" : [ { \"reason\" : \"forbidden\", \"due_to\" : [\"OPERATION_NOT_ALLOWED\"] } ], \"reason\" : \"forbidden\", \"due_to\" : [\"OPERATION_NOT_ALLOWED\"], \"status\" : 403 } } Oh, user `dev1` is not allowed to create this template. But wait! It looks like we have the same problem as had while creating index template. Alias `idev2` is not allowed. Let's try to do the same without this alias: $ curl -vk -u dev1:test \"http://localhost:9200/_component_template/ctemp1?pretty\" -XPUT -H \"Content-Type: application/json\" -d \\ '{ \"template\": { \"settings\": { \"index.number_of_replicas\": 0 }, \"aliases\": { \"idev1\": {} } } }' HTTP/1.1 200 OK content-type: application/json; charset=UTF-8 { \"acknowledged\" : true } Ha! As expected. A user has to have access to all aliases during adding a component template which has aliases defined. *Note* If a component template doesn't involve aliases, there is no restriction from ROR side to add one. It can be changed in future, when we add sth like `templates` rule.","title":"Create a component template"},{"location":"details/indices-rule-templates/#modify-a-component-template","text":"The request will be allowed when all of following conditions are met: * a template with requested name does exist, * all aliases of the existing template are allowed, * all aliases of the requested template are allowed. Example (click to expand) In the previous example, user `dev1` created the component template `ctemp1` with one alias `idev1`. Let's check if user `dev2` will be able to modify it: $ curl -vk -u dev2:test \"http://localhost:9200/_component_template/ctemp1?pretty\" -XPUT -H \"Content-Type: application/json\" -d \\ '{ \"template\": { \"settings\": { \"index.number_of_replicas\": 0 }, \"aliases\": { \"idev2\": {} } } }' HTTP/1.1 403 Forbidden content-type: application/json; charset=UTF-8 { \"error\" : { \"root_cause\" : [ { \"reason\" : \"forbidden\", \"due_to\" : [\"OPERATION_NOT_ALLOWED\"] } ], \"reason\" : \"forbidden\", \"due_to\" : [\"OPERATION_NOT_ALLOWED\"], \"status\" : 403 } } No. And this is a good behaviour, because `dev2` doesn't have an access to the alias `idev1` which the `ctemp1` has. ROR assumes, that he cannot modify the component template (please notice, that the same request will be allowed when a different, nonexistent component template name is used). I can assure you that `dev1` is able to modify the template (you can check if you want).","title":"Modify a component template"},{"location":"details/indices-rule-templates/#delete-a-component-template","text":"The request will be allowed when template does not exist OR all of the following conditions are met: * a template with requested name does exist, * all aliases of the existing template are allowed. Example (click to expand) If you read the previous example, you won't find anything interesting here. A component template can be removed only by someone whom ROR considers to have modification rights of the template. See that `dev2` is not able to remove `ctemp1`: $ curl -vk -u dev2:test -XDELETE \"http://localhost:9200/_component_template/ctemp1?pretty\" HTTP/1.1 403 Forbidden content-type: application/json; charset=UTF-8 { \"error\" : { \"root_cause\" : [ { \"reason\" : \"forbidden\", \"due_to\" : [\"OPERATION_NOT_ALLOWED\"] } ], \"reason\" : \"forbidden\", \"due_to\" : [\"OPERATION_NOT_ALLOWED\"], \"status\" : 403 } } I told you. But please remember that only aliases are checked by ROR when it's trying to figure out modification rights of a component template. If a component template doesn't have any aliases, it can be modified or deleted by any user.","title":"Delete a component template"},{"location":"details/indices-rule-templates/#get-component-templates","text":"At the moment there is no way to restrict which component templates can be visible to the user (it is going to change in the future - see a corresponding index template section). But ROR is going to hide the information about not allowed aliases of returned component templates. Example (click to expand) A careful reader can guess that ROR won't forbid showing component templates. But similar to indices templates, ROR will filter out aliases list depending on an aliases accessability of current user. Let's see an example: $ curl -vk -u admin:admin \"http://localhost:9200/_component_template?pretty\" HTTP/1.1 200 OK content-type: application/json; charset=UTF-8 { \"component_templates\" : [ { \"name\" : \"ctemp2\", \"component_template\" : { \"template\" : { \"settings\" : { \"index\" : { \"number_of_replicas\" : \"0\" } }, \"aliases\" : { \"idev2\" : { } } } } }, { \"name\" : \"ctemp1\", \"component_template\" : { \"template\" : { \"settings\" : { \"index\" : { \"number_of_replicas\" : \"0\" } }, \"aliases\" : { \"idev1\" : { } } } } } ] } We can see that we have two component templates. `ctemp1` has alias `idev1` and `ctemp2` alias `idev2`. Let check what templates `dev1` user will be able to see: $ curl -vk -u dev1:test \"http://localhost:9200/_component_template?pretty\" HTTP/1.1 200 OK content-type: application/json; charset=UTF-8 { \"component_templates\" : [ { \"name\" : \"ctemp2\", \"component_template\" : { \"template\" : { \"settings\" : { \"index\" : { \"number_of_replicas\" : \"0\" } }, \"aliases\" : { } } } }, { \"name\" : \"ctemp1\", \"component_template\" : { \"template\" : { \"settings\" : { \"index\" : { \"number_of_replicas\" : \"0\" } }, \"aliases\" : { \"idev1\" : { } } } } } ] } We can see that he is able to see all component templates, but `ctemp2` doesn't have `idev2` alias. User `dev1` has no access to the alias, so response returned by ROR doesn't contain the alias. Similar behaviour we will observe when `dev2` user will try to get all templates.","title":"Get component templates"},{"location":"details/indices-rule-templates/#troubleshooting","text":"To figure out why the template is not returned or/and cannot be altered, you should enable a DEBUG log level and check your logs. ROR logs each step of template request handling in the indices rule, so detailed description should explain the given template is not allowed.","title":"Troubleshooting"},{"location":"details/kibana-7.8.x-and-older/","text":"Kibana 7.8.x and older Kibana Plugin overview ReadonlyREST plugin for Kibana is not open source, and it's offered as part of the ReadonlyREST PRO and ReadonlyREST ENTERPRISE , and ReadonlyREST Free packages. See product descriptions and a comparison chart in the official ReadonlyREST website ReadonlyREST plugins for Kibana always require ReadonlyREST Free to be installed in the Elasticsearch nodes your Kibana instance(s) will connect to. It's not mandatory to install ReadonlyREST Free in all Elasticsearch nodes, but only in the ones in where you need the HTTP interface to be secured. After purchasing You will receive a link to the plugin zip file in an email. Download your zip. You will be able to download it also in the future as long as your subscription is active. Version strings All our plugins include in their file name a version string. For example the file readonlyrest-1.16.26_es6.4.0.zip has a version string 1.16.26_es6.4.0 . Reading version strings Given the version string 1.16.26_es6.4.0 ReadonlyREST plugin code version 1.16.26 Works only with Elasticsearch/Kibana version 6.4.0 The \"es\" stands for \"Elastic stack\" which used to mean the family of products made by Elastic which get released at the same time under the same version number. This was chosen before Elastic renamed their X-Pack commercial offer to Elastic Stack. To be clear, there is no affiliation between ReadonlyREST and Elastic, or their commercial products. Trial builds version strings Trial builds are valid for 30 days after they were built, and they will stop working soon after the time is elapsed. Trial builds have a special version string which includes a build-time timestamp. I.e. readonlyrest_kbn_pro-1.16.26-20180911_es6.0.0.zip ReadonlyREST PRO plugin version 1.16.26 Build date 11th September 2018, expiring on the 11th of October 2018. Works only with Kibana version 6.0.0 When an update is out You will receive another email notification that a new deliverable is available. If the update contains a security fix, it is very important that you take action and update the plugin immediately . Installation You can install this as a normal Kibana plugin using the bin/kibana-plugin utility. Install via URL This installation method is more practical if your Kibana server is connected to the internet. According to what edition of ReadonlyREST you want to install, from your Kibana installation, launch one of the commands: Please note that this will always download the latest version of Kibana plugin available for the current supported Elasticsearch version. # ReadonlyREST Free edition $ bin/kibana-plugin install \"https://api.beshu.tech/download/kbn?edition=kbn_free&email=<your_email_address>\" # ReadonlyREST PRO (30 days trial) edition $ bin/kibana-plugin install \"https://api.beshu.tech/download/trial?edition=kbn_pro&email=<your_email_address>\" # ReadonlyREST Enterprise (30 days trial) edition $ bin/kibana-plugin install \"https://api.beshu.tech/download/trial?edition=kbn_enterprise&email=<your_email_address>\" If you want to download the latest version of plugin for a specific version of Elasticsearch, then use query parameter esVersion to specify your required Elasticsearch version. # ReadonlyREST Free edition for Elasticsearch 7.6.1 $ bin/kibana-plugin install \"https://api.beshu.tech/download/kbn?edition=kbn_free&esVersion=7.6.1&email=<your_email_address>\" # ReadonlyREST PRO (30 days trial) edition for Elasticsearch 7.6.1 $ bin/kibana-plugin install \"https://api.beshu.tech/download/trial?edition=kbn_pro&esVersion=7.6.1&email=<your_email_address>\" # ReadonlyREST Enterprise (30 days trial) edition for Elasticsearch 7.6.1 $ bin/kibana-plugin install \"https://api.beshu.tech/download/trial?edition=kbn_enterprise&esVersion=7.6.1&email=<your_email_address>\" If you want to download an older version of plugin for a specific version of Elasticsearch, then use query parameter pluginVersion along with esVersion. # ReadonlyREST Free edition - version 1.22.0 for Elasticsearch 7.6.1 $ bin/kibana-plugin install \"https://api.beshu.tech/download/kbn?edition=kbn_free&esVersion=7.6.1&pluginVersion=1.22.0&email=<your_email_address>\" # ReadonlyREST PRO (30 days trial) edition - version 1.22.0 for Elasticsearch 7.6.1 $ bin/kibana-plugin install \"https://api.beshu.tech/download/trial?edition=kbn_pro&esVersion=7.6.1&pluginVersion=1.22.0&email=<your_email_address>\" # ReadonlyREST Enterprise (30 days trial) edition - version 1.22.0 for Elasticsearch 7.6.1 $ bin/kibana-plugin install \"https://api.beshu.tech/download/trial?edition=kbn_enterprise&esVersion=7.6.1&pluginVersion=1.22.0&email=<your_email_address>\" If you are a PRO or Enterprise subscriber, the link will include an extra parameter \"token\" which can only be used in association with the provided email address. You can append required plugin version and Elasticsearch version query parameters to download specific version as described above. NB: This URL is personal, and should be handled as a secret. # ReadonlyREST PRO (Official) edition $ bin/kibana-plugin install \"https://api.beshu.tech/download/trial?edition=kbn_pro&email=<your_email_address>&token=<your_secret_token>\" # ReadonlyREST Enterprise (30 days trial) edition $ bin/kibana-plugin install \"https://api.beshu.tech/download/trial?edition=kbn_enterprise&email=<your_email_address>&token=<your_secret_token>\" You can obtain official links with personal secret tokens using our self service download form , once your email address has been recognized as active subscriber. Install from zip file $ bin/kibana-plugin install file:///home/user/downloads/readonlyrest_kbn-X.Y.Z_esW.Q.U.zip Notice how we need to type in the format file:// + absolute path (yes, with three slashes). Uninstall $ bin/kibana-plugin remove readonlyrest_kbn Upgrade Just uninstall the old version and install the new version. $ bin/kibana-plugin remove readonlyrest_kbn Install the new version of ReadonlyREST into Kibana. $ bin/kibana-plugin install file:///home/user/downloads/readonlyrest_kbn-*.zip # Only for older versions (until Kibana early 6.x) $ touch optimize/bundles/readonlyrest_kbn.style.css Restart Kibana. Using ROR with a reverse proxy ROR - just like Kibana itself - is meant to be used either with a proxy or without one, but not both simultaneously. If you decide to set the server.basePath property in kibana.yml be sure to access RoR via a proxy, as it will not work properly when accessed directly. Configuration ReadonlyREST for Kibana is completely remote-controlled from the Elasticsearch configuration. Login credentials, hidden Kibana apps, etc. are all going to be configured from the Elasticearch side via the usual \"rules\". This means the configuration will be kept all in one place and if you used ReadonlyREST before , it will be also very familiar. In this document, every time you will encounter references to \"readonlyrest.yml\" or \"elasticsearch.yml\", we will be referring to the configuration files in the Elasticsearch plugin (our Kibana plugins do not need a \"readonlyrest.yml\"). In general, by design, we tend to concentrate all configuration within the main plugin (the Elasticsearch one) as much as possible. Clusterwide Settings vs readonlyrest.yml Our Kibana plugins introduce a \"ReadonlyREST\" Kibana app. From here, you can edit the security settings of the whole Elasticsearch cluster, and they will take effect within 10 seconds in all Elasticsearch cluster nodes without the need to restart them. When you change the security settings from the Kibana app, they will be saved in a special index called \".readonlyrest\", so all the Elasticsearch nodes will pick them up. You can customize a name of the index by setting readonlyrest.settings_index: .my_custom_readonlyrest in elasticsearch.yml file (remember to set the same value for all your ES nodes). When an Elasticsearch node restarts, the order of settings evaluation is the following: 1. Attempt to find valid settings in readonlyrest.yml 2. If none is found, look inside elasticsearch.yml 3. Once successfully bootstrapped using file-based settings, attempt to read \".readonlyrest\" index 4. If the index exists and contains valid settings, override file based settings with the ones from the index. 5. Pressing \"save\" in the cluster wide settings app, will not overwrite the readonlyrest.yml file. Best practices: Build and update your production security settings from the Kibana app (will be saved in index) Protect the \".readonlyrest\" Kibana index with an ACL rule Loading settings: order of precedence As you read, there are two possible places where the settings can be read from: readonlyrest.yml a file the user needs to create in the same directory where elasticsearch.yml is found. .readonlyrest index. Our Kibana plugins' GUI (PRO/Enterprise) is programmed to write this index. When the ES plugin boots up, it follows some logic to evaluate where to read the YAML settings from. The following diagram shows how that works. Malformed in-index settings If for some reason the in-index settings get corrupted and ROR can't parse them, then neither settings from file or in-index settings can be loaded, so ES can't start. In this case ES would print message like: Loading ReadonlyREST settings from index failed: Settings config content is malformed. Details: while scanning a quoted scalar in 'reader', line 9, column 17: auth_key: \"admin:container ^ To recover from this state, set readonlyrest.force_load_from_file: true in elasticsearch.yaml on one node es1 . Example recovery settings: elasticsearch.yaml [...] readonlyrest: force_load_from_file: true readonlyrest.yaml readonlyrest: access_control_rules: - name: \"::ADMIN recover::\" auth_key: admin:dev indices: [\"*\"] Then remove in-index settings index manually. curl -X DELETE \"admin:dev@es1:9200/.readonlyrest?pretty\" Now you can restore your settings to readonlyrest.yml , remove readonlyrest.force_load_from_file: true from elasticsearch.yaml and restart node. Example: multiuser ELK Make sure X-Pack is uninstalled or disabled from elasticsearch.yml (on the Elasticsearch side) and kibana.yml (on the Kibana side): This is how you disable X-pack modules: # For X-Pack users: you may only leave monitoring on. # Don't add this if X-Pack is not installed at all, or Kibana won't start. xpack.monitoring.enabled: true xpack.security.enabled: false xpack.watcher.enabled: false xpack.telemetry.enabled: false This is a typical example of configuration snippet to add at the end of your readonlyrest.yml (the settings file of the Elasticsearch plugin), to support ReadonlyREST PRO. readonlyrest: access_control_rules: - name: \"::LOGSTASH::\" auth_key: logstash:logstash actions: [\"indices:data/read/*\",\"indices:data/write/*\",\"indices:admin/template/*\",\"indices:admin/create\"] indices: [\"logstash-*\"] - name: \"::KIBANA-SRV::\" auth_key: kibana:kibana - name: \"::RO::\" auth_key: ro:dev kibana_access: ro indices: [ \".kibana\", \"logstash-*\"] kibana_hide_apps: [\"readonlyrest_kbn\", \"timelion\", \"kibana:dev_tools\", \"kibana:stack_management\"] - name: \"::RW::\" auth_key: rw:dev kibana_access: rw indices: [\".kibana\", \"logstash-*\"] kibana_hide_apps: [\"readonlyrest_kbn\", \"timelion\", \"kibana:dev_tools\", \"kibana:stack_management\"] - name: \"::ADMIN::\" auth_key: admin:dev # KIBANA ADMIN ACCESS NEEDED TO EDIT SECURITY SETTINGS IN ROR KIBANA APP! kibana_access: admin - name: \"::WEBSITE SEARCH BOX::\" indices: [\"public\"] actions: [\"indices:data/read/*\"] Very important Whatever your configuration ends up being, remember: The admin user has kibana_access: admin Remember to use kibana_hide_apps: [\"readonlyrest_kbn\"] to hide the ReadonlyREST icon from who is not meant to use it (makes for a better UX). Rules ordering matters Blocks related to the authentication of the users should be at the top of the ACL One of the most common mistakes is forgetting that the ACL blocks are evaluated in order from the first to the last. So, some request with credentials can be let through from one of the first blocks and come back to Kibana with no user identity metadata associated. Take this example of troublesome ACL: # PROBLEMATIC SETTINGS (EXAMPLE) \u26a0\ufe0f access_control_rules: - name: \"::FIRST BLOCK::\" hosts: [\"127.0.0.1\"] actions: [...] - name: \"::ADMIN::\" auth_key: admin:dev kibana_access: admin The user will be able to login because the login request will be allowed by the first ACL block. But the ACL will not have resolved any metadata about the user identity (credentials checking was ignored)! This means the response to the Kibana login request will contain no user identity metadata (username, hidden apps, etc) and ReadonlyREST for Kibana won't be able to function correctly. The solution to this is to reorder the ACL blocks, so the ones that authenticate Kibana users are on the top. # SOLUTION: KIBANA USER AUTH RELATED BLOCKS GO FIRST! \u2705\ud83d\udc4d access_control_rules: - name: \"::ADMIN::\" auth_key: admin:dev kibana_access: admin - name: \"::FIRST BLOCK::\" hosts: [\"127.0.0.1\"] actions: [...] Session cookie expiration When a user logs in, ReadonlyREST will write an encrypted cookie in the browser. This cookie has an time to live that can be tweaked with the following configuration key in kibana.yml . readonlyrest_kbn.session_timeout_minutes: 600 # defaults to 4320 (3 days) Clearing Session History By default, all the session data like search history, dev tool commands history, etc, will be wiped out from the browser whenever a new user is logged in, or a user changes tenancy. To override this behaviour, use this setting: readonlyrest_kbn.clearSessionOnEvents: [\"never\"] Possible values: \"login\", \"tenancyHop\", \"never\" . Kibana App strings Examples of valid arguments for the kibana_hide_apps: [...] rule (readonlyrest.yml) hide-app key App name App url kibana:discover Discover http://kibana-url:5601/app/kibana#/discover kibana:visualize Visualize http://kibana-url:5601/app/kibana#/visualize kibana:dashboard Dashboard http://kibana-url:5601/app/kibana#/dashboards timelion Timelion http://kibana-url:5601/app/timelion canvas Canvas http://kibana-url:5601/app/canvas maps Maps http://kibana-url:5601/app/maps code Code (Beta) http://kibana-url:5601/app/code ~~readonlyrest_kbn~~ (obsolete) ~~ReadonlyREST~~ ~~\\~\\~[~~ http://kibana-url:5601/app/readonlyrest_kbn\\~\\~](http://kibana-url:5601/app/readonlyrest_kbn)\\~\\~\\~\\~ ml Machine Learning http://kibana-url:5601/app/ml infra:home Infrastructure http://kibana-url:5601/app/infra#/infrastructure/inventory?_g=( ) infra:logs Logs http://kibana-url:5601/app/infra#/logs?_g=( ) apm APM http://kibana-url:5601/app/apm uptime Uptime http://kibana-url:5601/app/uptime#/ siem SIEM http://kibana-url:5601/app/siem graph Graph http://kibana-url:5601/app/graph kibana:dev_tools Dev Tools http://kibana-url:5601/app/kibana#/dev_tools monitoring Stack Monitoring http://kibana-url:5601/app/monitoring kibana:stack_management Stack Management http://kibana-url:5601/app/kibana#/management Kibana configuration Activate authentication for the Kibana server: let the Kibana daemon connect to Elasticsearch using a pair of credentials we just defined in readonlyrest.yml (see above, the ::KIBANA-SRV:: block). Open up conf/kibana.yml and add the following: # This is kibana.yml, but copy the exact same in elasticsearch.yml if you have to use some X-pack features. xpack.graph.enabled: false xpack.ml.enabled: false xpack.monitoring.enabled: true xpack.security.enabled: false # this is fundamental! xpack.watcher.enabled: false # Kibana server use ::KIBANA-SRV:: credentials elasticsearch.username: \"kibana\" elasticsearch.password: \"kibana\" And of course also make sure elasticsearch.url points to the designated Elasticsearch instance (check also the http or https) Proxy Auth ROR for Elasticsearch can delegate authentication to a reverse proxy which will enforce some kind of authentication, and pass the successfully authenticated user's name inside a X-Forwarded-User header. Today, it's possible to skip the regular ROR login form and use the \"delegated authentication\" technique in ROR for Kibana as well. Configure ROR for ES to expect delegated authentication (see proxy_auth rule ) in ROR for ES documentation. Open up conf/kibana.yml and add readonlyrest_kbn.proxy_auth_passthrough: true Now ROR for Kibana will skip the login form entirely , and will only require that all incoming requests must carry a X-Forwarded-User header containing the user's name. Based on this identity, ROR for Kibana will build an encrypted cookie and handle your session normally. Custom Logout link Normally, when a user presses the logout button in ROR for Kibana, it deletes the encrypted cookie that represents the users identity and the login form is shown. However, when the authentication is delegated to a proxy, the logout button needs to become a link to some URL capable to unregister the session a user initiated within the proxy. For this, ROR for Kibana offers a way to customize the logout button's URL: Find a link that will delete the reverse proxy's user session Open up conf/kibana.yml and add readonlyrest_kbn.custom_logout_link: https://..../logout Now users that gained a session through delegated auth, can also click on the logout button in ROR for kibana and actually exit their session. Custom Login link When you delegate authentication to an external service, you can tell ReadonlyREST to skip the classic login form entirely and redirect users to your proxy or identity provider's login screen. To enable this: Find your authentication proxy or identity provider login URL for the ROR app Open up conf/kibana.yml and add readonlyrest_kbn.custom_login_link: \"https://../login\" The advantage of this approach is a streamlined user experience for users that login with an external IdP. The disadvantage is that you give up the possibility to login as a local user in ROR, as the login form will be always skipped. Caveat Enabling proxy auth passthrough will relax the requirement to provide a password. Therefore, don't enable this option if you don't make sure Kibana can only be accessed through the reverse proxy* . JWT Token Forwarding as URL Query Parameter Alternatively to typing in credentials in the standard login form, it is possible to create an authenticated Kibana session by passing a JWT token as a query parameter in a URL. Configuration To enable this feature in ReadonlyREST, you need to: Have JWT authentication configured in ReadonlyREST (modifying readonlyrest.yml or the cluster wide settings UI in the Kibana plugin). See how . Specify the query parameter name in kibana.yml by adding the line readonlyrest_kbn.jwt_query_param: \"jwt\" as a string, in our case \"jwt\". In Action Once Kibana is restarted, you will be able to navigate to a link like this: http://kibana:5601/login?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzdWIiOiIxMjM0NTY3ODkwIiwibmFtZSI6IkpvaG4gRG9lIiwiYWRtaW4iOnRydWV9.TJVA95OrM7E2cBab30RMHrHDcEfxjoYZgeFONFh7HgQ The following will happen: The Kibana plugin will forward the JWT token found in the query parameter into the Authorization header in a request to Elasticsearch. Elasticsearch will cryptographically authenticate and resolve the user's identity from the JWT claims. Kibana will write an encrypted cookie in your browser and use that from now on for the length of the authenticated session. From here onwards, the session management will be identical to the normal login form flow. When the user presses logout, Kibana will delete the cookie and redirect you to the login form, or whatever link you configured as readonlyrest_kbn.custom_logout_link . Deep linking with JWT Because the identity is embedded in the link, and ReadonlyREST is able to authenticate the call on the fly, the JWT authentication can be used in conjunction with nextUrl query parameter for sharing deep links inside Kibana apps, or embedding visualizations and dashboards inside I-Frames. Anatomy of a JWT deep link http://kibana:5601/login?jwt=<the-token>&nextUrl=urlEncode(<kibana-path>) In Javascript one can compose a JWT deep link as follows: var absoluteKibanaPath = '/app/kibana#/visualize/edit/28dcde30-2258-11e8-82a3-af58d04b3c02?_g=()'; var url = 'http://kibana:5601/login?jwt=' + jwtToken + '&nextUrl=' + encodeURI(absoluteKibanaPath); console.log(\"Final JWT deep link: \" + url) The result may look something like this: http://localhost:5601/login?nextUrl=%2Fapp%2Fkibana%23%2Fvisualize%2Fedit%2F28dcde30-2258-11e8-82a3-af58d04b3c02%3F_g%3D%28%29&jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzdWIiOiIxMjM0NTY3ODkwIiwibmFtZSI6IkpvaG4gRG9lIiwiYWRtaW4iOnRydWV9.TJVA95OrM7E2cBab30RMHrHDcEfxjoYZgeFONFh7HgQ Audit log The audit log feature is widely described in \ud83d\udcd6docs for Elasticsearch plugin . Kibana plugin has predefined dashboard representing collected audit data. Loading visualization In the Audit tab of the ReadonlyREST Kibana app, there is a button that automatically creates a dashboard with some audit log specific visualizations. Click the Load button to load the dashboard and visualizations. An Override checkbox allows to reload the default dashboard and visualizations. It will override any previously loaded audit log dashboard. In detail, this feature creates three Kibana \"saved objects\": an index pattern for readonlyrest_audit-* a dashboard called ReadonlyREST Audit Log some visualizations Dashboard The audit log dashboard, by default, has only a few basic visualizations. They cover security, access logs, and performance metrics. SAML ReadonlyREST Enterprise supports service provider initiated via SAML. This connector supports both SSO (single sign on) and SLO (single log out). Here is how to configure it. Configure ror_kbn_auth bridge In order for the user identity information to flow securely from Kibana to Elasticsearch, we need to set up the two plugin with a shared secret, that is: an arbitrarily long string. Elasticsearch side Edit readonlyrest.yml readonlyrest: access_control_rules: - name: \"::KIBANA-SRV::\" auth_key: kibana:kibana ... all usual blocks of rules... - name: \"ReadonlyREST Enterprise instance #1\" ror_kbn_auth: name: \"kbn1\" ror_kbn: - name: kbn1 signature_key: \"my_shared_secret_kibana1_(min 256 chars)\" # <- use environmental variables for better security! \u26a0\ufe0fIMPORTANT the Basic HTTP auth credentials for the Kibana server are still needed for now, due to how Kibana works. Kibana side Edit kibana.yml and append: readonlyrest_kbn.auth: signature_key: \"my_shared_secret_kibana1(min 256 chars)\" saml_serv1: enabled: true type: saml issuer: ror buttonName: \"Partner's SSO Login\" entryPoint: 'https://my-saml-idp/saml2/http-post/sso' # <-- identity Provider's URL, to request to sign on kibanaExternalHost: 'my.public.hostname.com' # <-- public URL used by the Identity Provider to call back Kibana with the \"assertion\" message protocol: http # <-- is the Kibana server listening for \"http\" \"https\" connections? Default: http usernameParameter: 'nameID' groupsParameter: 'memberOf' logoutUrl: 'https://my-saml-idp/saml2/http-post/slo' # OPTIONAL, advanced parameters # decryptionCert: /etc/ror/integration/certs/pub.crt # cert: /etc/ror/integration/certs/dag.crt # decryptionPvk: /etc/ror/integration/certs/decrypt_pvk.crt # issuer: saml_sso_idp issuer : issuer string to supply to identity provider during sign on request. Defaults to 'ror' disableRequestedAuthnContext : if truthy, do not request a specific authentication context. This is known to help when authenticating against Active Directory (AD FS) servers. decryptionPvk : Service Provider Private Key. Private key that will be used to attempt to decrypt any encrypted assertions that are received. cert: The downloadable certificate in IDP Metadata (file, absolute path) For advanced SAML options, see passport-saml documentation . Identity provider side Enter the settings of your identity provider, create a new app. Configure it using the information found by connecting to http://my.public.hostname.com/ror_kbn_sso_saml_serv1/metadata.xml Example response: <?xml version=\"1.0\"?> <EntityDescriptor xmlns=\"urn:oasis:names:tc:SAML:2.0:metadata\" xmlns:ds=\"http://www.w3.org/2000/09/xmldsig#\" entityID=\"onelogin_saml\" ID=\"onelogin_saml\"> <SPSSODescriptor protocolSupportEnumeration=\"urn:oasis:names:tc:SAML:2.0:protocol\"> <SingleLogoutService Binding=\"urn:oasis:names:tc:SAML:2.0:bindings:HTTP-POST\" Location=\"http://my.public.hostname.com/ror_kbn_sso/notifylogout\"/> <NameIDFormat>urn:oasis:names:tc:SAML:1.1:nameid-format:emailAddress</NameIDFormat> <AssertionConsumerService index=\"1\" isDefault=\"true\" Binding=\"urn:oasis:names:tc:SAML:2.0:bindings:HTTP-POST\" Location=\"http://my.public.hostname.com/ror_kbn_sso/assert\"/> </SPSSODescriptor> </EntityDescriptor> Create some users and some groups in the identity provider app Check the user profile parameter names that the identity provider uses during the assertion callback ( TIP : set kibana in debug mode so ReadonlyREST will print the user profile). Match the name of the parameter used by the identity provider to carry the unique user ID (in the assertion message) to the usernameParameter kibana YAML setting. If you want to use SAML for authorization, take care of matching also the groupsParameter to the parameter name found in the assertion message to the kibana YAML setting. OpenID Connect (OIDC) ReadonlyREST Enterprise support OpenID Connect for authentication and authorization. soon we will create a specific guide only for OpenID, like the ones we have for SAML Here is how to configure it. Configure ror_kbn_auth bridge This part is identical as seen in SAML connectors. In order for the user identity information to flow securely from Kibana to Elasticsearch, we need to set up the two plugin with a shared secret, that is: an arbitrarily long string. Elasticsearch side Edit readonlyrest.yml readonlyrest: access_control_rules: - name: \"::KIBANA-SRV::\" auth_key: kibana:kibana ... all usual blocks of rules... - name: \"ReadonlyREST Enterprise instance #1\" ror_kbn_auth: name: \"kbn1\" ror_kbn: - name: kbn1 signature_key: \"my_shared_secret_kibana1_(min 256 chars)\" # <- use environmental variables for better security! \u26a0\ufe0fIMPORTANT the Basic HTTP auth credentials for the Kibana server are still needed for now, due to how Kibana works. If you have configured OIDC with the groupsParameter ( See below ), you can also restrict ACL to specific groups: readonlyrest: access_control_rules: - name: \"::KIBANA-SRV::\" auth_key: kibana:kibana ... all usual blocks of rules... - name: \"ReadonlyREST Enterprise instance #1 for group 1\" ror_kbn_auth: name: \"kbn1\" groups: [\"group1\"] - name: \"ReadonlyREST Enterprise instance #1 for group 2\" ror_kbn_auth: name: \"kbn1\" groups: [\"group2\"] ror_kbn: - name: kbn1 signature_key: \"my_shared_secret_kibana1_(min 256 chars)\" # <- use environmental variables for better security! You may also use any custom claim from the OIDC userinfo token in ACL rules by using {{jwt:assertion.<path_to_your_claim>}} syntax. See the dedicated section for more information. ( TIP : Do not forget the assertion prefix in front of you jsonpath. ) Kibana side We will assume the OpenID identity provider responds to port 8080 of localhost. In our example, we used Keycloak, an open source implementation of OpenID Connect identity provide. Edit kibana.yml and append: readonlyrest_kbn.auth: signature_key: \"my_shared_secret_kibana1(min 256 chars)\" oidc_kc: buttonName: \"KeyCloak OpenID\" type: \"oidc\" issuer: 'http://localhost:8080/auth/realms/ror' authorizationURL: 'http://localhost:8080/auth/realms/ror/protocol/openid-connect/auth' tokenURL: 'http://localhost:8080/auth/realms/ror/protocol/openid-connect/token' userInfoURL: 'http://localhost:8080/auth/realms/ror/protocol/openid-connect/userinfo' clientID: 'ror_oidc' clientSecret: '9f1d39c8-a211-460a-84b6-0a4a1499c455' scope: 'openid profile roles role_list email' usernameParameter: 'preferred_username' groupsParameter: 'groups' kibanaExternalHost: 'localhost:8080' logoutUrl: 'http://localhost:8080/auth/realms/ror/protocol/openid-connect/logout' Identity provider side Enter the settings interface of your identity provider, and create a new OpenID app . The redirect URL should be configured as http://localhost:5601/* assuming kibana is listening on localhost and on the default port. Create some users and some groups in the identity provider if not present. Check the user profile parameter names that the identity provider uses during the assertion callback ( TIP : set readonlyrest_kbn.logLevel: debug` in kibana.yml, so you will see the user profile how it's received from the identity provider right in the logs). Match the name of the parameter used by the identity provider to carry the unique user ID (in the assertion message) to the usernameParameter kibana YAML setting. If you want to use OpenID for authorization, take care of matching also the groupsParameter to the parameter name found in the assertion message to the kibana YAML setting. ( TIP : the groupsParameter must be present in the userinfo token of your OIDC provider.) If kibana is accessed through a reverse proxy, kibanaExternalHost should be configured with the external hostname. if omitted, the default value is equals to server.host:server.port defined in kibana.yml. ( This parameter can be used also when kibana is bound to 0.0.0.0, for example, if using docker.) Load balancers Enable health check endpoint Normally a load balancer needs a health check URL to see if the instance is still running, you can whitelist this Kibana path so the load balancer avoids a redirection to /login . Edit kibana.yml readonlyrest_kbn.whitelistedPaths: [\".*/api/status$\"] Session management with multiple Kibana instances Each Kibana node stores user sessions in-memory. This will cause problems when using multiple Kibana instances behind a load balancer (especially without sticky sessions), as there would be no synchronization between nodes' sessions cache. To avoid this, session synchronization via an Elasticsearch index should be enabled. Follow these steps: Come up with a string of at least 32 characters length or more to be used as the shared cookie encryption key, called cookiePass . Open up conf/kibana.yml and add: readonlyrest_kbn.cookiePass: \"generatedStringIn1step\" (example: \"12345678901234567890123456789012\") readonlyrest_kbn.cookieName (custom cookie name - this property is optional, if not specified default cookie name would be rorCookie ) readonlyrest_kbn.store_sessions_in_index: true (enable session storage in index) readonlyrest_kbn.sessions_index_name: \"someCustomIndexName\" (index name - this property is optional, if not specified default index would be .readonlyrest_kbn_sessions ) readonlyrest_kbn.sessions_refresh_after: 1000 (time in milliseconds, describes how often sessions should be fetched from ES and refreshed for each node - optional, by default 2 seconds) readonlyrest_kbn.sessions_probe_interval_seconds: 15 (default 10s) how often should the browser poll Kibana to check if their session is still valid. Raise this value if you connect to Kibana through slow networks (i.e. VPN), or have very slow loading dashboards. Add the above config in all Kibana nodes behind the load balancer, and restart them. Login screen tweaking It is possible to customize the look of the login screen. Two column layout By default,the login form appears in a single column view. But once title and subtitle are configured, it will switch to two columns for making room to the new text. readonlyrest_kbn.login_title: \"Some Title\" readonlyrest_kbn.login_subtitle: \"Longer text <b>any HTML is supported<b/> including ifrmaes\" Add your company logo It's recommended to use a transparent PNG, negative logo. Ideally a white foreground, and transparent background. Open config/kibana.yml and append the following: readonlyrest_kbn.login_custom_logo: 'https://.../logo.png' Add custom CSS/JS You have the opportunity to inject HTML code right before the closing head tag ( </head> ). Open config/kibana.yml and append the following: readonlyrest_kbn.login_html_head_inject: '<style> * { color:red; }</style>' Kibana UI tweaking With ReadonlyREST Enterprise, it's possible to inject custom CSS and Javascript to achieve a customised user experience for your users/tenants. Inject custom CSS in Kibana Open config/kibana.yml and append the following: readonlyrest_kbn.kibana_custom_css_inject: '.global-nav, kbnGlobalNav { background-color: green }' Alternatively, it's possible to load the CSS from a file in the filesystem: readonlyrest_kbn.kibana_custom_css_inject_file: '/tmp/custom.css' Inject custom JS in Kibana readonlyrest_kbn.kibana_custom_js_inject: '$(\".global-nav__logo\").hide(); alert(\"hello!\")' Map groups to aliases You can provide a function, mapping group names to aliases of your choosing. To do so, add the following line to config/kibana.yml : readonlyrest_kbn.groupsMapping: '(group) => group.toLowerCase()' \u26a0\ufe0fIMPORTANT The mapping function has to return a string. Otherwise, an error will be printed in kibana logs and the original group name will be used as fallback. Also, if the mapping function is not specified, the original group name value will be used. Tenancy index templating When a tenants logs in for the first time, ReadonlyREST Enterprise will create the \".kibana\" index associated to the tenancy. For example, it will create and initialize the \".kibana_user1\" index, where \"user1\" will store all the visualizations, dashboards, settings and index-patterns. The issue is that \"user1\"'s user experience will be really raw as they will see a completely blank Kibana tenancy. Not even a default index pattern will be present. And this is particularly challenging if the tenant is supposed to be read-only (i.e. kibana_access: \"ro\") because they won't even have privileges to create their own index-pattern, let alone any dashboards. To fix this, ReadonlyREST Enterprise offers the possibility for administrators to create a template kibana index from which all the Kibana objects will be copied over to the newly initialised tenancy. How to use tenancy templating An administrator will need to create the template tenancy, populate it with the default Kibana objects (index-patterns, dashboards) and configure ReadonlyREST Enterprise to take the index template it in use. Let's see this step by step: Create the template tenancy Let's start to add to our access control list (found in $ES_PATH_CONF/config/readonlyrest.yml, or ReadonlyREST App in Kibana) a local user \"administrator\" that will belong to two tenancies: the default one (stored in .kibana index), and the template one (stored in .kibana_template index). readonlyrest: audit_collector: true access_control_rules: - name: \"::KIBANA-SRV::\" auth_key: kibana:kibana verbosity: error - name: \"Admin Tenancy\" groups: [\"Admins\"] verbosity: error kibana_access: admin kibana_index: \".kibana\" - name: \"Template Tenancy\" groups: [\"Template\"] verbosity: error kibana_access: admin kibana_index: \".kibana_template\" users: - username: administrator auth_key: administrator:dev groups: [\"Admins\", \"Template\"] # can hop between two tenancies with top-left drop-down menu NB: If you know what you are doing, you can add a tenancy with kibana_index: \".kibana_template\" adding a LDAP/SAML group to your administrative user. Configure the template tenancy Now login as administrator in Kibana, hop into the \"Template\" tenancy, and start configuring the default UX for your future tenants. Add all the index patterns, create or import all the dashboards you want. Configure the template tenancy index in ReadonlyREST Enterprise Open kibana.yml and add the following line: readonlyrest_kbn.kibanaIndexTemplate: \".kibana_template\" Now, ReadonlyREST Enterprise will look for the \".kibana_template\" index, and try to copy over all its documents every time a new kibana index is initialised to support a new tenancy. Try it out Restart Kibana with the new setting. Add a new tenancy to the ACL: readonlyrest: audit_collector: true access_control_rules: - name: \"::KIBANA-SRV::\" auth_key: kibana:kibana verbosity: error - name: \"Admin Tenancy\" groups: [\"Admins\"] verbosity: error kibana_access: admin kibana_index: \".kibana\" - name: \"Template Tenancy\" groups: [\"Template\"] verbosity: error kibana_access: admin kibana_index: \".kibana_template\" # Newly added tenant! - name: user1 auth_key: user1:passwd kibana_access: rw kibana_index: \".kibana_user1\" users: - username: administrator auth_key: administrator:dev groups: [\"Admins\", \"Template\"] # can hop between two tenancies with top-left drop-down menu ` Now try to login as user1, and ReadonlyREST Enterprise should initialise the index \".kibana_user1\" with all the index patterns and dashboards contained in the template tenancy.","title":"Kibana 7.8.x and older"},{"location":"details/kibana-7.8.x-and-older/#kibana-78x-and-older","text":"","title":"Kibana 7.8.x and older"},{"location":"details/kibana-7.8.x-and-older/#kibana-plugin-overview","text":"ReadonlyREST plugin for Kibana is not open source, and it's offered as part of the ReadonlyREST PRO and ReadonlyREST ENTERPRISE , and ReadonlyREST Free packages. See product descriptions and a comparison chart in the official ReadonlyREST website ReadonlyREST plugins for Kibana always require ReadonlyREST Free to be installed in the Elasticsearch nodes your Kibana instance(s) will connect to. It's not mandatory to install ReadonlyREST Free in all Elasticsearch nodes, but only in the ones in where you need the HTTP interface to be secured.","title":"Kibana Plugin overview"},{"location":"details/kibana-7.8.x-and-older/#after-purchasing","text":"You will receive a link to the plugin zip file in an email. Download your zip. You will be able to download it also in the future as long as your subscription is active.","title":"After purchasing"},{"location":"details/kibana-7.8.x-and-older/#version-strings","text":"All our plugins include in their file name a version string. For example the file readonlyrest-1.16.26_es6.4.0.zip has a version string 1.16.26_es6.4.0 .","title":"Version strings"},{"location":"details/kibana-7.8.x-and-older/#reading-version-strings","text":"Given the version string 1.16.26_es6.4.0 ReadonlyREST plugin code version 1.16.26 Works only with Elasticsearch/Kibana version 6.4.0 The \"es\" stands for \"Elastic stack\" which used to mean the family of products made by Elastic which get released at the same time under the same version number. This was chosen before Elastic renamed their X-Pack commercial offer to Elastic Stack. To be clear, there is no affiliation between ReadonlyREST and Elastic, or their commercial products.","title":"Reading version strings"},{"location":"details/kibana-7.8.x-and-older/#trial-builds-version-strings","text":"Trial builds are valid for 30 days after they were built, and they will stop working soon after the time is elapsed. Trial builds have a special version string which includes a build-time timestamp. I.e. readonlyrest_kbn_pro-1.16.26-20180911_es6.0.0.zip ReadonlyREST PRO plugin version 1.16.26 Build date 11th September 2018, expiring on the 11th of October 2018. Works only with Kibana version 6.0.0","title":"Trial builds version strings"},{"location":"details/kibana-7.8.x-and-older/#when-an-update-is-out","text":"You will receive another email notification that a new deliverable is available. If the update contains a security fix, it is very important that you take action and update the plugin immediately .","title":"When an update is out"},{"location":"details/kibana-7.8.x-and-older/#installation","text":"You can install this as a normal Kibana plugin using the bin/kibana-plugin utility.","title":"Installation"},{"location":"details/kibana-7.8.x-and-older/#install-via-url","text":"This installation method is more practical if your Kibana server is connected to the internet. According to what edition of ReadonlyREST you want to install, from your Kibana installation, launch one of the commands: Please note that this will always download the latest version of Kibana plugin available for the current supported Elasticsearch version. # ReadonlyREST Free edition $ bin/kibana-plugin install \"https://api.beshu.tech/download/kbn?edition=kbn_free&email=<your_email_address>\" # ReadonlyREST PRO (30 days trial) edition $ bin/kibana-plugin install \"https://api.beshu.tech/download/trial?edition=kbn_pro&email=<your_email_address>\" # ReadonlyREST Enterprise (30 days trial) edition $ bin/kibana-plugin install \"https://api.beshu.tech/download/trial?edition=kbn_enterprise&email=<your_email_address>\" If you want to download the latest version of plugin for a specific version of Elasticsearch, then use query parameter esVersion to specify your required Elasticsearch version. # ReadonlyREST Free edition for Elasticsearch 7.6.1 $ bin/kibana-plugin install \"https://api.beshu.tech/download/kbn?edition=kbn_free&esVersion=7.6.1&email=<your_email_address>\" # ReadonlyREST PRO (30 days trial) edition for Elasticsearch 7.6.1 $ bin/kibana-plugin install \"https://api.beshu.tech/download/trial?edition=kbn_pro&esVersion=7.6.1&email=<your_email_address>\" # ReadonlyREST Enterprise (30 days trial) edition for Elasticsearch 7.6.1 $ bin/kibana-plugin install \"https://api.beshu.tech/download/trial?edition=kbn_enterprise&esVersion=7.6.1&email=<your_email_address>\" If you want to download an older version of plugin for a specific version of Elasticsearch, then use query parameter pluginVersion along with esVersion. # ReadonlyREST Free edition - version 1.22.0 for Elasticsearch 7.6.1 $ bin/kibana-plugin install \"https://api.beshu.tech/download/kbn?edition=kbn_free&esVersion=7.6.1&pluginVersion=1.22.0&email=<your_email_address>\" # ReadonlyREST PRO (30 days trial) edition - version 1.22.0 for Elasticsearch 7.6.1 $ bin/kibana-plugin install \"https://api.beshu.tech/download/trial?edition=kbn_pro&esVersion=7.6.1&pluginVersion=1.22.0&email=<your_email_address>\" # ReadonlyREST Enterprise (30 days trial) edition - version 1.22.0 for Elasticsearch 7.6.1 $ bin/kibana-plugin install \"https://api.beshu.tech/download/trial?edition=kbn_enterprise&esVersion=7.6.1&pluginVersion=1.22.0&email=<your_email_address>\" If you are a PRO or Enterprise subscriber, the link will include an extra parameter \"token\" which can only be used in association with the provided email address. You can append required plugin version and Elasticsearch version query parameters to download specific version as described above. NB: This URL is personal, and should be handled as a secret. # ReadonlyREST PRO (Official) edition $ bin/kibana-plugin install \"https://api.beshu.tech/download/trial?edition=kbn_pro&email=<your_email_address>&token=<your_secret_token>\" # ReadonlyREST Enterprise (30 days trial) edition $ bin/kibana-plugin install \"https://api.beshu.tech/download/trial?edition=kbn_enterprise&email=<your_email_address>&token=<your_secret_token>\" You can obtain official links with personal secret tokens using our self service download form , once your email address has been recognized as active subscriber.","title":"Install via URL"},{"location":"details/kibana-7.8.x-and-older/#install-from-zip-file","text":"$ bin/kibana-plugin install file:///home/user/downloads/readonlyrest_kbn-X.Y.Z_esW.Q.U.zip Notice how we need to type in the format file:// + absolute path (yes, with three slashes).","title":"Install from zip file"},{"location":"details/kibana-7.8.x-and-older/#uninstall","text":"$ bin/kibana-plugin remove readonlyrest_kbn","title":"Uninstall"},{"location":"details/kibana-7.8.x-and-older/#upgrade","text":"Just uninstall the old version and install the new version. $ bin/kibana-plugin remove readonlyrest_kbn Install the new version of ReadonlyREST into Kibana. $ bin/kibana-plugin install file:///home/user/downloads/readonlyrest_kbn-*.zip # Only for older versions (until Kibana early 6.x) $ touch optimize/bundles/readonlyrest_kbn.style.css Restart Kibana.","title":"Upgrade"},{"location":"details/kibana-7.8.x-and-older/#using-ror-with-a-reverse-proxy","text":"ROR - just like Kibana itself - is meant to be used either with a proxy or without one, but not both simultaneously. If you decide to set the server.basePath property in kibana.yml be sure to access RoR via a proxy, as it will not work properly when accessed directly.","title":"Using ROR with a reverse proxy"},{"location":"details/kibana-7.8.x-and-older/#configuration","text":"ReadonlyREST for Kibana is completely remote-controlled from the Elasticsearch configuration. Login credentials, hidden Kibana apps, etc. are all going to be configured from the Elasticearch side via the usual \"rules\". This means the configuration will be kept all in one place and if you used ReadonlyREST before , it will be also very familiar. In this document, every time you will encounter references to \"readonlyrest.yml\" or \"elasticsearch.yml\", we will be referring to the configuration files in the Elasticsearch plugin (our Kibana plugins do not need a \"readonlyrest.yml\"). In general, by design, we tend to concentrate all configuration within the main plugin (the Elasticsearch one) as much as possible.","title":"Configuration"},{"location":"details/kibana-7.8.x-and-older/#clusterwide-settings-vs-readonlyrestyml","text":"Our Kibana plugins introduce a \"ReadonlyREST\" Kibana app. From here, you can edit the security settings of the whole Elasticsearch cluster, and they will take effect within 10 seconds in all Elasticsearch cluster nodes without the need to restart them. When you change the security settings from the Kibana app, they will be saved in a special index called \".readonlyrest\", so all the Elasticsearch nodes will pick them up. You can customize a name of the index by setting readonlyrest.settings_index: .my_custom_readonlyrest in elasticsearch.yml file (remember to set the same value for all your ES nodes). When an Elasticsearch node restarts, the order of settings evaluation is the following: 1. Attempt to find valid settings in readonlyrest.yml 2. If none is found, look inside elasticsearch.yml 3. Once successfully bootstrapped using file-based settings, attempt to read \".readonlyrest\" index 4. If the index exists and contains valid settings, override file based settings with the ones from the index. 5. Pressing \"save\" in the cluster wide settings app, will not overwrite the readonlyrest.yml file. Best practices: Build and update your production security settings from the Kibana app (will be saved in index) Protect the \".readonlyrest\" Kibana index with an ACL rule","title":"Clusterwide Settings vs readonlyrest.yml"},{"location":"details/kibana-7.8.x-and-older/#loading-settings-order-of-precedence","text":"As you read, there are two possible places where the settings can be read from: readonlyrest.yml a file the user needs to create in the same directory where elasticsearch.yml is found. .readonlyrest index. Our Kibana plugins' GUI (PRO/Enterprise) is programmed to write this index. When the ES plugin boots up, it follows some logic to evaluate where to read the YAML settings from. The following diagram shows how that works.","title":"Loading settings: order of precedence"},{"location":"details/kibana-7.8.x-and-older/#malformed-in-index-settings","text":"If for some reason the in-index settings get corrupted and ROR can't parse them, then neither settings from file or in-index settings can be loaded, so ES can't start. In this case ES would print message like: Loading ReadonlyREST settings from index failed: Settings config content is malformed. Details: while scanning a quoted scalar in 'reader', line 9, column 17: auth_key: \"admin:container ^ To recover from this state, set readonlyrest.force_load_from_file: true in elasticsearch.yaml on one node es1 . Example recovery settings: elasticsearch.yaml [...] readonlyrest: force_load_from_file: true readonlyrest.yaml readonlyrest: access_control_rules: - name: \"::ADMIN recover::\" auth_key: admin:dev indices: [\"*\"] Then remove in-index settings index manually. curl -X DELETE \"admin:dev@es1:9200/.readonlyrest?pretty\" Now you can restore your settings to readonlyrest.yml , remove readonlyrest.force_load_from_file: true from elasticsearch.yaml and restart node.","title":"Malformed in-index settings"},{"location":"details/kibana-7.8.x-and-older/#example-multiuser-elk","text":"Make sure X-Pack is uninstalled or disabled from elasticsearch.yml (on the Elasticsearch side) and kibana.yml (on the Kibana side): This is how you disable X-pack modules: # For X-Pack users: you may only leave monitoring on. # Don't add this if X-Pack is not installed at all, or Kibana won't start. xpack.monitoring.enabled: true xpack.security.enabled: false xpack.watcher.enabled: false xpack.telemetry.enabled: false This is a typical example of configuration snippet to add at the end of your readonlyrest.yml (the settings file of the Elasticsearch plugin), to support ReadonlyREST PRO. readonlyrest: access_control_rules: - name: \"::LOGSTASH::\" auth_key: logstash:logstash actions: [\"indices:data/read/*\",\"indices:data/write/*\",\"indices:admin/template/*\",\"indices:admin/create\"] indices: [\"logstash-*\"] - name: \"::KIBANA-SRV::\" auth_key: kibana:kibana - name: \"::RO::\" auth_key: ro:dev kibana_access: ro indices: [ \".kibana\", \"logstash-*\"] kibana_hide_apps: [\"readonlyrest_kbn\", \"timelion\", \"kibana:dev_tools\", \"kibana:stack_management\"] - name: \"::RW::\" auth_key: rw:dev kibana_access: rw indices: [\".kibana\", \"logstash-*\"] kibana_hide_apps: [\"readonlyrest_kbn\", \"timelion\", \"kibana:dev_tools\", \"kibana:stack_management\"] - name: \"::ADMIN::\" auth_key: admin:dev # KIBANA ADMIN ACCESS NEEDED TO EDIT SECURITY SETTINGS IN ROR KIBANA APP! kibana_access: admin - name: \"::WEBSITE SEARCH BOX::\" indices: [\"public\"] actions: [\"indices:data/read/*\"]","title":"Example: multiuser ELK"},{"location":"details/kibana-7.8.x-and-older/#very-important","text":"Whatever your configuration ends up being, remember: The admin user has kibana_access: admin Remember to use kibana_hide_apps: [\"readonlyrest_kbn\"] to hide the ReadonlyREST icon from who is not meant to use it (makes for a better UX).","title":"Very important"},{"location":"details/kibana-7.8.x-and-older/#rules-ordering-matters","text":"Blocks related to the authentication of the users should be at the top of the ACL One of the most common mistakes is forgetting that the ACL blocks are evaluated in order from the first to the last. So, some request with credentials can be let through from one of the first blocks and come back to Kibana with no user identity metadata associated. Take this example of troublesome ACL: # PROBLEMATIC SETTINGS (EXAMPLE) \u26a0\ufe0f access_control_rules: - name: \"::FIRST BLOCK::\" hosts: [\"127.0.0.1\"] actions: [...] - name: \"::ADMIN::\" auth_key: admin:dev kibana_access: admin The user will be able to login because the login request will be allowed by the first ACL block. But the ACL will not have resolved any metadata about the user identity (credentials checking was ignored)! This means the response to the Kibana login request will contain no user identity metadata (username, hidden apps, etc) and ReadonlyREST for Kibana won't be able to function correctly. The solution to this is to reorder the ACL blocks, so the ones that authenticate Kibana users are on the top. # SOLUTION: KIBANA USER AUTH RELATED BLOCKS GO FIRST! \u2705\ud83d\udc4d access_control_rules: - name: \"::ADMIN::\" auth_key: admin:dev kibana_access: admin - name: \"::FIRST BLOCK::\" hosts: [\"127.0.0.1\"] actions: [...]","title":"Rules ordering matters"},{"location":"details/kibana-7.8.x-and-older/#session-cookie-expiration","text":"When a user logs in, ReadonlyREST will write an encrypted cookie in the browser. This cookie has an time to live that can be tweaked with the following configuration key in kibana.yml . readonlyrest_kbn.session_timeout_minutes: 600 # defaults to 4320 (3 days)","title":"Session cookie expiration"},{"location":"details/kibana-7.8.x-and-older/#clearing-session-history","text":"By default, all the session data like search history, dev tool commands history, etc, will be wiped out from the browser whenever a new user is logged in, or a user changes tenancy. To override this behaviour, use this setting: readonlyrest_kbn.clearSessionOnEvents: [\"never\"] Possible values: \"login\", \"tenancyHop\", \"never\" .","title":"Clearing Session History"},{"location":"details/kibana-7.8.x-and-older/#kibana-app-strings","text":"Examples of valid arguments for the kibana_hide_apps: [...] rule (readonlyrest.yml) hide-app key App name App url kibana:discover Discover http://kibana-url:5601/app/kibana#/discover kibana:visualize Visualize http://kibana-url:5601/app/kibana#/visualize kibana:dashboard Dashboard http://kibana-url:5601/app/kibana#/dashboards timelion Timelion http://kibana-url:5601/app/timelion canvas Canvas http://kibana-url:5601/app/canvas maps Maps http://kibana-url:5601/app/maps code Code (Beta) http://kibana-url:5601/app/code ~~readonlyrest_kbn~~ (obsolete) ~~ReadonlyREST~~ ~~\\~\\~[~~ http://kibana-url:5601/app/readonlyrest_kbn\\~\\~](http://kibana-url:5601/app/readonlyrest_kbn)\\~\\~\\~\\~ ml Machine Learning http://kibana-url:5601/app/ml infra:home Infrastructure http://kibana-url:5601/app/infra#/infrastructure/inventory?_g=( ) infra:logs Logs http://kibana-url:5601/app/infra#/logs?_g=( ) apm APM http://kibana-url:5601/app/apm uptime Uptime http://kibana-url:5601/app/uptime#/ siem SIEM http://kibana-url:5601/app/siem graph Graph http://kibana-url:5601/app/graph kibana:dev_tools Dev Tools http://kibana-url:5601/app/kibana#/dev_tools monitoring Stack Monitoring http://kibana-url:5601/app/monitoring kibana:stack_management Stack Management http://kibana-url:5601/app/kibana#/management","title":"Kibana App strings"},{"location":"details/kibana-7.8.x-and-older/#kibana-configuration","text":"Activate authentication for the Kibana server: let the Kibana daemon connect to Elasticsearch using a pair of credentials we just defined in readonlyrest.yml (see above, the ::KIBANA-SRV:: block). Open up conf/kibana.yml and add the following: # This is kibana.yml, but copy the exact same in elasticsearch.yml if you have to use some X-pack features. xpack.graph.enabled: false xpack.ml.enabled: false xpack.monitoring.enabled: true xpack.security.enabled: false # this is fundamental! xpack.watcher.enabled: false # Kibana server use ::KIBANA-SRV:: credentials elasticsearch.username: \"kibana\" elasticsearch.password: \"kibana\" And of course also make sure elasticsearch.url points to the designated Elasticsearch instance (check also the http or https)","title":"Kibana configuration"},{"location":"details/kibana-7.8.x-and-older/#proxy-auth","text":"ROR for Elasticsearch can delegate authentication to a reverse proxy which will enforce some kind of authentication, and pass the successfully authenticated user's name inside a X-Forwarded-User header. Today, it's possible to skip the regular ROR login form and use the \"delegated authentication\" technique in ROR for Kibana as well. Configure ROR for ES to expect delegated authentication (see proxy_auth rule ) in ROR for ES documentation. Open up conf/kibana.yml and add readonlyrest_kbn.proxy_auth_passthrough: true Now ROR for Kibana will skip the login form entirely , and will only require that all incoming requests must carry a X-Forwarded-User header containing the user's name. Based on this identity, ROR for Kibana will build an encrypted cookie and handle your session normally.","title":"Proxy Auth"},{"location":"details/kibana-7.8.x-and-older/#custom-logout-link","text":"Normally, when a user presses the logout button in ROR for Kibana, it deletes the encrypted cookie that represents the users identity and the login form is shown. However, when the authentication is delegated to a proxy, the logout button needs to become a link to some URL capable to unregister the session a user initiated within the proxy. For this, ROR for Kibana offers a way to customize the logout button's URL: Find a link that will delete the reverse proxy's user session Open up conf/kibana.yml and add readonlyrest_kbn.custom_logout_link: https://..../logout Now users that gained a session through delegated auth, can also click on the logout button in ROR for kibana and actually exit their session.","title":"Custom Logout link"},{"location":"details/kibana-7.8.x-and-older/#custom-login-link","text":"When you delegate authentication to an external service, you can tell ReadonlyREST to skip the classic login form entirely and redirect users to your proxy or identity provider's login screen. To enable this: Find your authentication proxy or identity provider login URL for the ROR app Open up conf/kibana.yml and add readonlyrest_kbn.custom_login_link: \"https://../login\" The advantage of this approach is a streamlined user experience for users that login with an external IdP. The disadvantage is that you give up the possibility to login as a local user in ROR, as the login form will be always skipped.","title":"Custom Login link"},{"location":"details/kibana-7.8.x-and-older/#caveat","text":"Enabling proxy auth passthrough will relax the requirement to provide a password. Therefore, don't enable this option if you don't make sure Kibana can only be accessed through the reverse proxy* .","title":"Caveat"},{"location":"details/kibana-7.8.x-and-older/#jwt-token-forwarding-as-url-query-parameter","text":"Alternatively to typing in credentials in the standard login form, it is possible to create an authenticated Kibana session by passing a JWT token as a query parameter in a URL.","title":"JWT Token Forwarding as URL Query Parameter"},{"location":"details/kibana-7.8.x-and-older/#configuration_1","text":"To enable this feature in ReadonlyREST, you need to: Have JWT authentication configured in ReadonlyREST (modifying readonlyrest.yml or the cluster wide settings UI in the Kibana plugin). See how . Specify the query parameter name in kibana.yml by adding the line readonlyrest_kbn.jwt_query_param: \"jwt\" as a string, in our case \"jwt\".","title":"Configuration"},{"location":"details/kibana-7.8.x-and-older/#in-action","text":"Once Kibana is restarted, you will be able to navigate to a link like this: http://kibana:5601/login?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzdWIiOiIxMjM0NTY3ODkwIiwibmFtZSI6IkpvaG4gRG9lIiwiYWRtaW4iOnRydWV9.TJVA95OrM7E2cBab30RMHrHDcEfxjoYZgeFONFh7HgQ The following will happen: The Kibana plugin will forward the JWT token found in the query parameter into the Authorization header in a request to Elasticsearch. Elasticsearch will cryptographically authenticate and resolve the user's identity from the JWT claims. Kibana will write an encrypted cookie in your browser and use that from now on for the length of the authenticated session. From here onwards, the session management will be identical to the normal login form flow. When the user presses logout, Kibana will delete the cookie and redirect you to the login form, or whatever link you configured as readonlyrest_kbn.custom_logout_link . Deep linking with JWT Because the identity is embedded in the link, and ReadonlyREST is able to authenticate the call on the fly, the JWT authentication can be used in conjunction with nextUrl query parameter for sharing deep links inside Kibana apps, or embedding visualizations and dashboards inside I-Frames. Anatomy of a JWT deep link http://kibana:5601/login?jwt=<the-token>&nextUrl=urlEncode(<kibana-path>) In Javascript one can compose a JWT deep link as follows: var absoluteKibanaPath = '/app/kibana#/visualize/edit/28dcde30-2258-11e8-82a3-af58d04b3c02?_g=()'; var url = 'http://kibana:5601/login?jwt=' + jwtToken + '&nextUrl=' + encodeURI(absoluteKibanaPath); console.log(\"Final JWT deep link: \" + url) The result may look something like this: http://localhost:5601/login?nextUrl=%2Fapp%2Fkibana%23%2Fvisualize%2Fedit%2F28dcde30-2258-11e8-82a3-af58d04b3c02%3F_g%3D%28%29&jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzdWIiOiIxMjM0NTY3ODkwIiwibmFtZSI6IkpvaG4gRG9lIiwiYWRtaW4iOnRydWV9.TJVA95OrM7E2cBab30RMHrHDcEfxjoYZgeFONFh7HgQ","title":"In Action"},{"location":"details/kibana-7.8.x-and-older/#audit-log","text":"The audit log feature is widely described in \ud83d\udcd6docs for Elasticsearch plugin . Kibana plugin has predefined dashboard representing collected audit data.","title":"Audit log"},{"location":"details/kibana-7.8.x-and-older/#loading-visualization","text":"In the Audit tab of the ReadonlyREST Kibana app, there is a button that automatically creates a dashboard with some audit log specific visualizations. Click the Load button to load the dashboard and visualizations. An Override checkbox allows to reload the default dashboard and visualizations. It will override any previously loaded audit log dashboard. In detail, this feature creates three Kibana \"saved objects\": an index pattern for readonlyrest_audit-* a dashboard called ReadonlyREST Audit Log some visualizations","title":"Loading visualization"},{"location":"details/kibana-7.8.x-and-older/#dashboard","text":"The audit log dashboard, by default, has only a few basic visualizations. They cover security, access logs, and performance metrics.","title":"Dashboard"},{"location":"details/kibana-7.8.x-and-older/#saml","text":"ReadonlyREST Enterprise supports service provider initiated via SAML. This connector supports both SSO (single sign on) and SLO (single log out). Here is how to configure it.","title":"SAML"},{"location":"details/kibana-7.8.x-and-older/#configure-ror_kbn_auth-bridge","text":"In order for the user identity information to flow securely from Kibana to Elasticsearch, we need to set up the two plugin with a shared secret, that is: an arbitrarily long string.","title":"Configure ror_kbn_auth bridge"},{"location":"details/kibana-7.8.x-and-older/#elasticsearch-side","text":"Edit readonlyrest.yml readonlyrest: access_control_rules: - name: \"::KIBANA-SRV::\" auth_key: kibana:kibana ... all usual blocks of rules... - name: \"ReadonlyREST Enterprise instance #1\" ror_kbn_auth: name: \"kbn1\" ror_kbn: - name: kbn1 signature_key: \"my_shared_secret_kibana1_(min 256 chars)\" # <- use environmental variables for better security! \u26a0\ufe0fIMPORTANT the Basic HTTP auth credentials for the Kibana server are still needed for now, due to how Kibana works.","title":"Elasticsearch side"},{"location":"details/kibana-7.8.x-and-older/#kibana-side","text":"Edit kibana.yml and append: readonlyrest_kbn.auth: signature_key: \"my_shared_secret_kibana1(min 256 chars)\" saml_serv1: enabled: true type: saml issuer: ror buttonName: \"Partner's SSO Login\" entryPoint: 'https://my-saml-idp/saml2/http-post/sso' # <-- identity Provider's URL, to request to sign on kibanaExternalHost: 'my.public.hostname.com' # <-- public URL used by the Identity Provider to call back Kibana with the \"assertion\" message protocol: http # <-- is the Kibana server listening for \"http\" \"https\" connections? Default: http usernameParameter: 'nameID' groupsParameter: 'memberOf' logoutUrl: 'https://my-saml-idp/saml2/http-post/slo' # OPTIONAL, advanced parameters # decryptionCert: /etc/ror/integration/certs/pub.crt # cert: /etc/ror/integration/certs/dag.crt # decryptionPvk: /etc/ror/integration/certs/decrypt_pvk.crt # issuer: saml_sso_idp issuer : issuer string to supply to identity provider during sign on request. Defaults to 'ror' disableRequestedAuthnContext : if truthy, do not request a specific authentication context. This is known to help when authenticating against Active Directory (AD FS) servers. decryptionPvk : Service Provider Private Key. Private key that will be used to attempt to decrypt any encrypted assertions that are received. cert: The downloadable certificate in IDP Metadata (file, absolute path) For advanced SAML options, see passport-saml documentation .","title":"Kibana side"},{"location":"details/kibana-7.8.x-and-older/#identity-provider-side","text":"Enter the settings of your identity provider, create a new app. Configure it using the information found by connecting to http://my.public.hostname.com/ror_kbn_sso_saml_serv1/metadata.xml Example response: <?xml version=\"1.0\"?> <EntityDescriptor xmlns=\"urn:oasis:names:tc:SAML:2.0:metadata\" xmlns:ds=\"http://www.w3.org/2000/09/xmldsig#\" entityID=\"onelogin_saml\" ID=\"onelogin_saml\"> <SPSSODescriptor protocolSupportEnumeration=\"urn:oasis:names:tc:SAML:2.0:protocol\"> <SingleLogoutService Binding=\"urn:oasis:names:tc:SAML:2.0:bindings:HTTP-POST\" Location=\"http://my.public.hostname.com/ror_kbn_sso/notifylogout\"/> <NameIDFormat>urn:oasis:names:tc:SAML:1.1:nameid-format:emailAddress</NameIDFormat> <AssertionConsumerService index=\"1\" isDefault=\"true\" Binding=\"urn:oasis:names:tc:SAML:2.0:bindings:HTTP-POST\" Location=\"http://my.public.hostname.com/ror_kbn_sso/assert\"/> </SPSSODescriptor> </EntityDescriptor> Create some users and some groups in the identity provider app Check the user profile parameter names that the identity provider uses during the assertion callback ( TIP : set kibana in debug mode so ReadonlyREST will print the user profile). Match the name of the parameter used by the identity provider to carry the unique user ID (in the assertion message) to the usernameParameter kibana YAML setting. If you want to use SAML for authorization, take care of matching also the groupsParameter to the parameter name found in the assertion message to the kibana YAML setting.","title":"Identity provider side"},{"location":"details/kibana-7.8.x-and-older/#openid-connect-oidc","text":"ReadonlyREST Enterprise support OpenID Connect for authentication and authorization. soon we will create a specific guide only for OpenID, like the ones we have for SAML Here is how to configure it.","title":"OpenID Connect (OIDC)"},{"location":"details/kibana-7.8.x-and-older/#configure-ror_kbn_auth-bridge_1","text":"This part is identical as seen in SAML connectors. In order for the user identity information to flow securely from Kibana to Elasticsearch, we need to set up the two plugin with a shared secret, that is: an arbitrarily long string.","title":"Configure ror_kbn_auth bridge"},{"location":"details/kibana-7.8.x-and-older/#elasticsearch-side_1","text":"Edit readonlyrest.yml readonlyrest: access_control_rules: - name: \"::KIBANA-SRV::\" auth_key: kibana:kibana ... all usual blocks of rules... - name: \"ReadonlyREST Enterprise instance #1\" ror_kbn_auth: name: \"kbn1\" ror_kbn: - name: kbn1 signature_key: \"my_shared_secret_kibana1_(min 256 chars)\" # <- use environmental variables for better security! \u26a0\ufe0fIMPORTANT the Basic HTTP auth credentials for the Kibana server are still needed for now, due to how Kibana works. If you have configured OIDC with the groupsParameter ( See below ), you can also restrict ACL to specific groups: readonlyrest: access_control_rules: - name: \"::KIBANA-SRV::\" auth_key: kibana:kibana ... all usual blocks of rules... - name: \"ReadonlyREST Enterprise instance #1 for group 1\" ror_kbn_auth: name: \"kbn1\" groups: [\"group1\"] - name: \"ReadonlyREST Enterprise instance #1 for group 2\" ror_kbn_auth: name: \"kbn1\" groups: [\"group2\"] ror_kbn: - name: kbn1 signature_key: \"my_shared_secret_kibana1_(min 256 chars)\" # <- use environmental variables for better security! You may also use any custom claim from the OIDC userinfo token in ACL rules by using {{jwt:assertion.<path_to_your_claim>}} syntax. See the dedicated section for more information. ( TIP : Do not forget the assertion prefix in front of you jsonpath. )","title":"Elasticsearch side"},{"location":"details/kibana-7.8.x-and-older/#kibana-side_1","text":"We will assume the OpenID identity provider responds to port 8080 of localhost. In our example, we used Keycloak, an open source implementation of OpenID Connect identity provide. Edit kibana.yml and append: readonlyrest_kbn.auth: signature_key: \"my_shared_secret_kibana1(min 256 chars)\" oidc_kc: buttonName: \"KeyCloak OpenID\" type: \"oidc\" issuer: 'http://localhost:8080/auth/realms/ror' authorizationURL: 'http://localhost:8080/auth/realms/ror/protocol/openid-connect/auth' tokenURL: 'http://localhost:8080/auth/realms/ror/protocol/openid-connect/token' userInfoURL: 'http://localhost:8080/auth/realms/ror/protocol/openid-connect/userinfo' clientID: 'ror_oidc' clientSecret: '9f1d39c8-a211-460a-84b6-0a4a1499c455' scope: 'openid profile roles role_list email' usernameParameter: 'preferred_username' groupsParameter: 'groups' kibanaExternalHost: 'localhost:8080' logoutUrl: 'http://localhost:8080/auth/realms/ror/protocol/openid-connect/logout'","title":"Kibana side"},{"location":"details/kibana-7.8.x-and-older/#identity-provider-side_1","text":"Enter the settings interface of your identity provider, and create a new OpenID app . The redirect URL should be configured as http://localhost:5601/* assuming kibana is listening on localhost and on the default port. Create some users and some groups in the identity provider if not present. Check the user profile parameter names that the identity provider uses during the assertion callback ( TIP : set readonlyrest_kbn.logLevel: debug` in kibana.yml, so you will see the user profile how it's received from the identity provider right in the logs). Match the name of the parameter used by the identity provider to carry the unique user ID (in the assertion message) to the usernameParameter kibana YAML setting. If you want to use OpenID for authorization, take care of matching also the groupsParameter to the parameter name found in the assertion message to the kibana YAML setting. ( TIP : the groupsParameter must be present in the userinfo token of your OIDC provider.) If kibana is accessed through a reverse proxy, kibanaExternalHost should be configured with the external hostname. if omitted, the default value is equals to server.host:server.port defined in kibana.yml. ( This parameter can be used also when kibana is bound to 0.0.0.0, for example, if using docker.)","title":"Identity provider side"},{"location":"details/kibana-7.8.x-and-older/#load-balancers","text":"","title":"Load balancers"},{"location":"details/kibana-7.8.x-and-older/#enable-health-check-endpoint","text":"Normally a load balancer needs a health check URL to see if the instance is still running, you can whitelist this Kibana path so the load balancer avoids a redirection to /login . Edit kibana.yml readonlyrest_kbn.whitelistedPaths: [\".*/api/status$\"]","title":"Enable health check endpoint"},{"location":"details/kibana-7.8.x-and-older/#session-management-with-multiple-kibana-instances","text":"Each Kibana node stores user sessions in-memory. This will cause problems when using multiple Kibana instances behind a load balancer (especially without sticky sessions), as there would be no synchronization between nodes' sessions cache. To avoid this, session synchronization via an Elasticsearch index should be enabled. Follow these steps: Come up with a string of at least 32 characters length or more to be used as the shared cookie encryption key, called cookiePass . Open up conf/kibana.yml and add: readonlyrest_kbn.cookiePass: \"generatedStringIn1step\" (example: \"12345678901234567890123456789012\") readonlyrest_kbn.cookieName (custom cookie name - this property is optional, if not specified default cookie name would be rorCookie ) readonlyrest_kbn.store_sessions_in_index: true (enable session storage in index) readonlyrest_kbn.sessions_index_name: \"someCustomIndexName\" (index name - this property is optional, if not specified default index would be .readonlyrest_kbn_sessions ) readonlyrest_kbn.sessions_refresh_after: 1000 (time in milliseconds, describes how often sessions should be fetched from ES and refreshed for each node - optional, by default 2 seconds) readonlyrest_kbn.sessions_probe_interval_seconds: 15 (default 10s) how often should the browser poll Kibana to check if their session is still valid. Raise this value if you connect to Kibana through slow networks (i.e. VPN), or have very slow loading dashboards. Add the above config in all Kibana nodes behind the load balancer, and restart them.","title":"Session management with multiple Kibana instances"},{"location":"details/kibana-7.8.x-and-older/#login-screen-tweaking","text":"It is possible to customize the look of the login screen.","title":"Login screen tweaking"},{"location":"details/kibana-7.8.x-and-older/#two-column-layout","text":"By default,the login form appears in a single column view. But once title and subtitle are configured, it will switch to two columns for making room to the new text. readonlyrest_kbn.login_title: \"Some Title\" readonlyrest_kbn.login_subtitle: \"Longer text <b>any HTML is supported<b/> including ifrmaes\"","title":"Two column layout"},{"location":"details/kibana-7.8.x-and-older/#add-your-company-logo","text":"It's recommended to use a transparent PNG, negative logo. Ideally a white foreground, and transparent background. Open config/kibana.yml and append the following: readonlyrest_kbn.login_custom_logo: 'https://.../logo.png'","title":"Add your company logo"},{"location":"details/kibana-7.8.x-and-older/#add-custom-cssjs","text":"You have the opportunity to inject HTML code right before the closing head tag ( </head> ). Open config/kibana.yml and append the following: readonlyrest_kbn.login_html_head_inject: '<style> * { color:red; }</style>'","title":"Add custom CSS/JS"},{"location":"details/kibana-7.8.x-and-older/#kibana-ui-tweaking","text":"With ReadonlyREST Enterprise, it's possible to inject custom CSS and Javascript to achieve a customised user experience for your users/tenants.","title":"Kibana UI tweaking"},{"location":"details/kibana-7.8.x-and-older/#inject-custom-css-in-kibana","text":"Open config/kibana.yml and append the following: readonlyrest_kbn.kibana_custom_css_inject: '.global-nav, kbnGlobalNav { background-color: green }' Alternatively, it's possible to load the CSS from a file in the filesystem: readonlyrest_kbn.kibana_custom_css_inject_file: '/tmp/custom.css'","title":"Inject custom CSS in Kibana"},{"location":"details/kibana-7.8.x-and-older/#inject-custom-js-in-kibana","text":"readonlyrest_kbn.kibana_custom_js_inject: '$(\".global-nav__logo\").hide(); alert(\"hello!\")'","title":"Inject custom JS in Kibana"},{"location":"details/kibana-7.8.x-and-older/#map-groups-to-aliases","text":"You can provide a function, mapping group names to aliases of your choosing. To do so, add the following line to config/kibana.yml : readonlyrest_kbn.groupsMapping: '(group) => group.toLowerCase()' \u26a0\ufe0fIMPORTANT The mapping function has to return a string. Otherwise, an error will be printed in kibana logs and the original group name will be used as fallback. Also, if the mapping function is not specified, the original group name value will be used.","title":"Map groups to aliases"},{"location":"details/kibana-7.8.x-and-older/#tenancy-index-templating","text":"When a tenants logs in for the first time, ReadonlyREST Enterprise will create the \".kibana\" index associated to the tenancy. For example, it will create and initialize the \".kibana_user1\" index, where \"user1\" will store all the visualizations, dashboards, settings and index-patterns. The issue is that \"user1\"'s user experience will be really raw as they will see a completely blank Kibana tenancy. Not even a default index pattern will be present. And this is particularly challenging if the tenant is supposed to be read-only (i.e. kibana_access: \"ro\") because they won't even have privileges to create their own index-pattern, let alone any dashboards. To fix this, ReadonlyREST Enterprise offers the possibility for administrators to create a template kibana index from which all the Kibana objects will be copied over to the newly initialised tenancy.","title":"Tenancy index templating"},{"location":"details/kibana-7.8.x-and-older/#how-to-use-tenancy-templating","text":"An administrator will need to create the template tenancy, populate it with the default Kibana objects (index-patterns, dashboards) and configure ReadonlyREST Enterprise to take the index template it in use. Let's see this step by step:","title":"How to use tenancy templating"},{"location":"details/kibana-7.8.x-and-older/#create-the-template-tenancy","text":"Let's start to add to our access control list (found in $ES_PATH_CONF/config/readonlyrest.yml, or ReadonlyREST App in Kibana) a local user \"administrator\" that will belong to two tenancies: the default one (stored in .kibana index), and the template one (stored in .kibana_template index). readonlyrest: audit_collector: true access_control_rules: - name: \"::KIBANA-SRV::\" auth_key: kibana:kibana verbosity: error - name: \"Admin Tenancy\" groups: [\"Admins\"] verbosity: error kibana_access: admin kibana_index: \".kibana\" - name: \"Template Tenancy\" groups: [\"Template\"] verbosity: error kibana_access: admin kibana_index: \".kibana_template\" users: - username: administrator auth_key: administrator:dev groups: [\"Admins\", \"Template\"] # can hop between two tenancies with top-left drop-down menu NB: If you know what you are doing, you can add a tenancy with kibana_index: \".kibana_template\" adding a LDAP/SAML group to your administrative user.","title":"Create the template tenancy"},{"location":"details/kibana-7.8.x-and-older/#configure-the-template-tenancy","text":"Now login as administrator in Kibana, hop into the \"Template\" tenancy, and start configuring the default UX for your future tenants. Add all the index patterns, create or import all the dashboards you want.","title":"Configure the template tenancy"},{"location":"details/kibana-7.8.x-and-older/#configure-the-template-tenancy-index-in-readonlyrest-enterprise","text":"Open kibana.yml and add the following line: readonlyrest_kbn.kibanaIndexTemplate: \".kibana_template\" Now, ReadonlyREST Enterprise will look for the \".kibana_template\" index, and try to copy over all its documents every time a new kibana index is initialised to support a new tenancy.","title":"Configure the template tenancy index in ReadonlyREST Enterprise"},{"location":"details/kibana-7.8.x-and-older/#try-it-out","text":"Restart Kibana with the new setting. Add a new tenancy to the ACL: readonlyrest: audit_collector: true access_control_rules: - name: \"::KIBANA-SRV::\" auth_key: kibana:kibana verbosity: error - name: \"Admin Tenancy\" groups: [\"Admins\"] verbosity: error kibana_access: admin kibana_index: \".kibana\" - name: \"Template Tenancy\" groups: [\"Template\"] verbosity: error kibana_access: admin kibana_index: \".kibana_template\" # Newly added tenant! - name: user1 auth_key: user1:passwd kibana_access: rw kibana_index: \".kibana_user1\" users: - username: administrator auth_key: administrator:dev groups: [\"Admins\", \"Template\"] # can hop between two tenancies with top-left drop-down menu ` Now try to login as user1, and ReadonlyREST Enterprise should initialise the index \".kibana_user1\" with all the index patterns and dashboards contained in the template tenancy.","title":"Try it out"},{"location":"examples/","text":"Examples","title":"Examples"},{"location":"examples/#examples","text":"","title":"Examples"},{"location":"examples/multitenancy_guide/","text":"Multi-tenancy Elastic Stack This document will guide you through setting up your Elasticsearch and Kibana stack with ReadonlyREST such that: There will be two tenancies: one for Sales and one for Ops department. In each tenancy, 3 users will be able to login into Kibana using their own set of credentials Each tenancy will contain its own, independant Kibana dashboards, visualizations and index patterns. Each user within a tenancy may be restricted to visualizing distinct subsets of the whole data contained in Elasticsearch (i.e. only certain indices). Users and capabilities For this tutorials, we want to have three users per tenancy, each of them has a distinct access level to a shared Kibana tenancy (set of dashboards and settings). Sales Department \"sales_admin\" \"sales_rw_usr\" \"sales_ro_usr\" Can create,edit,delete Sales' dashboards \u2705 \u2705 Can change Kibana settings for Sales \u2705 \u2705 Only sees \"sales_logstash*\" data from 2018 \u2705 Can see \"add\",\"delete\",\"edit\" buttons \u2705 \u2705 \"dev-tools\" Kibana App is hidden \u2705 \u2705 \"readonlyrest\" Kibana App is hidden \u2705 Ops Department \"ops_admin\" \"ops_rw_usr\" \"ops_ro_usr\" Can create,edit,delete Ops dashboards \u2705 \u2705 Can change Kibana settings for Ops \u2705 \u2705 Only sees ops_logstash data from 2018 \u2705 Can see \"add\",\"delete\",\"edit\" buttons \u2705 \u2705 \"dev-tools\" Kibana App is hidden \u2705 \u2705 \"readonlyrest\" Kibana App is hidden \u2705 NB: ReadonlyREST for Elastisearch and ReadonlyREST Enterprise for Kibana have an great amount of features like groups, connector for external systems like LDAP, etc. Don't forget to visit the full documentation and the forum to know more about it. NB: The capabilities gained by admin users when they access the \"readonlyrest\" Kibana App are global , that is, they can add/remove tenancies, users, groups, etc. Before you start For the scope of this guide, we will assume: You will have a functioning installation of Elasticsearch and Kibana You have installed the ROR plugin for Elasticsearch You have installed the ROR Enterprise plugin for Kibana If you don't have the ROR Enterprise for Kibana plugin, get yourself a two weeks free trial build! IMPORTANT: disable Xpack Security module Because ReadonlyREST is not compatible with XPack Security module please make sure you disable xpack.security module from both Kibana and Elasticsearch by adding the following line to both elasticsearch.yml and kibana.yml : xpack.security.enabled: false Setup: the Elasticsearch side Right beside your elasticsearch.yml , create a file called readonlyrest.yml and write the following settings into it. readonlyrest: # IMPORTANT FOR LOGIN/LOGOUT TO WORK WITH ROR PLUGIN FOR KIBANA prompt_for_basic_auth: false access_control_rules: ######################################################### # These credentials shall be used by the logstash daemon. ######################################################### - name: \"::LOGSTASH::\" auth_key: logstash:logstash actions: [\"indices:data/read/*\",\"indices:data/write/*\",\"indices:admin/template/*\",\"indices:admin/create\"] indices: [\"*logstash-*\"] ##################################################################################### # These credentials have no limitations, and shall be used only by the Kibana deamon. ##################################################################################### - name: \"::KIBANA-SRV::\" auth_key: kibana:kibana verbosity: error ############################## # SALES: Actual human users... ############################## - name: \"::RO_SALES::\" auth_key: sales_ro_usr:dev1 kibana_access: ro indices: [ \".kibana_sales\", \"logstash-2018*\"] kibana_hide_apps: [\"readonlyrest_kbn\", \"kibana:dev_tools\"] kibana_index: \".kibana_sales\" - name: \"::RW_SALES::\" auth_key: sales_rw_usr:dev2 kibana_access: rw indices: [\".kibana_sales\", \"logstash-*\"] kibana_hide_apps: [\"readonlyrest_kbn\", \"timelion\", \"kibana:dev_tools\", \"kibana:management\"] kibana_index: \".kibana_sales\" - name: \"::ADMIN_SALES::\" auth_key: sales_admin_usr:dev3 kibana_access: admin indices: [\".kibana_sales\", \"logstash-*\"] kibana_index: \".kibana_sales\" ########################### # OPS Actual human users... ########################### - name: \"::RO_OPS::\" auth_key: ops_ro_usr:dev4 kibana_access: ro indices: [ \".kibana_ops\", \"logstash-2018*\"] kibana_hide_apps: [\"readonlyrest_kbn\", \"kibana:dev_tools\"] kibana_index: \".kibana_ops\" - name: \"::RW_OPS::\" auth_key: ops_rw_usr:dev5 kibana_access: rw indices: [\".kibana_ops\", \"logstash-*\"] kibana_hide_apps: [\"readonlyrest_kbn\", \"timelion\", \"kibana:dev_tools\", \"kibana:management\"] kibana_index: \".kibana_ops\" - name: \"::ADMIN_OPS::\" auth_key: ops_admin_usr:dev6 kibana_access: admin indices: [\".kibana_ops\", \"logstash-*\"] kibana_index: \".kibana_ops\" Setup: the Kibana side With ROR, we try as much as possible to keep all the settings withing the Elasticsearch domain. Therefore, you'll notice how few settings are needed on the Kibana side, apart from actually installing the plugin. Open up config/kibana.yml and add/edit the following settings: # Kibana server use ::KIBANA-SRV:: credentials elasticsearch.username: \"kibana\" elasticsearch.password: \"kibana\" Running Fire up Elasticsearch $ bin/elasticsearch And then Kibana $ bin/kibana Logging in Now you are ready to point your browser to the Kibana server IP (defaulting on port 5601) and you should see a login prompt. You can login as any user i.e. \"sales_rw_usr\", or \"ops_admin\" and the password is always \"dev\". MJust remember to login with a RW user first, so Kibana can create its own default settings.","title":"Multi-tenancy Elastic Stack"},{"location":"examples/multitenancy_guide/#multi-tenancy-elastic-stack","text":"This document will guide you through setting up your Elasticsearch and Kibana stack with ReadonlyREST such that: There will be two tenancies: one for Sales and one for Ops department. In each tenancy, 3 users will be able to login into Kibana using their own set of credentials Each tenancy will contain its own, independant Kibana dashboards, visualizations and index patterns. Each user within a tenancy may be restricted to visualizing distinct subsets of the whole data contained in Elasticsearch (i.e. only certain indices).","title":"Multi-tenancy Elastic Stack"},{"location":"examples/multitenancy_guide/#users-and-capabilities","text":"For this tutorials, we want to have three users per tenancy, each of them has a distinct access level to a shared Kibana tenancy (set of dashboards and settings).","title":"Users and capabilities"},{"location":"examples/multitenancy_guide/#sales-department","text":"\"sales_admin\" \"sales_rw_usr\" \"sales_ro_usr\" Can create,edit,delete Sales' dashboards \u2705 \u2705 Can change Kibana settings for Sales \u2705 \u2705 Only sees \"sales_logstash*\" data from 2018 \u2705 Can see \"add\",\"delete\",\"edit\" buttons \u2705 \u2705 \"dev-tools\" Kibana App is hidden \u2705 \u2705 \"readonlyrest\" Kibana App is hidden \u2705","title":"Sales Department"},{"location":"examples/multitenancy_guide/#ops-department","text":"\"ops_admin\" \"ops_rw_usr\" \"ops_ro_usr\" Can create,edit,delete Ops dashboards \u2705 \u2705 Can change Kibana settings for Ops \u2705 \u2705 Only sees ops_logstash data from 2018 \u2705 Can see \"add\",\"delete\",\"edit\" buttons \u2705 \u2705 \"dev-tools\" Kibana App is hidden \u2705 \u2705 \"readonlyrest\" Kibana App is hidden \u2705 NB: ReadonlyREST for Elastisearch and ReadonlyREST Enterprise for Kibana have an great amount of features like groups, connector for external systems like LDAP, etc. Don't forget to visit the full documentation and the forum to know more about it. NB: The capabilities gained by admin users when they access the \"readonlyrest\" Kibana App are global , that is, they can add/remove tenancies, users, groups, etc.","title":"Ops Department"},{"location":"examples/multitenancy_guide/#before-you-start","text":"For the scope of this guide, we will assume: You will have a functioning installation of Elasticsearch and Kibana You have installed the ROR plugin for Elasticsearch You have installed the ROR Enterprise plugin for Kibana If you don't have the ROR Enterprise for Kibana plugin, get yourself a two weeks free trial build!","title":"Before you start"},{"location":"examples/multitenancy_guide/#important-disable-xpack-security-module","text":"Because ReadonlyREST is not compatible with XPack Security module please make sure you disable xpack.security module from both Kibana and Elasticsearch by adding the following line to both elasticsearch.yml and kibana.yml : xpack.security.enabled: false","title":"IMPORTANT: disable Xpack Security module"},{"location":"examples/multitenancy_guide/#setup-the-elasticsearch-side","text":"Right beside your elasticsearch.yml , create a file called readonlyrest.yml and write the following settings into it. readonlyrest: # IMPORTANT FOR LOGIN/LOGOUT TO WORK WITH ROR PLUGIN FOR KIBANA prompt_for_basic_auth: false access_control_rules: ######################################################### # These credentials shall be used by the logstash daemon. ######################################################### - name: \"::LOGSTASH::\" auth_key: logstash:logstash actions: [\"indices:data/read/*\",\"indices:data/write/*\",\"indices:admin/template/*\",\"indices:admin/create\"] indices: [\"*logstash-*\"] ##################################################################################### # These credentials have no limitations, and shall be used only by the Kibana deamon. ##################################################################################### - name: \"::KIBANA-SRV::\" auth_key: kibana:kibana verbosity: error ############################## # SALES: Actual human users... ############################## - name: \"::RO_SALES::\" auth_key: sales_ro_usr:dev1 kibana_access: ro indices: [ \".kibana_sales\", \"logstash-2018*\"] kibana_hide_apps: [\"readonlyrest_kbn\", \"kibana:dev_tools\"] kibana_index: \".kibana_sales\" - name: \"::RW_SALES::\" auth_key: sales_rw_usr:dev2 kibana_access: rw indices: [\".kibana_sales\", \"logstash-*\"] kibana_hide_apps: [\"readonlyrest_kbn\", \"timelion\", \"kibana:dev_tools\", \"kibana:management\"] kibana_index: \".kibana_sales\" - name: \"::ADMIN_SALES::\" auth_key: sales_admin_usr:dev3 kibana_access: admin indices: [\".kibana_sales\", \"logstash-*\"] kibana_index: \".kibana_sales\" ########################### # OPS Actual human users... ########################### - name: \"::RO_OPS::\" auth_key: ops_ro_usr:dev4 kibana_access: ro indices: [ \".kibana_ops\", \"logstash-2018*\"] kibana_hide_apps: [\"readonlyrest_kbn\", \"kibana:dev_tools\"] kibana_index: \".kibana_ops\" - name: \"::RW_OPS::\" auth_key: ops_rw_usr:dev5 kibana_access: rw indices: [\".kibana_ops\", \"logstash-*\"] kibana_hide_apps: [\"readonlyrest_kbn\", \"timelion\", \"kibana:dev_tools\", \"kibana:management\"] kibana_index: \".kibana_ops\" - name: \"::ADMIN_OPS::\" auth_key: ops_admin_usr:dev6 kibana_access: admin indices: [\".kibana_ops\", \"logstash-*\"] kibana_index: \".kibana_ops\"","title":"Setup: the Elasticsearch side"},{"location":"examples/multitenancy_guide/#setup-the-kibana-side","text":"With ROR, we try as much as possible to keep all the settings withing the Elasticsearch domain. Therefore, you'll notice how few settings are needed on the Kibana side, apart from actually installing the plugin. Open up config/kibana.yml and add/edit the following settings: # Kibana server use ::KIBANA-SRV:: credentials elasticsearch.username: \"kibana\" elasticsearch.password: \"kibana\"","title":"Setup: the Kibana side"},{"location":"examples/multitenancy_guide/#running","text":"Fire up Elasticsearch $ bin/elasticsearch And then Kibana $ bin/kibana","title":"Running"},{"location":"examples/multitenancy_guide/#logging-in","text":"Now you are ready to point your browser to the Kibana server IP (defaulting on port 5601) and you should see a login prompt. You can login as any user i.e. \"sales_rw_usr\", or \"ops_admin\" and the password is always \"dev\". MJust remember to login with a RW user first, so Kibana can create its own default settings.","title":"Logging in"},{"location":"examples/multiuser_guide/","text":"Multi-user Elastic Stack This document will guide you through setting up your Elasticsearch and Kibana stack with ReadonlyREST such that: 3 users will be able to login into Kibana using their own set of credentials All users will see the same Kibana dashboards, but may be seeing different subsets of the whole data contained in Elasticsearch. Users and capabilities For this tutorials, we want to have three users, each of them has a distinct access level to a shared Kibana tenancy (set of dashboards and settings). \"admin\" \"rw_usr\" \"ro_usr\" Can create, edit, delete dashboards \u2705 \u2705 Can change Kibana settings \u2705 \u2705 Only sees logstash data from 2019 \u2705 Can see \"add\", \"delete\", \"edit\" buttons \u2705 \u2705 \"dev-tools\" Kibana App is hidden \u2705 \u2705 \"readonlyrest\" Kibana App is hidden \u2705 NB: ReadonlyREST for Elastisearch and ReadonlyREST PRO for Kibana have an great amount of features like groups, connector for external systems like LDAP, etc. Don't forget to visit the full documentation and the forum to know more about it. NB: This guide works with ROR Enterprise as well. Before you start For the scope of this guide, we will assume: You will have a functioning installation of Elasticsearch and Kibana You have installed the ROR plugin for Elasticsearch You have installed the ROR PRO/Enterprise plugin for Kibana If you don't have the ROR PRO (or Enterprise ) plugin for Kibana, get yourself a two weeks free trial build Setup: the Elasticsearch side On the same directory with your elasticsearch.yml (default: config/ , create a file called readonlyrest.yml and write the following settings into it. readonlyrest: # IMPORTANT FOR LOGIN/LOGOUT TO WORK WITH ROR PLUGIN FOR KIBANA prompt_for_basic_auth: false access_control_rules: ######################################################### # These credentials shall be used by the logstash daemon. ######################################################### - name: \"::LOGSTASH::\" auth_key: logstash:logstash actions: [\"indices:data/read/*\",\"indices:data/write/*\",\"indices:admin/template/*\",\"indices:admin/create\"] indices: [\"*logstash-*\"] ##################################################################################### # These credentials have no limitations, and shall be used only by the Kibana deamon. ##################################################################################### - name: \"::KIBANA-SRV::\" auth_key: kibana:kibana ####################### # Actual human users... ####################### - name: \"::RO::\" auth_key: ro_usr:dev kibana_access: ro indices: [ \".kibana\", \"logstash-2019*\"] # <--- can see only data from 2019 kibana_hide_apps: [\"readonlyrest_kbn\", \"timelion\", \"kibana:dev_tools\", \"kibana:management\"] - name: \"::RW::\" auth_key: rw_usr:dev kibana_access: rw indices: [\".kibana\", \"logstash-*\"] kibana_hide_apps: [\"readonlyrest_kbn\", \"timelion\", \"kibana:dev_tools\", \"kibana:management\"] - name: \"::ADMIN::\" auth_key: admin_usr:dev kibana_access: admin indices: [\".kibana\", \"logstash-*\"] Setup: the Kibana side With ROR, we try as much as possible to keep all the settings withing the Elasticsearch domain. Therefore, you'll notice how few settings are needed on the Kibana side, apart from actually installing the plugin. Open up config/kibana.yml and add/edit the following settings: # Kibana server use ::KIBANA-SRV:: credentials elasticsearch.username: \"kibana\" elasticsearch.password: \"kibana\" Running Fire up Elasticsearch $ bin/elasticsearch And then Kibana $ bin/kibana Logging in Now you are ready to point your browser to the Kibana server IP (defaulting on port 5601) and you should see a login prompt. You can login as any user i.e. \"rw_usr\", or \"admin\" and the password is always \"dev\". Just remember to login with a RW user first, so Kibana can create its own default settings.","title":"Multi-user Elastic Stack"},{"location":"examples/multiuser_guide/#multi-user-elastic-stack","text":"This document will guide you through setting up your Elasticsearch and Kibana stack with ReadonlyREST such that: 3 users will be able to login into Kibana using their own set of credentials All users will see the same Kibana dashboards, but may be seeing different subsets of the whole data contained in Elasticsearch.","title":"Multi-user Elastic Stack"},{"location":"examples/multiuser_guide/#users-and-capabilities","text":"For this tutorials, we want to have three users, each of them has a distinct access level to a shared Kibana tenancy (set of dashboards and settings). \"admin\" \"rw_usr\" \"ro_usr\" Can create, edit, delete dashboards \u2705 \u2705 Can change Kibana settings \u2705 \u2705 Only sees logstash data from 2019 \u2705 Can see \"add\", \"delete\", \"edit\" buttons \u2705 \u2705 \"dev-tools\" Kibana App is hidden \u2705 \u2705 \"readonlyrest\" Kibana App is hidden \u2705 NB: ReadonlyREST for Elastisearch and ReadonlyREST PRO for Kibana have an great amount of features like groups, connector for external systems like LDAP, etc. Don't forget to visit the full documentation and the forum to know more about it. NB: This guide works with ROR Enterprise as well.","title":"Users and capabilities"},{"location":"examples/multiuser_guide/#before-you-start","text":"For the scope of this guide, we will assume: You will have a functioning installation of Elasticsearch and Kibana You have installed the ROR plugin for Elasticsearch You have installed the ROR PRO/Enterprise plugin for Kibana If you don't have the ROR PRO (or Enterprise ) plugin for Kibana, get yourself a two weeks free trial build","title":"Before you start"},{"location":"examples/multiuser_guide/#setup-the-elasticsearch-side","text":"On the same directory with your elasticsearch.yml (default: config/ , create a file called readonlyrest.yml and write the following settings into it. readonlyrest: # IMPORTANT FOR LOGIN/LOGOUT TO WORK WITH ROR PLUGIN FOR KIBANA prompt_for_basic_auth: false access_control_rules: ######################################################### # These credentials shall be used by the logstash daemon. ######################################################### - name: \"::LOGSTASH::\" auth_key: logstash:logstash actions: [\"indices:data/read/*\",\"indices:data/write/*\",\"indices:admin/template/*\",\"indices:admin/create\"] indices: [\"*logstash-*\"] ##################################################################################### # These credentials have no limitations, and shall be used only by the Kibana deamon. ##################################################################################### - name: \"::KIBANA-SRV::\" auth_key: kibana:kibana ####################### # Actual human users... ####################### - name: \"::RO::\" auth_key: ro_usr:dev kibana_access: ro indices: [ \".kibana\", \"logstash-2019*\"] # <--- can see only data from 2019 kibana_hide_apps: [\"readonlyrest_kbn\", \"timelion\", \"kibana:dev_tools\", \"kibana:management\"] - name: \"::RW::\" auth_key: rw_usr:dev kibana_access: rw indices: [\".kibana\", \"logstash-*\"] kibana_hide_apps: [\"readonlyrest_kbn\", \"timelion\", \"kibana:dev_tools\", \"kibana:management\"] - name: \"::ADMIN::\" auth_key: admin_usr:dev kibana_access: admin indices: [\".kibana\", \"logstash-*\"]","title":"Setup: the Elasticsearch side"},{"location":"examples/multiuser_guide/#setup-the-kibana-side","text":"With ROR, we try as much as possible to keep all the settings withing the Elasticsearch domain. Therefore, you'll notice how few settings are needed on the Kibana side, apart from actually installing the plugin. Open up config/kibana.yml and add/edit the following settings: # Kibana server use ::KIBANA-SRV:: credentials elasticsearch.username: \"kibana\" elasticsearch.password: \"kibana\"","title":"Setup: the Kibana side"},{"location":"examples/multiuser_guide/#running","text":"Fire up Elasticsearch $ bin/elasticsearch And then Kibana $ bin/kibana","title":"Running"},{"location":"examples/multiuser_guide/#logging-in","text":"Now you are ready to point your browser to the Kibana server IP (defaulting on port 5601) and you should see a login prompt. You can login as any user i.e. \"rw_usr\", or \"admin\" and the password is always \"dev\". Just remember to login with a RW user first, so Kibana can create its own default settings.","title":"Logging in"},{"location":"examples/impersonation/external-services-mocks-ui/","text":"External services mocks configuration External services mock is used to simulate the response of existing authentication or authorization service like LDAP. You don't need to create a user account for configuration testing. You will only need to define users (and their associated groups) that would normally be returned by the external services, listed in test settings. After clicking add/edit user buttons (1), you will see a dialog with an option to add (2) or remove (3) user from external service mock","title":"External services mocks configuration"},{"location":"examples/impersonation/external-services-mocks-ui/#external-services-mocks-configuration","text":"External services mock is used to simulate the response of existing authentication or authorization service like LDAP. You don't need to create a user account for configuration testing. You will only need to define users (and their associated groups) that would normally be returned by the external services, listed in test settings. After clicking add/edit user buttons (1), you will see a dialog with an option to add (2) or remove (3) user from external service mock","title":"External services mocks configuration"},{"location":"examples/impersonation/impersonate-user-ui/","text":"Impersonating Open the ROR menu Click the Edit security settings button Go into the Impersonate tab You can free type impersonate. This button is available only in the situation when in some cases, the system is not able to receive all usernames. In this case, to impersonate, you need to type impersonating username manually. You can add/edit user in a specific external auth mock service You can impersonate a user and imitate his behavior and actions When an impersonation session is started correctly, the \"impersonating\" will be visible in the ROR menu as shown in the picture. Click the Finish impersonation button to stop impersonation and go back into Impersonate tab","title":"Impersonate user ui"},{"location":"examples/impersonation/impersonate-user-ui/#impersonating","text":"Open the ROR menu Click the Edit security settings button Go into the Impersonate tab You can free type impersonate. This button is available only in the situation when in some cases, the system is not able to receive all usernames. In this case, to impersonate, you need to type impersonating username manually. You can add/edit user in a specific external auth mock service You can impersonate a user and imitate his behavior and actions When an impersonation session is started correctly, the \"impersonating\" will be visible in the ROR menu as shown in the picture. Click the Finish impersonation button to stop impersonation and go back into Impersonate tab","title":"Impersonating"},{"location":"examples/impersonation/test-settings-ui/","text":"Writing Test Settings For impersonation to work, some valid Test Settings should be created and saved. It's important that the main ROR setting will be unaffected, so you, as an admin/user don't need to worry that you will break something. Here is how to write test settings: Open the ROR menu Click the Edit security settings button Go into the Test settings tab You can set the \"time to live\" (TTL), that is a time interval after which the test settings will be automatically deactivated and impersonation session will also abruptly exit You can load current settings as test settings You can deactivate settings manually You can save test settings as settings","title":"Writing Test Settings"},{"location":"examples/impersonation/test-settings-ui/#writing-test-settings","text":"For impersonation to work, some valid Test Settings should be created and saved. It's important that the main ROR setting will be unaffected, so you, as an admin/user don't need to worry that you will break something. Here is how to write test settings: Open the ROR menu Click the Edit security settings button Go into the Test settings tab You can set the \"time to live\" (TTL), that is a time interval after which the test settings will be automatically deactivated and impersonation session will also abruptly exit You can load current settings as test settings You can deactivate settings manually You can save test settings as settings","title":"Writing Test Settings"},{"location":"examples/oidc-sso/","text":"OpenID Connect (OIDC) SSO With ReadonlyREST Enterprise, you can integrate with OpenID Connect (OIDC) Single Sign-on identity providers for both authentication and authorization. Follow the guides to know more.","title":"OpenID Connect (OIDC) SSO"},{"location":"examples/oidc-sso/#openid-connect-oidc-sso","text":"With ReadonlyREST Enterprise, you can integrate with OpenID Connect (OIDC) Single Sign-on identity providers for both authentication and authorization. Follow the guides to know more.","title":"OpenID Connect (OIDC) SSO"},{"location":"examples/oidc-sso/keycloak_oidc/","text":"Keycloak This document will guide you through the task of setting up an excellent, open-source identity provider ( KeyCloak ) to work as an external authenticator and authorizer system for your ELK stack. The scenario is the usual: A centralised, large Elasticsearch cluster A Kibana installation We want one, centralised multi tenant Elasticsearch + Kibana; But with some more enterprise requirements: Users need to be able to change their passwords independently Users need to verify their emails Group managers need to be able to add, remove, block (only) their users. Multi factor authentication (MFA) is a requirement. What is Keycloak Keycloak is an advanced authentication server that lets user administer their credentials, and speaks many authentication protocols, Including OpenID Connect (OIDC) SSO. Setup KeyCloak This tutorial was created using KeyCloak 14.0.0. Download the Keycloak from their official website . This guide will use keycloak docker image Run Keycloak: run docker run -e KEYCLOAK_USER= -e KEYCLOAK_PASSWORD= jboss/keycloak where USERNAME and PASSWORD are credentials for your admin account log in as admin Follow the explanation below, or (if your KC version is the same or close enough to this) use the import function to load this configuration file If you imported the JSON file, you should have a \"ror\" realm, and an OpenID Connect (OIDC) client called \"ror_oidc\" (keep this ID or change the \"clientID\" setting in kibana.yml). Please now select \"ror\" realm, navigate to \"clients\", click \"ror_oidc\" client and double-check everything matches with your use case, as this guide assumes both Kibana, Elasticsearch, and Keycloak are running on \"localhost\". Configure Keycloak to work with ROR First, we want to create a new dedicated \"ror\" realm, so we don't interfere with any other use of this Keycloak installation. Then, let's create an OpenId Connect client for this realm: Then, configure the OpenID Connect (OIDC) client kibana.yml (without ssl enabled) # More on how to enable SSL on the official documentation of Kibana server.ssl.enabled: false xpack.security.enabled: false elasticsearch: hosts: [\"https://localhost:9200\"] # <-- our Elasticsearch responds to https ssl.verificationMode: none username: kibana password: kibana readonlyrest_kbn: logLevel: debug auth: # this secret string has to be longer than 256 chars, use environmental variables to fill it in maybe. signature_key: \"9yzBfnLaTYLfGPzyKW9es76RKYhUVgmuv6ZtehaScj5msGpBpa5FWpwk295uJYaaffTFnQC5tsknh2AguVDaTrqCLfM5zCTqdE4UGNL73h28Bg4dPrvTAFQyygQqv4xfgnevBED6VZYdfjXAQLc8J8ywaHQQSmprZqYCWGE6sM3vzNUEWWB3kmGrEKa4sGbXhmXZCvL6NDnEJhXPDJAzu9BMQxn8CzVLqrx6BxDgPYF8gZCxtyxMckXwCaYXrxAGbjkYH69F4wYhuAdHSWgRAQCuWwYmWCA6g39j4VPge5pv962XYvxwJpvn23Y5KvNZ5S5c6crdG4f4gTCXnU36x92fKMQzsQV9K4phcuNvMWkpqVB6xMA5aPzUeHcGytD93dG8D52P5BxsgaJJE6QqDrk3Y2vyLw9ZEbJhPRJxbuBKVCBtVx26Ldd46dq5eyyzmNEyQGLrjQ4qd978VtG8TNT5rkn4ETJQEju5HfCBbjm3urGLFVqxhGVawecT4YM9Rry4EqXWkRJGTFQWQRnweUFbKNbVTC9NxcXEp6K5rSPEy9trb5UYLYhhMJ9fWSBMuenGRjNSJxeurMRCaxPpNppBLFnp8qW5ezfHgCBpEjkSNNzP4uXMZFAXmdUfJ8XQdPTWuYfdHYc5TZWnzrdq9wcfFQRDpDB2zX5Myu96krDt9vA7wNKfYwkSczA6qUQV66jA8nV4Cs38cDAKVBXnxz22ddAVrPv8ajpu7hgBtULMURjvLt94Nc5FDKw79CTTQxffWEj9BJCDCpQnTufmT8xenywwVJvtj49yv2MP2mGECrVDRmcGUAYBKR8G6ZnFAYDVC9UhY46FGWDcyVX3HKwgtHeb45Ww7dsW8JdMnZYctaEU585GZmqTJp2LcAWRcQPH25JewnPX8pjzVpJNcy7avfA2bcU86bfASvQBDUCrhjgRmK2ECR6vzPwTsYKRgFrDqb62FeMdrKgJ9vKs435T5ACN7MNtdRXHQ4fj5pNpUMDW26Wd7tt9bkBTqEGf\" oidc_kc: buttonName: \"KeyCloak OpenID\" type: \"oidc\" protocol: \"http\" issuer: 'http://localhost:8080/auth/realms/ror' <-- Get it from OpenID Endpoint Configuration authorizationURL: 'http://localhost:8080/auth/realms/ror/protocol/openid-connect/auth' <-- Value from from OpenID Endpoint Configuration tokenURL: 'http://localhost:8080/auth/realms/ror/protocol/openid-connect/token' <-- Value from from OpenID Endpoint Configuration userInfoURL: 'http://localhost:8080/auth/realms/ror/protocol/openid-connect/userinfo' <-- Value from from OpenID Endpoint Configuration clientID: 'ror_oidc' <-- Declared in a realm Client Scopes clientSecret: '35d0c1db-a2b7-42d9-9a43-bea88c6535e6' <-- Declared in a realm ror_oidc (our created client) Credentials tab scope: 'openid profile roles role_list email' <-- Declared in a realm Client Scopes usernameParameter: 'preferred_username' groupsParameter: 'groups' kibanaExternalHost: 'localhost:5601' logoutUrl: 'http://localhost:8080/auth/realms/ror/protocol/openid-connect/logout' <-- Value from from OpenID Endpoint Configuration jwksURL: 'http://localhost:8080/auth/realms/ror/protocol/openid-connect/certs' <-- Value from from OpenID Endpoint Configuration To verify all OpenID Endpoint Configuration-based, you can open OpenID Endpoint Configuration page in the kibana realm To provide clientSecret value, you need to open ror_oidc client (or your custom client name) Setup Elasticsearch with ReadonlyREST Our elasticsearch can be run with or without SSL. To make it available on HTTPS (more detailed info in our documentation ), so we modify the elasticsearch.yml append to elasticsearch.yml xpack.security.enabled: false http.type: ssl_netty4 # <-- needed for ROR SSL Write in readonlyrest.yml readonlyrest: ssl: enable: true keystore_file: \"keystore.jks\" keystore_pass: readonlyrest key_pass: readonlyrest prompt_for_basic_auth: false audit_collector: true access_control_rules: - name: \"::KIBANA-SRV::\" auth_key: kibana:kibana verbosity: error - name: \"ReadonlyREST Enterprise instance #1\" kibana_index: \".kibana_sso\" ror_kbn_auth: name: \"kbn1\" ror_kbn: - name: kbn1 # It has to be the same string as we declared in kibana.yml. signature_key: \"9yzBfnLaTYLfGPzyKW9es76RKYhUVgmuv6ZtehaScj5msGpBpa5FWpwk295uJYaaffTFnQC5tsknh2AguVDaTrqCLfM5zCTqdE4UGNL73h28Bg4dPrvTAFQyygQqv4xfgnevBED6VZYdfjXAQLc8J8ywaHQQSmprZqYCWGE6sM3vzNUEWWB3kmGrEKa4sGbXhmXZCvL6NDnEJhXPDJAzu9BMQxn8CzVLqrx6BxDgPYF8gZCxtyxMckXwCaYXrxAGbjkYH69F4wYhuAdHSWgRAQCuWwYmWCA6g39j4VPge5pv962XYvxwJpvn23Y5KvNZ5S5c6crdG4f4gTCXnU36x92fKMQzsQV9K4phcuNvMWkpqVB6xMA5aPzUeHcGytD93dG8D52P5BxsgaJJE6QqDrk3Y2vyLw9ZEbJhPRJxbuBKVCBtVx26Ldd46dq5eyyzmNEyQGLrjQ4qd978VtG8TNT5rkn4ETJQEju5HfCBbjm3urGLFVqxhGVawecT4YM9Rry4EqXWkRJGTFQWQRnweUFbKNbVTC9NxcXEp6K5rSPEy9trb5UYLYhhMJ9fWSBMuenGRjNSJxeurMRCaxPpNppBLFnp8qW5ezfHgCBpEjkSNNzP4uXMZFAXmdUfJ8XQdPTWuYfdHYc5TZWnzrdq9wcfFQRDpDB2zX5Myu96krDt9vA7wNKfYwkSczA6qUQV66jA8nV4Cs38cDAKVBXnxz22ddAVrPv8ajpu7hgBtULMURjvLt94Nc5FDKw79CTTQxffWEj9BJCDCpQnTufmT8xenywwVJvtj49yv2MP2mGECrVDRmcGUAYBKR8G6ZnFAYDVC9UhY46FGWDcyVX3HKwgtHeb45Ww7dsW8JdMnZYctaEU585GZmqTJp2LcAWRcQPH25JewnPX8pjzVpJNcy7avfA2bcU86bfASvQBDUCrhjgRmK2ECR6vzPwTsYKRgFrDqb62FeMdrKgJ9vKs435T5ACN7MNtdRXHQ4fj5pNpUMDW26Wd7tt9bkBTqEGf\"","title":"Keycloak"},{"location":"examples/oidc-sso/keycloak_oidc/#keycloak","text":"This document will guide you through the task of setting up an excellent, open-source identity provider ( KeyCloak ) to work as an external authenticator and authorizer system for your ELK stack. The scenario is the usual: A centralised, large Elasticsearch cluster A Kibana installation We want one, centralised multi tenant Elasticsearch + Kibana; But with some more enterprise requirements: Users need to be able to change their passwords independently Users need to verify their emails Group managers need to be able to add, remove, block (only) their users. Multi factor authentication (MFA) is a requirement.","title":"Keycloak"},{"location":"examples/oidc-sso/keycloak_oidc/#what-is-keycloak","text":"Keycloak is an advanced authentication server that lets user administer their credentials, and speaks many authentication protocols, Including OpenID Connect (OIDC) SSO.","title":"What is Keycloak"},{"location":"examples/oidc-sso/keycloak_oidc/#setup-keycloak","text":"This tutorial was created using KeyCloak 14.0.0. Download the Keycloak from their official website . This guide will use keycloak docker image Run Keycloak: run docker run -e KEYCLOAK_USER= -e KEYCLOAK_PASSWORD= jboss/keycloak where USERNAME and PASSWORD are credentials for your admin account log in as admin Follow the explanation below, or (if your KC version is the same or close enough to this) use the import function to load this configuration file If you imported the JSON file, you should have a \"ror\" realm, and an OpenID Connect (OIDC) client called \"ror_oidc\" (keep this ID or change the \"clientID\" setting in kibana.yml). Please now select \"ror\" realm, navigate to \"clients\", click \"ror_oidc\" client and double-check everything matches with your use case, as this guide assumes both Kibana, Elasticsearch, and Keycloak are running on \"localhost\".","title":"Setup KeyCloak"},{"location":"examples/oidc-sso/keycloak_oidc/#configure-keycloak-to-work-with-ror","text":"First, we want to create a new dedicated \"ror\" realm, so we don't interfere with any other use of this Keycloak installation. Then, let's create an OpenId Connect client for this realm: Then, configure the OpenID Connect (OIDC) client kibana.yml (without ssl enabled) # More on how to enable SSL on the official documentation of Kibana server.ssl.enabled: false xpack.security.enabled: false elasticsearch: hosts: [\"https://localhost:9200\"] # <-- our Elasticsearch responds to https ssl.verificationMode: none username: kibana password: kibana readonlyrest_kbn: logLevel: debug auth: # this secret string has to be longer than 256 chars, use environmental variables to fill it in maybe. signature_key: \"9yzBfnLaTYLfGPzyKW9es76RKYhUVgmuv6ZtehaScj5msGpBpa5FWpwk295uJYaaffTFnQC5tsknh2AguVDaTrqCLfM5zCTqdE4UGNL73h28Bg4dPrvTAFQyygQqv4xfgnevBED6VZYdfjXAQLc8J8ywaHQQSmprZqYCWGE6sM3vzNUEWWB3kmGrEKa4sGbXhmXZCvL6NDnEJhXPDJAzu9BMQxn8CzVLqrx6BxDgPYF8gZCxtyxMckXwCaYXrxAGbjkYH69F4wYhuAdHSWgRAQCuWwYmWCA6g39j4VPge5pv962XYvxwJpvn23Y5KvNZ5S5c6crdG4f4gTCXnU36x92fKMQzsQV9K4phcuNvMWkpqVB6xMA5aPzUeHcGytD93dG8D52P5BxsgaJJE6QqDrk3Y2vyLw9ZEbJhPRJxbuBKVCBtVx26Ldd46dq5eyyzmNEyQGLrjQ4qd978VtG8TNT5rkn4ETJQEju5HfCBbjm3urGLFVqxhGVawecT4YM9Rry4EqXWkRJGTFQWQRnweUFbKNbVTC9NxcXEp6K5rSPEy9trb5UYLYhhMJ9fWSBMuenGRjNSJxeurMRCaxPpNppBLFnp8qW5ezfHgCBpEjkSNNzP4uXMZFAXmdUfJ8XQdPTWuYfdHYc5TZWnzrdq9wcfFQRDpDB2zX5Myu96krDt9vA7wNKfYwkSczA6qUQV66jA8nV4Cs38cDAKVBXnxz22ddAVrPv8ajpu7hgBtULMURjvLt94Nc5FDKw79CTTQxffWEj9BJCDCpQnTufmT8xenywwVJvtj49yv2MP2mGECrVDRmcGUAYBKR8G6ZnFAYDVC9UhY46FGWDcyVX3HKwgtHeb45Ww7dsW8JdMnZYctaEU585GZmqTJp2LcAWRcQPH25JewnPX8pjzVpJNcy7avfA2bcU86bfASvQBDUCrhjgRmK2ECR6vzPwTsYKRgFrDqb62FeMdrKgJ9vKs435T5ACN7MNtdRXHQ4fj5pNpUMDW26Wd7tt9bkBTqEGf\" oidc_kc: buttonName: \"KeyCloak OpenID\" type: \"oidc\" protocol: \"http\" issuer: 'http://localhost:8080/auth/realms/ror' <-- Get it from OpenID Endpoint Configuration authorizationURL: 'http://localhost:8080/auth/realms/ror/protocol/openid-connect/auth' <-- Value from from OpenID Endpoint Configuration tokenURL: 'http://localhost:8080/auth/realms/ror/protocol/openid-connect/token' <-- Value from from OpenID Endpoint Configuration userInfoURL: 'http://localhost:8080/auth/realms/ror/protocol/openid-connect/userinfo' <-- Value from from OpenID Endpoint Configuration clientID: 'ror_oidc' <-- Declared in a realm Client Scopes clientSecret: '35d0c1db-a2b7-42d9-9a43-bea88c6535e6' <-- Declared in a realm ror_oidc (our created client) Credentials tab scope: 'openid profile roles role_list email' <-- Declared in a realm Client Scopes usernameParameter: 'preferred_username' groupsParameter: 'groups' kibanaExternalHost: 'localhost:5601' logoutUrl: 'http://localhost:8080/auth/realms/ror/protocol/openid-connect/logout' <-- Value from from OpenID Endpoint Configuration jwksURL: 'http://localhost:8080/auth/realms/ror/protocol/openid-connect/certs' <-- Value from from OpenID Endpoint Configuration To verify all OpenID Endpoint Configuration-based, you can open OpenID Endpoint Configuration page in the kibana realm To provide clientSecret value, you need to open ror_oidc client (or your custom client name)","title":"Configure Keycloak to work with ROR"},{"location":"examples/oidc-sso/keycloak_oidc/#setup-elasticsearch-with-readonlyrest","text":"Our elasticsearch can be run with or without SSL. To make it available on HTTPS (more detailed info in our documentation ), so we modify the elasticsearch.yml append to elasticsearch.yml xpack.security.enabled: false http.type: ssl_netty4 # <-- needed for ROR SSL Write in readonlyrest.yml readonlyrest: ssl: enable: true keystore_file: \"keystore.jks\" keystore_pass: readonlyrest key_pass: readonlyrest prompt_for_basic_auth: false audit_collector: true access_control_rules: - name: \"::KIBANA-SRV::\" auth_key: kibana:kibana verbosity: error - name: \"ReadonlyREST Enterprise instance #1\" kibana_index: \".kibana_sso\" ror_kbn_auth: name: \"kbn1\" ror_kbn: - name: kbn1 # It has to be the same string as we declared in kibana.yml. signature_key: \"9yzBfnLaTYLfGPzyKW9es76RKYhUVgmuv6ZtehaScj5msGpBpa5FWpwk295uJYaaffTFnQC5tsknh2AguVDaTrqCLfM5zCTqdE4UGNL73h28Bg4dPrvTAFQyygQqv4xfgnevBED6VZYdfjXAQLc8J8ywaHQQSmprZqYCWGE6sM3vzNUEWWB3kmGrEKa4sGbXhmXZCvL6NDnEJhXPDJAzu9BMQxn8CzVLqrx6BxDgPYF8gZCxtyxMckXwCaYXrxAGbjkYH69F4wYhuAdHSWgRAQCuWwYmWCA6g39j4VPge5pv962XYvxwJpvn23Y5KvNZ5S5c6crdG4f4gTCXnU36x92fKMQzsQV9K4phcuNvMWkpqVB6xMA5aPzUeHcGytD93dG8D52P5BxsgaJJE6QqDrk3Y2vyLw9ZEbJhPRJxbuBKVCBtVx26Ldd46dq5eyyzmNEyQGLrjQ4qd978VtG8TNT5rkn4ETJQEju5HfCBbjm3urGLFVqxhGVawecT4YM9Rry4EqXWkRJGTFQWQRnweUFbKNbVTC9NxcXEp6K5rSPEy9trb5UYLYhhMJ9fWSBMuenGRjNSJxeurMRCaxPpNppBLFnp8qW5ezfHgCBpEjkSNNzP4uXMZFAXmdUfJ8XQdPTWuYfdHYc5TZWnzrdq9wcfFQRDpDB2zX5Myu96krDt9vA7wNKfYwkSczA6qUQV66jA8nV4Cs38cDAKVBXnxz22ddAVrPv8ajpu7hgBtULMURjvLt94Nc5FDKw79CTTQxffWEj9BJCDCpQnTufmT8xenywwVJvtj49yv2MP2mGECrVDRmcGUAYBKR8G6ZnFAYDVC9UhY46FGWDcyVX3HKwgtHeb45Ww7dsW8JdMnZYctaEU585GZmqTJp2LcAWRcQPH25JewnPX8pjzVpJNcy7avfA2bcU86bfASvQBDUCrhjgRmK2ECR6vzPwTsYKRgFrDqb62FeMdrKgJ9vKs435T5ACN7MNtdRXHQ4fj5pNpUMDW26Wd7tt9bkBTqEGf\"","title":"Setup Elasticsearch with ReadonlyREST"},{"location":"examples/saml-sso/","text":"SAML SSO With ReadonlyREST Enterprise, you can integrate with SAML 2.0 Single Sign-on identity providers for both authentication and authorization. Follow the guides to know more.","title":"SAML SSO"},{"location":"examples/saml-sso/#saml-sso","text":"With ReadonlyREST Enterprise, you can integrate with SAML 2.0 Single Sign-on identity providers for both authentication and authorization. Follow the guides to know more.","title":"SAML SSO"},{"location":"examples/saml-sso/adfs/","text":"Microsoft ADFS How to Connect ROR Enterprise with SAML and ADFS ReadonlyREST (ROR) Enterprise allows for complex authentication and authorization configurations with Kibana and Elasticsearch. When Elasticsearch is combined with Kibana, a data visualization dashboard, the combination provides a powerful way to ingest logs and analyze data. To access that data, many enterprises manage users in a central directory. This directory could be an Active Directory (AD) instance, in the case of a Windows-centric environment, or a cloud directory provider, such as Google Cloud Identity, in a cloud-based environment. Instead of integrating these services directly into a product, an abstraction layer such as SAML can provide authentication and authorization and tie into different back ends as necessary. ReadonlyREST provides a free Elasticsearch plugin that provides advanced authentication options. When it is combined with the ReadonlyREST Enterprise plugin for Kibana, integrating SAML authentication into the authentication process becomes easy. This article will walk through the process of setting up an entire environment in order to demonstrate how the ReadonlyREST free and Enterprise plugins integrate with Active Directory Federation Services (AD FS) to provide SAML authentication. In this tutorial, you will learn how to: Provision Azure Virtual Machines to host Active Directory, Elasticsearch, and Kibana Install and configure Active Directory (AD) Services Provision sample AD users Install and configure Active Directory Certificate Services (AD CS) Install and configure Active Directory Federation Services (AD FS) Install and configure ElasticSearch and the ReadonlyREST Free Plugin Install and configure Kibana and the ReadonlyREST Enterprise Plugin Provisioning Azure Virtual Machines to Host Active Directory, Elasticsearch, and Kibana Any Windows Server 2016 Virtual Machines (VM) can be used for this process; however, in this demonstration, the Microsoft Azure environment will be used to provision and host the VMs. You can name your VMs whatever you would like. This article will refer to the names listed below for consistency. Virtual Machine 1: lc-win2019-02 Roles : Active Directory, AD Certificate Services, AD Federation Services, DNS Memory : 4GB Virtual Machine 2: lc-win2019-03 Roles : Elasticsearch, Kibana Memory : 8GB These Azure VMs will be Pay-As-You-Go and Spot Instances for affordability. The example shown below is for the Elasticsearch and Kibana VM which will be duplicated for the Active Directory VM but will have 4GBs of memory instead of 8GB. Please note that Azure Spot Instances cannot be resized after creation. Provisioning Virtual Machines Log into the Azure portal using a Pay-As-You-Go subscription. Create a new virtual machine. If you do not already have a resource group created to serve as a home for the VMs, select Create new and create the resource group. Name your virtual machine appropriately, and choose the details for your instance, as shown in the example below. You can use the default hard drive sizes and Standard HDD disks for this environment. The default Networking options will also work here. As will the default Management options. No additional Advanced options are necessary. If you would like to tag your VMs for later categorization and tracking, you can do so here. Finally, create the VM. After this VM has been created, create one more to host the Active Directory and related services. In the end, you should have two VMs as outlined above. Installing and Configuring Active Directory (AD) Services After the two VMs have been provisioned, the next step is to set up directory services on the first VM, lc-win2019-02. Installing Active Directory Services Once you are logged into lc-win2019-02, choose Add Roles and Features on the Server Manager screen. Select Role-based or feature-based installation . Select the correct server from the server pool. Select Active Directory Domain Services, and add the additional features as prompted. No additional features are necessary since the default options work. Click Next on the Active Directory Domain Services informational screen. Finally, select Restart the destination server automatically if required . Click Yes when prompted, and then click Install. Once installation has finished, click on Close. Configuring Active Directory Services If DNS has not been installed already, the role installation screen may pop up in the middle of the Active Directory installation. Installation instructions for the DNS role are shown after the Configuring Active Directory Services section below. Click on Promote this server to a domain controller, which will allow you to see the Deployment Configuration screen. Name the domain. In this case, use ad.lc-test.local. This name was arbitrarily chosen. Using a subdomain such as \u201cad\u201d instead of your actual domain (i.e., [lc-test.local]( http://lc-test.local\\ is recommended. Select Windows Server 2016 as the functional level . For the domain controller capabilities , choose Domain Name System (DNS) server . Set a Directory Services Restore Mode (DSRM) password. The following DNS Options warning message can be disregarded: Set the NetBIOS domain name , which is usually the short name prior to the host name (e.g., AD), and click Next. Use the default paths, and click on Next. On the Review Options screen, click Next if everything looks correct. On the Prerequisites Check screen, click Install. You\u2019ll see a number of warnings related to the fact that this is a test environment. They can be safely ignored. When you click Close , you will have a successful configuration. Click Close on the restart prompt. Configuring the Domain Name Services (DNS) Role Click on the DNS Services role, add the additional features as requested, and click Next. If you are using DHCP for the server (this is not recommended for a production service), then you will see the validation warning shown below. It can be disregarded. Click on Continue and Install. Click Next on the Features screen, since no additional features are necessary. Click Next on the informational DNS Server screen. Click Install on the Confirmation screen. Select Restart the destination server automatically if required, and click Install. Finally, click Close, and you will have a successful installation. Joining Computers to the Domain Next we need to join the second server\u2014the one hosting Elasticsearch and Kibana\u2014to the domain. Open an RDP connection to the second server. Then, open Notepad as an Administrator, and open the file C:\\Windows\\System32\\drivers\\etc\\hosts. Add the IP address and hostnames for the domain controller. These will reflect the IP addresses and hostnames you chose for your configuration: FQDN : 10.0.0.5 - ad.lc-test.local NetBIOS : 10.0.0.5 - ad Additionally, you will need to change your network adapter DNS to point to your domain server; in this case, it is 10.0.0.5. If the system restarted, open an RDP connection, and then open the System screen under the Control Pane and select Advanced System settings. Click on Change to add this server to the domain. Enter the domain (e.g., ad.lc-test.local). Click on OK, and enter the credentials of the account that has privileges enabling it to add the domain. Restart the server after joining it to the domain. Provisioning Sample AD Users For testing purposes, it can be useful to provision additional users within the Active Directory. The following PowerShell script, which should be run on the domain controller, will make this easy. Note that we are setting the mail attribute which will be used for the SAML username. Import-Module -Name 'ActiveDirectory' $Domain = 'ad.lc-test.local'\\ $OU = 'CN=Users,DC=ad,DC=lc-test,DC=local' $Users = @{\\ \"TestUser1\" = \"testPass1\"\\ \"TestUser2\" = \"testPass2\"\\ \"TestUser3\" = \"testPass3\"\\ \"TestUser4\" = \"testPass4\"\\ \"TestUser5\" = \"testPass5\"\\ } $Users.GetEnumerator() | ForEach-Object {\\ $Name = $_.Key\\ $Password = $_.Value $Params = @{\\ \"Name\" = $Name\\ \"Path\" = $OU\\ \"AccountPassword\" = (ConvertTo-SecureString -AsPlainText $Password -Force)\\ \"Enabled\" = $True\\ \"DisplayName\" = $Name\\ \"PasswordNeverExpires\" = $True\\ \"CannotChangePassword\" = $True\\ \"EmailAddres\" = \"$Name@$Domain\"\\ } New-ADUser @Params\\ } Installing Active Directory Certificate Services (AD CS) Click on Active Directory Certificate Services, and add the additional features as prompted. Since no additional features are necessary, allow defaults, and click on Next. On the Active Directory Certificate Services informational screen, click Next to continue. Select the Certification Authority role services, and click Next. Select Restart the destination server automatically if required, and click on Install. Finally, click on Close when the installation has been completed. Configuring Active Directory Certificate Services Click on Configure Active Directory Certificate Services. Select the default administrative user for AD CS credentials. Under Role Services , check Certification Authority, and click Next. Select Enterprise CA, and click on Next. Click on Root CA , then click on Next. Click on Create a new private key, and then click on Next. Select RSA#Microsoft Software Key Storage Provider , a default key length of 2048 , and a hash algorithm of SHA256. Click Next. Use the defaults given for the CA Name, and click on Next. Select a validity period of 5 years, and click on Next. Leave the default database locations in place, and click on Next. Click on Configure and Close when the configuration process has been completed. Installing and Configuring Active Directory Federation Services (AD FS) Previously, it was recommended that AD FS should not be installed on the same server as the DC because IIS was installed as part of that process. As of 2012, this recommendation has changed, since AD FS does not use IIS anymore. Now, mounting AD FS and DC on the same server is advised for domains under 1000 users. Provisioning SSL Certificate Templates Open the Certification Authority MMC snapin, right-click on Certificate Templates, and click on Manage. Select Duplicate Template on the Web Server template. Enter \u201cSSL Certificates\u201d in the box labeled Template display name on the General tab. On the Security tab, click on Enroll and Allow for Authenticated Users, and, finally, Apply the configuration. Right-click on Certificate Templates \u2192 New \u2192 Certificate Template to Issue. Select SSL Certificates from the Certificate Template list, and click OK. Provisioning the SSL Certificate Open the Certificates MMC snapin for the Local Computer. Navigate to Personal \u2192 Certificates, and right-click to open All Tasks \u2192 Request New Certificate. Click Next on the Before you Begin screen. Click Next on the Select Certificate Enrollment Policy screen. Select SSL Certificates, and click on More information is required to enroll for this certificate. Select Click here to configure settings to configure the certificate. Add the following details on the Certificate Properties Subject screen, then click OK : Subject Name Common Name : CN=lc-win2019-02.ad.lc-test.local Alternative Name DNS : lc-win2019-02.ad.lc-test.local DNS : enterpriseregistration.ad.lc-test.local Click on Enroll to request the certificate, then click Finish . Setting up Active Directory Federation Services Select the Active Directory Federation Services role, and click Next. Click Next on Select Features , since no additional features are needed. Click Next on the Active Directory Federation Services informational screen. Check Restart the destination server automatically if required, and click Install and Close when the installation has completed. Creating a Group Managed Service Account and Adding a KDS Key It is best to use a gMSA (group Managed Service Account) instead of a traditional sMSA (standalone Managed Service Account). The primary difference between the two is that, in a gMSA, the Windows operating system manages the password for the account instead of relying on the administrator to do it. Before we can select the gMSA, however, we need to add a KDS Root Key . To avoid non-blocking warnings later in the process, this key should be added with an effective date of 10 hours prior to the current date and time. Open a PowerShell session as an Administrator, and run the following command to add the KDS root key: Add-KdsRootKey -EffectiveTime ((Get-Date).AddHours(-10)) If you do not take this step, you will see the following error when attempting to add the gMSA account: To create a gMSA account to use with the AD FS service, use the PowerShell script provided below. If you get an \u201caccess denied\u201d error when running Install-ADServiceAccount, you may need to restart the server first. $Name = 'sa_adfs' $Params = @{\\ \"Name\" = $Name\\ \"DNSHostName\" = 'lc-win2019-02.ad.lc-test.local'\\ \"PrincipalsAllowedToRetrieveManagedPassword\" = 'lc-win2019-02$'\\ \"ServicePrincipalNames\" = 'http/lc-win2019-02.ad.lc-test.local'\\ } $ServiceAccount = New-ADServiceAccount @Params Install-ADServiceAccount -Identity $Name Add-ADComputerServiceAccount -Identity 'lc-win2019-02' -ServiceAccount $ServiceAccount Configuring Federation Services Click on the link that says Configure the federation service on this server . Select Create the first federation server in a federation server farm, and click Next. On the Connect to Active Directory Domain Services screen, leave the default user selected, then click on Next . Select the previously created SSL Certificate, and enter \u201cLC Test\u201d for the Federation Service Display Name. Click Next. On the Specify Service Account screen, click on Select to use an existing account and locate the sa_adfs service account that was previously created. Click Next. Select Create a database on this server using Windows Internal Database, and click Next . Click on Next under Review Options. Verify the Pre-requisite Checks, and click on Configure. Click on Close, and restart the server. The warnings shown below can be disregarded for this test instance: Once the server has restarted, open an Administrative PowerShell session, and run the following command to enable the IdP Signon Page: Set-ADFSProperties -EnableIdPInitiatedSignonPage $True Verify that AD FS metadata is being returned by navigating to the following URL: https://{FQDN of AD FS Server}/adfs/fs/federationserverservice.asmx Setting Up ReadonlyREST Relying Trust Open the AD FS MMC snapin, right-click on the Relying Party Trusts folder, and select Add Relying Party Trust. Select Claims aware, and click Start. Choose Enter data about the relying party manually, and click Next. Enter a Display Name (in this case, \u201cror\u201d), and click Next. It\u2019s not necessary to specify a token encryption certificate, so click Next to continue. Select the option Enable support for the SAML 2.0 SSL service URL, and enter: https://{IP Address of Kibana Server}:5601/ror_kbn_sso_saml_adfs/assert The saml_adfs will change depending on the name chosen in the configuration of the kibana.yml file. Enter the Relying party trust identifiers , in this case, \u201cror.\u201d This will match the Issuer in the Kibana configuration. Click Next when you are done with this step. On the Access Control Policy screen, select Permit everyone, and click Next. Click Next to finish adding the trust. Verify that Configure claims insurance policy for this application is selected, and click on Close. Configuring Claims Though we have not yet configured claims for Kibana, the metadata for the SAML configuration in Kibana would look similar to the following, if you were able to view it: The important section to note concerns the claims issuance policy. We need to return a NameID format in the form of an emailAddress by entering the following code : \\ \\ urn:oasis:names:tc:SAML:1.1:nameid-format:emailAddress\\ \\ Therefore, we need two rules: one to pull back the LDAP attribute from the Active Directory, and another to transform that data into the correct format. Click on Add Rule on the Edit Claim Issuance Policy for ror screen. For the first rule, choose Send LDAP Attributes as Claims, and click Next. Choose the AD Attribute to return\u2014in this case, the email address\u2014and click Finish on the Configure Rule screen of the Add Transform Claim Rule Wizard. Claim rule name : LDAP Email Active Store : Active Directory LDAP Attribute : E-Mail-Addresses Outgoing Claim Type : E-Mail Address Click on Add Rule, then choose the Transform an Incoming Claim claim rule template, and click on Next. Enter the transformation details as listed below, and, on the Edit Rule screen, click on OK. Claim rule name : Email Transform Incoming claim type : E-Mail Address Outgoing claim type : Name ID Outgoing name ID format : Email Pass through all claim values : Selected Click OK to save the rules. Please note that the order of the rules on the Edit Claim Issuance Policy screen is important. Updating Relying Party Trusts Navigate to the Relying Party Trusts folder, right-click on the ror trust, and select Properties. Click on the Endpoints tab, select the SAML Assertion Consumer Endpoints, and click on Edit. Click on Set the trusted URL as default, and change the Index to 1 from 0. Click OK. On the Endpoints screen, click on Add SAML, and enter the SAML Logout details as follows: Endpoint Type : SAML Logout Binding : POST Trusted URL : https://{IP Address of Kibana Server}:5601/ror_kbn_sso_saml_adfs/notifylogout Click on OK to save the modified properties. Installing and Configuring Elasticsearch and the ReadonlyREST Free Plugin Installing Elasticsearch Elasticsearch will be installed on the lc-win2019-03 server provisioned with 8GB of RAM in Azure. Locate a recent download of Elasticsearch , and install the MSI package. At the time this article was written, the most recent version available was 7.6.2; however, you may want to check for more updated versions as they become available. Launch the downloaded installer and click Next on the Locations screen, leaving the defaults in place. Use the defaults on the Service screen, and click Next. Use the defaults on the Configuration screen, and click Next. No additional plugins are necessary; therefore, click Next. Leave the X-Pack licenses set to Basic, and click on Install. Click on Exit. Installing the Elasticsearch Plugin Navigate to the ReadonlyREST Plugin download page to enter your details. You will receive the download link in your email. Make sure to choose the Free Elasticsearch Plugin that matches your Elasticstack version. Download the plugin, open an Administrative command prompt, and navigate to the Elasticsearch program directory. Run the plugin installation by entering the following: cd \"C:\\Program Files\\Elastic\\ElasticSearch\\7.6.2\\bin\" elasticsearch-plugin.bat install file:///C:/Users/lc-admin.AD/Downloads/readonlyrest-1.19.4_es7.6.2.zip 5. 6. Navigate to the C:\\ProgramData\\Elastic\\ElasticSearch\\config directory, and create the file readonlyrest.yml. 7. 8. Open the readonlyrest.yml file in Notepad to run this very basic configuration that configures the following two different access control rules: 1. \u201c ::KIBANA-SRV:: \u201d \u2014this rule allows the Kibana server to authenticate to Elasticsearch using digest authentication with the username \u201ckibana\u201d and password \u201ckibana.\u201d 2. \u201cADFS Users\u201d\u2014this rule uses the ror_kbn_auth method which allows SAML authenticates to succeed. 9. Create a random 256-character signature_key. This key will be shared between Kibana and Elasticsearch. 10. Please note that the kbn1 identifier must match in the ror_kbn_auth and ror_kbn sections; however, any names can be used for them. ``` readonlyrest: access_control_rules: name: \"::KIBANA-SRV::\" auth_key: kibana:kibana name: \"ADFS Users\" ror_kbn_auth: name: \"kbn1\" ror_kbn: - name: kbn1 signature_key: \"VEGj@YLLhsAigspnNi2Xsopsqja_nrKUqU__eQW9VQ2!9p!RoeHwc-G.y-MVJtYYcDFCH.e3W2BKcZsoynJaHyjjXyh7kDHjsYKPkczvai-xCzP@Ez3QW23ZBFuReA7kPAqnc6pQ3VeNeFf3sWNoKeJAt_d9J7aFwEvCP2Gb-kQcA8YR wNWHQuo-jwmmo2Qqpu_Fq3aKFCbNFWUbK@BVwmmKezxn3h687mAkuyhV4.hnfrjVjF-Rphjqmy4.tB8\" ``` 11. Restart Elasticsearch Windows Service . This can be done in the Services * MMC snapin. Installing and Configuring Kibana and the ReadonlyREST Enterprise Plugin Installing Kibana Locate a recent download of Kibana , and download the zip package. At the time this article was written, the most recent version was 7.6.2. You may want to check for more updated links as they become available. Extract the Kibana installation. Note that this is a rather large file. If you have trouble with the default Windows zip extractor, you may want to try a tool such as 7-Zip. Move the extracted folder to C:\\kibana. This may require you to rename the folder. Open an administrative command prompt, and navigate to the Kibana directory to run the kibana.bat batch file and start Kibana. Once Kibana has started, navigate to [ http://localhost:5601](http://localhost:5601\\ to verify that Kibana is functional. Creating a Self-Signed Certificate for Kibana It is necessary to make Kibana operate under SSL for AD FS to perform SAML authentication. The easiest way to generate a self-signed certificate using the required format is to use OpenSSL . A Windows version of this tool available for download is located here . If Microsoft Visual C++ 2017 Redistributables (64-bit) is not already installed, click Yes to download the installation and run the installer first. Accept the license agreement, and click on Install. Back on the OpenSSL installation, click on I accept the agreement , then click on Next. Click Next on the Destination Location screen. Click Next on the Select Start Menu Folder screen. Select The Windows system directory on the Additional Tasks screen, and click Next. Click on Install. Click on Finish. Open an administrative command prompt, and run the following command to create the certificates in the specific X509 PEM format that Kibana requires: \"C:\\Program Files\\OpenSSL-Win64\\bin\\openssl.exe\" req -x509 -sha256 -nodes -days 730 -newkey rsa:2048 -keyout localhost-key.pem -out localhost.pem -subj \"/C=US/ST=IL/L=Bloomington/O=lc-test/CN=10.0.0.6\" 19. Change the subj to one that is more indicative of your installation. Make sure the CN={IP Address} matches the accessible IP of your Elasticsearch/Kibana server. 20. 21. Locate the newly created pem certificates and copy them to C:\\kibana\\ssl_cert. 22. The ssl_cert directory will need to be created first. For our purposes here, it has been arbitrarily named. 23. 24. Restart Kibana by entering Ctrl-C in the running command prompt window and then re-running kibana.bat. Installing the ReadonlyREST Enterprise Plugin Navigate to the ReadonlyREST Plugin download page to enter your details. You will get the download link in your email. Making sure to choose the Enterprise Kibana Plugin and match it with your Elasticstack version. The email that you receive will contain installation instructions. The link will be time-limited, as shown below. Navigate to C:\\kibana\\config, and locate the kibana.yml configuration file. Open the kibana.yml file in Notepad and update it with the following details: elasticsearch.username\u2014This field matches the first part (pre-colon) of the auth_key in the readonlyrest.yml Elasticsearch configuration file. elasticsearch.password\u2014This field matches the second part (post-colon) of the auth_key in the readonlyrest.yml Elasticsearch configuration file. elasticsearch.ssl.verificationMode\u2014Set the value to \u201ctrue\u201d to ignore SSL errors. This is useful when working in a test environment. xpack.security.enabled\u2014This must be disabled for ReadonlyREST to work. [server.host]( http://server.host\u2014By default, this will be [localhost]( http://localhost\\ ; but, we need to use a routable address, which, in this case, is the 10.0.0.6 IP of this server. server.ssl.enabled\u2014This is used to turn on SSL and respond to https. server.ssl.certificate\u2014This is the location of the public key certificate. server.ssl.key\u2014This is the location of the private key for the certificate. readonlyrest_kbn.logLevel\u2014The value is set to \u201cdebug\u201d to enable troubleshooting in the console. readonlyrest_kbn.clearSessionOnEvents\u2014This clears the session on a successful login event. readonlyrest_kbn.auth.signature_key\u2014This must match the 256-character value in the signature_key attribute of the readonlyrest.yml Elasticsearch configuration file. readonlyrest_kbn.auth.saml_adfs.buttonName\u2014This is the name of the login button on the login screen of Kibana. readonlyrest_kbn.auth.saml_adfs.enabled\u2014This enables the SAML SSO configuration. readonlyrest_kbn.auth.saml_adfs.type\u2014For AD FS, this must be \u201csaml.\u201d readonlyrest_kbn.auth.saml_adfs.issue \u2014This is the unique identifier that was defined in the AD FS Relying Party Trust configuration, in this case, \u201cror.\u201d readonlyrest_kbn.auth.saml_adfs.protocol\u2014AD FS requires https. readonlyrest_kbn.auth.saml_adfs.entryPoint\u2014This is the entry point for AD FS\u2014 https://{AD FS Server}/adfs/ls. readonlyrest_kbn.auth.saml_adfs.logoutUrl\u2014This is the logout call to AD FS\u2014 https://{AD FS Server}/adfs/ls?wa=wsignout1.0. readonlyrest_kbn.auth.saml_adfs.kibanaExternalHost\u2014This is the address and port without the protocol preceding (i.e., https). readonlyrest_kbn.auth.saml_adfs.usernameParameter\u2014This configuration is only doing authentication, and it must match the nameID parameter. Opening the Firewall Port To allow the AD FS server to talk to Kibana, we need to open the 5601 port on the Kibana server since [localhost]( http://localhost\\ is not routable. Open the Windows Firewall with Advanced Security screen, and add a new rule under Inbound Rules. Choose Port. Add the specific local port of 5601, and click Next. Select Allow the connection, and click Next. Choose all profiles (the default), and click Next. Name the rule \u201cKibana,\u201d and click Finish. Demonstration Navigate to your Kibana URL ( https://10.0.0.6:5601\\ using Chrome or Firefox. Do not use IE or the SSO button may not show up. Click on ADFS, the button configured in the kibana.yml file, and log in with one of the created AD users. Use the defined mail attribute on the AD account (an email address). With a successful login, the Kibana screen will appear, and you will see your SAML authenticated user in the lower right corner. Conclusion ReadonlyREST combined with Elasticsearch and Kibana opens a world of advanced authentication and authorization options to you. Though only a basic configuration was outlined here, many more useful configuration options are available. You can find out more information about these advanced configurations in the ReadonlyREST documentation and in the ROR forums.","title":"Microsoft ADFS"},{"location":"examples/saml-sso/adfs/#microsoft-adfs","text":"How to Connect ROR Enterprise with SAML and ADFS ReadonlyREST (ROR) Enterprise allows for complex authentication and authorization configurations with Kibana and Elasticsearch. When Elasticsearch is combined with Kibana, a data visualization dashboard, the combination provides a powerful way to ingest logs and analyze data. To access that data, many enterprises manage users in a central directory. This directory could be an Active Directory (AD) instance, in the case of a Windows-centric environment, or a cloud directory provider, such as Google Cloud Identity, in a cloud-based environment. Instead of integrating these services directly into a product, an abstraction layer such as SAML can provide authentication and authorization and tie into different back ends as necessary. ReadonlyREST provides a free Elasticsearch plugin that provides advanced authentication options. When it is combined with the ReadonlyREST Enterprise plugin for Kibana, integrating SAML authentication into the authentication process becomes easy. This article will walk through the process of setting up an entire environment in order to demonstrate how the ReadonlyREST free and Enterprise plugins integrate with Active Directory Federation Services (AD FS) to provide SAML authentication. In this tutorial, you will learn how to: Provision Azure Virtual Machines to host Active Directory, Elasticsearch, and Kibana Install and configure Active Directory (AD) Services Provision sample AD users Install and configure Active Directory Certificate Services (AD CS) Install and configure Active Directory Federation Services (AD FS) Install and configure ElasticSearch and the ReadonlyREST Free Plugin Install and configure Kibana and the ReadonlyREST Enterprise Plugin","title":"Microsoft ADFS"},{"location":"examples/saml-sso/adfs/#provisioning-azure-virtual-machines-to-host-active-directory-elasticsearch-and-kibana","text":"Any Windows Server 2016 Virtual Machines (VM) can be used for this process; however, in this demonstration, the Microsoft Azure environment will be used to provision and host the VMs. You can name your VMs whatever you would like. This article will refer to the names listed below for consistency. Virtual Machine 1: lc-win2019-02 Roles : Active Directory, AD Certificate Services, AD Federation Services, DNS Memory : 4GB Virtual Machine 2: lc-win2019-03 Roles : Elasticsearch, Kibana Memory : 8GB These Azure VMs will be Pay-As-You-Go and Spot Instances for affordability. The example shown below is for the Elasticsearch and Kibana VM which will be duplicated for the Active Directory VM but will have 4GBs of memory instead of 8GB. Please note that Azure Spot Instances cannot be resized after creation.","title":"Provisioning Azure Virtual Machines to Host Active Directory, Elasticsearch, and Kibana"},{"location":"examples/saml-sso/adfs/#provisioning-virtual-machines","text":"Log into the Azure portal using a Pay-As-You-Go subscription. Create a new virtual machine. If you do not already have a resource group created to serve as a home for the VMs, select Create new and create the resource group. Name your virtual machine appropriately, and choose the details for your instance, as shown in the example below. You can use the default hard drive sizes and Standard HDD disks for this environment. The default Networking options will also work here. As will the default Management options. No additional Advanced options are necessary. If you would like to tag your VMs for later categorization and tracking, you can do so here. Finally, create the VM. After this VM has been created, create one more to host the Active Directory and related services. In the end, you should have two VMs as outlined above.","title":"Provisioning Virtual Machines"},{"location":"examples/saml-sso/adfs/#installing-and-configuring-active-directory-ad-services","text":"After the two VMs have been provisioned, the next step is to set up directory services on the first VM, lc-win2019-02.","title":"Installing and Configuring Active Directory (AD) Services"},{"location":"examples/saml-sso/adfs/#installing-active-directory-services","text":"Once you are logged into lc-win2019-02, choose Add Roles and Features on the Server Manager screen. Select Role-based or feature-based installation . Select the correct server from the server pool. Select Active Directory Domain Services, and add the additional features as prompted. No additional features are necessary since the default options work. Click Next on the Active Directory Domain Services informational screen. Finally, select Restart the destination server automatically if required . Click Yes when prompted, and then click Install. Once installation has finished, click on Close.","title":"Installing Active Directory Services"},{"location":"examples/saml-sso/adfs/#configuring-active-directory-services","text":"If DNS has not been installed already, the role installation screen may pop up in the middle of the Active Directory installation. Installation instructions for the DNS role are shown after the Configuring Active Directory Services section below. Click on Promote this server to a domain controller, which will allow you to see the Deployment Configuration screen. Name the domain. In this case, use ad.lc-test.local. This name was arbitrarily chosen. Using a subdomain such as \u201cad\u201d instead of your actual domain (i.e., [lc-test.local]( http://lc-test.local\\ is recommended. Select Windows Server 2016 as the functional level . For the domain controller capabilities , choose Domain Name System (DNS) server . Set a Directory Services Restore Mode (DSRM) password. The following DNS Options warning message can be disregarded: Set the NetBIOS domain name , which is usually the short name prior to the host name (e.g., AD), and click Next. Use the default paths, and click on Next. On the Review Options screen, click Next if everything looks correct. On the Prerequisites Check screen, click Install. You\u2019ll see a number of warnings related to the fact that this is a test environment. They can be safely ignored. When you click Close , you will have a successful configuration. Click Close on the restart prompt.","title":"Configuring Active Directory Services"},{"location":"examples/saml-sso/adfs/#configuring-the-domain-name-services-dns-role","text":"Click on the DNS Services role, add the additional features as requested, and click Next. If you are using DHCP for the server (this is not recommended for a production service), then you will see the validation warning shown below. It can be disregarded. Click on Continue and Install. Click Next on the Features screen, since no additional features are necessary. Click Next on the informational DNS Server screen. Click Install on the Confirmation screen. Select Restart the destination server automatically if required, and click Install. Finally, click Close, and you will have a successful installation.","title":"Configuring the Domain Name Services (DNS) Role"},{"location":"examples/saml-sso/adfs/#joining-computers-to-the-domain","text":"Next we need to join the second server\u2014the one hosting Elasticsearch and Kibana\u2014to the domain. Open an RDP connection to the second server. Then, open Notepad as an Administrator, and open the file C:\\Windows\\System32\\drivers\\etc\\hosts. Add the IP address and hostnames for the domain controller. These will reflect the IP addresses and hostnames you chose for your configuration: FQDN : 10.0.0.5 - ad.lc-test.local NetBIOS : 10.0.0.5 - ad Additionally, you will need to change your network adapter DNS to point to your domain server; in this case, it is 10.0.0.5. If the system restarted, open an RDP connection, and then open the System screen under the Control Pane and select Advanced System settings. Click on Change to add this server to the domain. Enter the domain (e.g., ad.lc-test.local). Click on OK, and enter the credentials of the account that has privileges enabling it to add the domain. Restart the server after joining it to the domain.","title":"Joining Computers to the Domain"},{"location":"examples/saml-sso/adfs/#provisioning-sample-ad-users","text":"For testing purposes, it can be useful to provision additional users within the Active Directory. The following PowerShell script, which should be run on the domain controller, will make this easy. Note that we are setting the mail attribute which will be used for the SAML username. Import-Module -Name 'ActiveDirectory' $Domain = 'ad.lc-test.local'\\ $OU = 'CN=Users,DC=ad,DC=lc-test,DC=local' $Users = @{\\ \"TestUser1\" = \"testPass1\"\\ \"TestUser2\" = \"testPass2\"\\ \"TestUser3\" = \"testPass3\"\\ \"TestUser4\" = \"testPass4\"\\ \"TestUser5\" = \"testPass5\"\\ } $Users.GetEnumerator() | ForEach-Object {\\ $Name = $_.Key\\ $Password = $_.Value $Params = @{\\ \"Name\" = $Name\\ \"Path\" = $OU\\ \"AccountPassword\" = (ConvertTo-SecureString -AsPlainText $Password -Force)\\ \"Enabled\" = $True\\ \"DisplayName\" = $Name\\ \"PasswordNeverExpires\" = $True\\ \"CannotChangePassword\" = $True\\ \"EmailAddres\" = \"$Name@$Domain\"\\ } New-ADUser @Params\\ }","title":"Provisioning Sample AD Users"},{"location":"examples/saml-sso/adfs/#installing-active-directory-certificate-services-ad-cs","text":"Click on Active Directory Certificate Services, and add the additional features as prompted. Since no additional features are necessary, allow defaults, and click on Next. On the Active Directory Certificate Services informational screen, click Next to continue. Select the Certification Authority role services, and click Next. Select Restart the destination server automatically if required, and click on Install. Finally, click on Close when the installation has been completed.","title":"Installing Active Directory Certificate Services (AD CS)"},{"location":"examples/saml-sso/adfs/#configuring-active-directory-certificate-services","text":"Click on Configure Active Directory Certificate Services. Select the default administrative user for AD CS credentials. Under Role Services , check Certification Authority, and click Next. Select Enterprise CA, and click on Next. Click on Root CA , then click on Next. Click on Create a new private key, and then click on Next. Select RSA#Microsoft Software Key Storage Provider , a default key length of 2048 , and a hash algorithm of SHA256. Click Next. Use the defaults given for the CA Name, and click on Next. Select a validity period of 5 years, and click on Next. Leave the default database locations in place, and click on Next. Click on Configure and Close when the configuration process has been completed.","title":"Configuring Active Directory Certificate Services"},{"location":"examples/saml-sso/adfs/#installing-and-configuring-active-directory-federation-services-ad-fs","text":"Previously, it was recommended that AD FS should not be installed on the same server as the DC because IIS was installed as part of that process. As of 2012, this recommendation has changed, since AD FS does not use IIS anymore. Now, mounting AD FS and DC on the same server is advised for domains under 1000 users.","title":"Installing and Configuring Active Directory Federation Services (AD FS)"},{"location":"examples/saml-sso/adfs/#provisioning-ssl-certificate-templates","text":"Open the Certification Authority MMC snapin, right-click on Certificate Templates, and click on Manage. Select Duplicate Template on the Web Server template. Enter \u201cSSL Certificates\u201d in the box labeled Template display name on the General tab. On the Security tab, click on Enroll and Allow for Authenticated Users, and, finally, Apply the configuration. Right-click on Certificate Templates \u2192 New \u2192 Certificate Template to Issue. Select SSL Certificates from the Certificate Template list, and click OK.","title":"Provisioning SSL Certificate Templates"},{"location":"examples/saml-sso/adfs/#provisioning-the-ssl-certificate","text":"Open the Certificates MMC snapin for the Local Computer. Navigate to Personal \u2192 Certificates, and right-click to open All Tasks \u2192 Request New Certificate. Click Next on the Before you Begin screen. Click Next on the Select Certificate Enrollment Policy screen. Select SSL Certificates, and click on More information is required to enroll for this certificate. Select Click here to configure settings to configure the certificate. Add the following details on the Certificate Properties Subject screen, then click OK : Subject Name Common Name : CN=lc-win2019-02.ad.lc-test.local Alternative Name DNS : lc-win2019-02.ad.lc-test.local DNS : enterpriseregistration.ad.lc-test.local Click on Enroll to request the certificate, then click Finish .","title":"Provisioning the SSL Certificate"},{"location":"examples/saml-sso/adfs/#setting-up-active-directory-federation-services","text":"Select the Active Directory Federation Services role, and click Next. Click Next on Select Features , since no additional features are needed. Click Next on the Active Directory Federation Services informational screen. Check Restart the destination server automatically if required, and click Install and Close when the installation has completed.","title":"Setting up Active Directory Federation Services"},{"location":"examples/saml-sso/adfs/#creating-a-group-managed-service-account-and-adding-a-kds-key","text":"It is best to use a gMSA (group Managed Service Account) instead of a traditional sMSA (standalone Managed Service Account). The primary difference between the two is that, in a gMSA, the Windows operating system manages the password for the account instead of relying on the administrator to do it. Before we can select the gMSA, however, we need to add a KDS Root Key . To avoid non-blocking warnings later in the process, this key should be added with an effective date of 10 hours prior to the current date and time. Open a PowerShell session as an Administrator, and run the following command to add the KDS root key: Add-KdsRootKey -EffectiveTime ((Get-Date).AddHours(-10)) If you do not take this step, you will see the following error when attempting to add the gMSA account: To create a gMSA account to use with the AD FS service, use the PowerShell script provided below. If you get an \u201caccess denied\u201d error when running Install-ADServiceAccount, you may need to restart the server first. $Name = 'sa_adfs' $Params = @{\\ \"Name\" = $Name\\ \"DNSHostName\" = 'lc-win2019-02.ad.lc-test.local'\\ \"PrincipalsAllowedToRetrieveManagedPassword\" = 'lc-win2019-02$'\\ \"ServicePrincipalNames\" = 'http/lc-win2019-02.ad.lc-test.local'\\ } $ServiceAccount = New-ADServiceAccount @Params Install-ADServiceAccount -Identity $Name Add-ADComputerServiceAccount -Identity 'lc-win2019-02' -ServiceAccount $ServiceAccount","title":"Creating a Group Managed Service Account and Adding a KDS Key"},{"location":"examples/saml-sso/adfs/#configuring-federation-services","text":"Click on the link that says Configure the federation service on this server . Select Create the first federation server in a federation server farm, and click Next. On the Connect to Active Directory Domain Services screen, leave the default user selected, then click on Next . Select the previously created SSL Certificate, and enter \u201cLC Test\u201d for the Federation Service Display Name. Click Next. On the Specify Service Account screen, click on Select to use an existing account and locate the sa_adfs service account that was previously created. Click Next. Select Create a database on this server using Windows Internal Database, and click Next . Click on Next under Review Options. Verify the Pre-requisite Checks, and click on Configure. Click on Close, and restart the server. The warnings shown below can be disregarded for this test instance: Once the server has restarted, open an Administrative PowerShell session, and run the following command to enable the IdP Signon Page: Set-ADFSProperties -EnableIdPInitiatedSignonPage $True Verify that AD FS metadata is being returned by navigating to the following URL: https://{FQDN of AD FS Server}/adfs/fs/federationserverservice.asmx","title":"Configuring Federation Services"},{"location":"examples/saml-sso/adfs/#setting-up-readonlyrest-relying-trust","text":"Open the AD FS MMC snapin, right-click on the Relying Party Trusts folder, and select Add Relying Party Trust. Select Claims aware, and click Start. Choose Enter data about the relying party manually, and click Next. Enter a Display Name (in this case, \u201cror\u201d), and click Next. It\u2019s not necessary to specify a token encryption certificate, so click Next to continue. Select the option Enable support for the SAML 2.0 SSL service URL, and enter: https://{IP Address of Kibana Server}:5601/ror_kbn_sso_saml_adfs/assert The saml_adfs will change depending on the name chosen in the configuration of the kibana.yml file. Enter the Relying party trust identifiers , in this case, \u201cror.\u201d This will match the Issuer in the Kibana configuration. Click Next when you are done with this step. On the Access Control Policy screen, select Permit everyone, and click Next. Click Next to finish adding the trust. Verify that Configure claims insurance policy for this application is selected, and click on Close.","title":"Setting Up ReadonlyREST Relying Trust"},{"location":"examples/saml-sso/adfs/#configuring-claims","text":"Though we have not yet configured claims for Kibana, the metadata for the SAML configuration in Kibana would look similar to the following, if you were able to view it: The important section to note concerns the claims issuance policy. We need to return a NameID format in the form of an emailAddress by entering the following code : \\ \\ urn:oasis:names:tc:SAML:1.1:nameid-format:emailAddress\\ \\ Therefore, we need two rules: one to pull back the LDAP attribute from the Active Directory, and another to transform that data into the correct format. Click on Add Rule on the Edit Claim Issuance Policy for ror screen. For the first rule, choose Send LDAP Attributes as Claims, and click Next. Choose the AD Attribute to return\u2014in this case, the email address\u2014and click Finish on the Configure Rule screen of the Add Transform Claim Rule Wizard. Claim rule name : LDAP Email Active Store : Active Directory LDAP Attribute : E-Mail-Addresses Outgoing Claim Type : E-Mail Address Click on Add Rule, then choose the Transform an Incoming Claim claim rule template, and click on Next. Enter the transformation details as listed below, and, on the Edit Rule screen, click on OK. Claim rule name : Email Transform Incoming claim type : E-Mail Address Outgoing claim type : Name ID Outgoing name ID format : Email Pass through all claim values : Selected Click OK to save the rules. Please note that the order of the rules on the Edit Claim Issuance Policy screen is important.","title":"Configuring Claims"},{"location":"examples/saml-sso/adfs/#updating-relying-party-trusts","text":"Navigate to the Relying Party Trusts folder, right-click on the ror trust, and select Properties. Click on the Endpoints tab, select the SAML Assertion Consumer Endpoints, and click on Edit. Click on Set the trusted URL as default, and change the Index to 1 from 0. Click OK. On the Endpoints screen, click on Add SAML, and enter the SAML Logout details as follows: Endpoint Type : SAML Logout Binding : POST Trusted URL : https://{IP Address of Kibana Server}:5601/ror_kbn_sso_saml_adfs/notifylogout Click on OK to save the modified properties.","title":"Updating Relying Party Trusts"},{"location":"examples/saml-sso/adfs/#installing-and-configuring-elasticsearch-and-the-readonlyrest-free-plugin","text":"","title":"Installing and Configuring Elasticsearch and the ReadonlyREST Free Plugin"},{"location":"examples/saml-sso/adfs/#installing-elasticsearch","text":"Elasticsearch will be installed on the lc-win2019-03 server provisioned with 8GB of RAM in Azure. Locate a recent download of Elasticsearch , and install the MSI package. At the time this article was written, the most recent version available was 7.6.2; however, you may want to check for more updated versions as they become available. Launch the downloaded installer and click Next on the Locations screen, leaving the defaults in place. Use the defaults on the Service screen, and click Next. Use the defaults on the Configuration screen, and click Next. No additional plugins are necessary; therefore, click Next. Leave the X-Pack licenses set to Basic, and click on Install. Click on Exit.","title":"Installing Elasticsearch"},{"location":"examples/saml-sso/adfs/#installing-the-elasticsearch-plugin","text":"Navigate to the ReadonlyREST Plugin download page to enter your details. You will receive the download link in your email. Make sure to choose the Free Elasticsearch Plugin that matches your Elasticstack version. Download the plugin, open an Administrative command prompt, and navigate to the Elasticsearch program directory. Run the plugin installation by entering the following: cd \"C:\\Program Files\\Elastic\\ElasticSearch\\7.6.2\\bin\" elasticsearch-plugin.bat install file:///C:/Users/lc-admin.AD/Downloads/readonlyrest-1.19.4_es7.6.2.zip 5. 6. Navigate to the C:\\ProgramData\\Elastic\\ElasticSearch\\config directory, and create the file readonlyrest.yml. 7. 8. Open the readonlyrest.yml file in Notepad to run this very basic configuration that configures the following two different access control rules: 1. \u201c ::KIBANA-SRV:: \u201d \u2014this rule allows the Kibana server to authenticate to Elasticsearch using digest authentication with the username \u201ckibana\u201d and password \u201ckibana.\u201d 2. \u201cADFS Users\u201d\u2014this rule uses the ror_kbn_auth method which allows SAML authenticates to succeed. 9. Create a random 256-character signature_key. This key will be shared between Kibana and Elasticsearch. 10. Please note that the kbn1 identifier must match in the ror_kbn_auth and ror_kbn sections; however, any names can be used for them. ``` readonlyrest: access_control_rules: name: \"::KIBANA-SRV::\" auth_key: kibana:kibana name: \"ADFS Users\" ror_kbn_auth: name: \"kbn1\" ror_kbn: - name: kbn1 signature_key: \"VEGj@YLLhsAigspnNi2Xsopsqja_nrKUqU__eQW9VQ2!9p!RoeHwc-G.y-MVJtYYcDFCH.e3W2BKcZsoynJaHyjjXyh7kDHjsYKPkczvai-xCzP@Ez3QW23ZBFuReA7kPAqnc6pQ3VeNeFf3sWNoKeJAt_d9J7aFwEvCP2Gb-kQcA8YR wNWHQuo-jwmmo2Qqpu_Fq3aKFCbNFWUbK@BVwmmKezxn3h687mAkuyhV4.hnfrjVjF-Rphjqmy4.tB8\" ``` 11. Restart Elasticsearch Windows Service . This can be done in the Services * MMC snapin.","title":"Installing the Elasticsearch Plugin"},{"location":"examples/saml-sso/adfs/#installing-and-configuring-kibana-and-the-readonlyrest-enterprise-plugin","text":"","title":"Installing and Configuring Kibana and the ReadonlyREST Enterprise Plugin"},{"location":"examples/saml-sso/adfs/#installing-kibana","text":"Locate a recent download of Kibana , and download the zip package. At the time this article was written, the most recent version was 7.6.2. You may want to check for more updated links as they become available. Extract the Kibana installation. Note that this is a rather large file. If you have trouble with the default Windows zip extractor, you may want to try a tool such as 7-Zip. Move the extracted folder to C:\\kibana. This may require you to rename the folder. Open an administrative command prompt, and navigate to the Kibana directory to run the kibana.bat batch file and start Kibana. Once Kibana has started, navigate to [ http://localhost:5601](http://localhost:5601\\ to verify that Kibana is functional.","title":"Installing Kibana"},{"location":"examples/saml-sso/adfs/#creating-a-self-signed-certificate-for-kibana","text":"It is necessary to make Kibana operate under SSL for AD FS to perform SAML authentication. The easiest way to generate a self-signed certificate using the required format is to use OpenSSL . A Windows version of this tool available for download is located here . If Microsoft Visual C++ 2017 Redistributables (64-bit) is not already installed, click Yes to download the installation and run the installer first. Accept the license agreement, and click on Install. Back on the OpenSSL installation, click on I accept the agreement , then click on Next. Click Next on the Destination Location screen. Click Next on the Select Start Menu Folder screen. Select The Windows system directory on the Additional Tasks screen, and click Next. Click on Install. Click on Finish. Open an administrative command prompt, and run the following command to create the certificates in the specific X509 PEM format that Kibana requires: \"C:\\Program Files\\OpenSSL-Win64\\bin\\openssl.exe\" req -x509 -sha256 -nodes -days 730 -newkey rsa:2048 -keyout localhost-key.pem -out localhost.pem -subj \"/C=US/ST=IL/L=Bloomington/O=lc-test/CN=10.0.0.6\" 19. Change the subj to one that is more indicative of your installation. Make sure the CN={IP Address} matches the accessible IP of your Elasticsearch/Kibana server. 20. 21. Locate the newly created pem certificates and copy them to C:\\kibana\\ssl_cert. 22. The ssl_cert directory will need to be created first. For our purposes here, it has been arbitrarily named. 23. 24. Restart Kibana by entering Ctrl-C in the running command prompt window and then re-running kibana.bat.","title":"Creating a Self-Signed Certificate for Kibana"},{"location":"examples/saml-sso/adfs/#installing-the-readonlyrest-enterprise-plugin","text":"Navigate to the ReadonlyREST Plugin download page to enter your details. You will get the download link in your email. Making sure to choose the Enterprise Kibana Plugin and match it with your Elasticstack version. The email that you receive will contain installation instructions. The link will be time-limited, as shown below. Navigate to C:\\kibana\\config, and locate the kibana.yml configuration file. Open the kibana.yml file in Notepad and update it with the following details: elasticsearch.username\u2014This field matches the first part (pre-colon) of the auth_key in the readonlyrest.yml Elasticsearch configuration file. elasticsearch.password\u2014This field matches the second part (post-colon) of the auth_key in the readonlyrest.yml Elasticsearch configuration file. elasticsearch.ssl.verificationMode\u2014Set the value to \u201ctrue\u201d to ignore SSL errors. This is useful when working in a test environment. xpack.security.enabled\u2014This must be disabled for ReadonlyREST to work. [server.host]( http://server.host\u2014By default, this will be [localhost]( http://localhost\\ ; but, we need to use a routable address, which, in this case, is the 10.0.0.6 IP of this server. server.ssl.enabled\u2014This is used to turn on SSL and respond to https. server.ssl.certificate\u2014This is the location of the public key certificate. server.ssl.key\u2014This is the location of the private key for the certificate. readonlyrest_kbn.logLevel\u2014The value is set to \u201cdebug\u201d to enable troubleshooting in the console. readonlyrest_kbn.clearSessionOnEvents\u2014This clears the session on a successful login event. readonlyrest_kbn.auth.signature_key\u2014This must match the 256-character value in the signature_key attribute of the readonlyrest.yml Elasticsearch configuration file. readonlyrest_kbn.auth.saml_adfs.buttonName\u2014This is the name of the login button on the login screen of Kibana. readonlyrest_kbn.auth.saml_adfs.enabled\u2014This enables the SAML SSO configuration. readonlyrest_kbn.auth.saml_adfs.type\u2014For AD FS, this must be \u201csaml.\u201d readonlyrest_kbn.auth.saml_adfs.issue \u2014This is the unique identifier that was defined in the AD FS Relying Party Trust configuration, in this case, \u201cror.\u201d readonlyrest_kbn.auth.saml_adfs.protocol\u2014AD FS requires https. readonlyrest_kbn.auth.saml_adfs.entryPoint\u2014This is the entry point for AD FS\u2014 https://{AD FS Server}/adfs/ls. readonlyrest_kbn.auth.saml_adfs.logoutUrl\u2014This is the logout call to AD FS\u2014 https://{AD FS Server}/adfs/ls?wa=wsignout1.0. readonlyrest_kbn.auth.saml_adfs.kibanaExternalHost\u2014This is the address and port without the protocol preceding (i.e., https). readonlyrest_kbn.auth.saml_adfs.usernameParameter\u2014This configuration is only doing authentication, and it must match the nameID parameter.","title":"Installing the ReadonlyREST Enterprise Plugin"},{"location":"examples/saml-sso/adfs/#opening-the-firewall-port","text":"To allow the AD FS server to talk to Kibana, we need to open the 5601 port on the Kibana server since [localhost]( http://localhost\\ is not routable. Open the Windows Firewall with Advanced Security screen, and add a new rule under Inbound Rules. Choose Port. Add the specific local port of 5601, and click Next. Select Allow the connection, and click Next. Choose all profiles (the default), and click Next. Name the rule \u201cKibana,\u201d and click Finish.","title":"Opening the Firewall Port"},{"location":"examples/saml-sso/adfs/#demonstration","text":"Navigate to your Kibana URL ( https://10.0.0.6:5601\\ using Chrome or Firefox. Do not use IE or the SSO button may not show up. Click on ADFS, the button configured in the kibana.yml file, and log in with one of the created AD users. Use the defined mail attribute on the AD account (an email address). With a successful login, the Kibana screen will appear, and you will see your SAML authenticated user in the lower right corner.","title":"Demonstration"},{"location":"examples/saml-sso/adfs/#conclusion","text":"ReadonlyREST combined with Elasticsearch and Kibana opens a world of advanced authentication and authorization options to you. Though only a basic configuration was outlined here, many more useful configuration options are available. You can find out more information about these advanced configurations in the ReadonlyREST documentation and in the ROR forums.","title":"Conclusion"},{"location":"examples/saml-sso/azure_ad/","text":"Microsoft Azure AD Azure Active Directory (Azure AD) is Microsoft\u2019s cloud-based identity and access management ( IAM ) service. And it can be used as a SAML Single Sign-On (SSO) [identity provider (IdP)]( https://en.wikipedia.org/wiki/Identity_provider_(SAML )) for a pool of exiting users to sign in and access resources in external service providers like ReadonlyREST Enterprise . With Azure AD, you can graphically manage users, groups, credentials and permissions. ReadonlyREST Enterprise for Kibana will collaborate with Azure AD to authenticate, grant permissions and access to tenancies for users that are entirely managed within Azure AD. In this guide, we are going to see how to configure Elasticsearch and Kibana with ReadonlyREST Enterprise to make use of Azure AD via the SAML protocol. The result will be a multi-user, optionally multi-tenant Kibana instance powered by ReadonlyREST . Install Elasticsearch and Kibana Make sure you have a functioning installation of Kibana, backed by an instance of Elasticsearch. You can find the installation guide in Elastic's website. Set up the ReadonlyREST plugins In order to use ReadonlyREST Enterprise for Kibana, make sure you have installed ReadonlyREST Free for Elasticsearch first. Head to our setup guide to find instructions. Once ReadonlyREST Free plugin is installed, configure an ACL for accepting SAML sessions from ReadonlyREST Enterprise for Kibana. This is also explained in our guide . Remember to choose a very long secret phrase (256+ characters) Now head to the Kibana directory, and install a trial (or full) version of ReadonlyREST Enterprise, which can be freely downloaded from our download page . For installation instructions , see our Kibana plugin guide. Azure AD only speaks with \"https\" websites, so make sure your Kibana web server is configured to serve pages in https. See a guide from Elastic on how to enable SSL Conventions and assumptions in this guide This tutorial assumes that Kibana runs in https://localhost:5601 , which is clearly only valid if you are trying this authentication system in your local computer. And it also assumes you used something like mkcert to let your browser trust SSL certificates for localhost URLs. In the real world, when you are configuring Kibana in production, make sure: 1. You have a valid SSL certificate for the Kibana server 2. You replace all the references to localhost:5601 with the publicly reachable host name of your actual Kibana server. ReadonlyREST Configuration Now, on the Elasticsearch side , you should have the $ES_HOME/config/readonlyrest.yml file configured to accept SAML sessions from kibana using the ror_kbn_auth rule. I.e. readonlyrest: access_control_rules: - name: \"::KIBANA-SRV::\" auth_key: kibana:kibana ... all usual blocks of rules... - name: \"ReadonlyREST Enterprise sessions\" ror_kbn_auth: name: \"kbn1\" ror_kbn: - name: kbn1 signature_key: \"my_shared_secret_kibana1_(min 256 chars)\" # <- use environmental variables for better security! On the Kibana side , we will now configure our Kibana plugin to speak with Azure AD. Open your $KBN_HOME/config/kibana.yml , it should look something like: xpack.security.enabled: false elasticsearch.hosts: [\"http://localhost:9200\"] # <-- consider enabling \"https\" using the SSL feature in ReadonlyREST Free! elasticsearch.username: \"kibana\" elasticsearch.password: \"kibana\" # elasticsearch.ssl.verificationMode: none # <-- uncomment if your Elasticsearch uses \"https\" with self signed certificates server.ssl.enabled: true # <-- It's mandatory for Azure AD that we enable SSL in our Kibana server! server.ssl.certificate: '/etc/kibana/ssl_cert/localhost.pem' server.ssl.key: '/etc/kibana/ssl_cert/localhost-key.pem' readonlyrest_kbn: logLevel: debug clearSessionOnEvents: [\"login\"] auth: signature_key: \"my_shared_secret_kibana1_(min 256 chars)\" # <- use environmental variables for better security! saml_azure: buttonName: 'Azure AD SAML SSO' enabled: true type: saml issuer: 'ror' protocol: 'https' cert: '/etc/kibana/config/cert.pem' # <-- will download later from Azure enterprise app dashboard entryPoint: 'https://login.microsoftonline.com/xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx/saml2' kibanaExternalHost: 'localhost:5601' usernameParameter: 'http://schemas.microsoft.com/identity/claims/displayname' groupsParameter: 'http://schemas.microsoft.com/ws/2008/06/identity/claims/groups' Notes about ReadonlyREST Kibana settings The issuer parameter is important and should be ideantical to what you wrote in the field (1) Basic SAML Configuration - Identifier (Entity ID) in the Azure AD settings. The entryPoint value should be copied from the field (4) Set up ReadonlyREST Enterprise > Login URL in Azure AD settings. The kibanaExternalHost only accepts the browser facing hostname (or IP address) and optionally the port of our Kibana server. Do not put any \"https://\" prefix here. The cert is an absolute path to the base64 version of the certificate ReadonlyREST Enterprise will use to verify the signature of the SAML assertion coming from Azure AD. This file can be downloaded from : (3) SAML Signing Certificate > Certificate (Base64) The groupsParameter and usernameParameter values represent the JSON fields names from the SAML assertion object coming from Azure AD. They represent the field names we take the username and groups information from. An example of SAML assertion object coming from Azure AD after successful authentication looks like so: { \"http://schemas.microsoft.com/claims/authnmethodsreferences\": \"urn:oasis:names:tc:SAML:2.0:ac:classes:PasswordProtectedTransport\", \"http://schemas.microsoft.com/identity/claims/displayname\": \"Simone Scarduzio\", \"http://schemas.microsoft.com/identity/claims/identityprovider\": \"https://sts.windows.net/88af1572-1347-45b6-8f65-xxxxxxxxx/\", \"http://schemas.microsoft.com/identity/claims/objectidentifier\": \"486abf50-a61f-40e9-8a37-3ff6a6eeda26\", \"http://schemas.microsoft.com/identity/claims/tenantid\": \"88af1572-1347-45b6-8f65-xxxxxxxxxxxx\", \"http://schemas.microsoft.com/ws/2008/06/identity/claims/groups\": [ \"00f22de3-0d59-4867-8e1a-xxxxxxxxxxxx\", \"dbe4ff5a-deba-419f-a653-xxxxxxxxxxxx\", \"3c19b288-263c-4dd1-9947-xxxxxxxxxxxx\" ], \"http://schemas.microsoft.com/ws/2008/06/identity/claims/wids\": \"62e90394-69f5-4237-9190-xxxxxxxxxxxx\", \"http://schemas.xmlsoap.org/ws/2005/05/identity/claims/givenname\": \"Simone\", \"http://schemas.xmlsoap.org/ws/2005/05/identity/claims/name\": \"Simone@ror-enterprise-test.com\", \"http://schemas.xmlsoap.org/ws/2005/05/identity/claims/surname\": \"Scarduzio\", \"issuer\": \"https://sts.windows.net/88af1572-1347-45b6-8f65-xxxxxxxxxxxx/\", \"nameID\": \"Simone@ror-enterprise-test.com\", \"nameIDFormat\": \"urn:oasis:names:tc:SAML:1.1:nameid-format:emailAddress\", \"sessionIndex\": \"_97f290ee-2ff6-445f-a0c6-xxxxxxxxxxxx\", \"user\": \"Simone Scarduzio\" } Azure AD configuration Login in your Microsoft Azure dashboard, and head to Enterprise Applications. Click on \"Non-gallery application\". Create a new app called \"Readonlyrest Enterprise\". Click \"Single Sign On\" to configure the app for SAML. Insert URLs and data about our Kibana server as shown in the picture. And press SAVE. Download the base64 encoded \"pem\" file, and place it under the absolute path /etc/kibana/config/cert.pem . 7 Make sure this app has at least a test user assigned, and press SAVE. Otherwise the single sign-on will fail. Testing if this all works. Now point your browser to your Kibana installation (in the example https://localhost:5601 ). You should now see a new blue button that says \"Azure AD SAML SSO\". Press it, and you should see the Azure AD login page. Place your credentials here, or pick an already authenticated identity to enter Kibana. You will now be redirected to Kibana, logged in as your Azure AD identity. You can now logout from the \"ReadonlyREST SAML SSO\" Azure AD Enterprise app by pressing the exit button right beside the username in the bottom right corner. Authorization using Azure AD groups Users in Azure AD can belong to groups. The list of group associated to a user is useful information for ReadonlyREST Enterprise for identifying sets of users that we want to authorize to: see certain indices perform certain actions over certain indices belong to a tenancy have read or read/write permission to a tenancy have administrative rights over ReadonlyREST cluster-wide security settings many more things, or even a combination of all these. Example: ReadonlyREST Admins group Suppose we would like to authorise the group \"ReadonlyREST Admins\" to access the administrative dashboard that can oversee all the indices, and we want to grant them access to an \"admin\" tenancy that contains dashboards based on the real time ReadonlyREST audit logs indices. Creating and assigning the group in Azure Ad Let's go to Azure and make sure the \"ReadonlyREST Admins\" group is created, and one or more users - including ours - belongs to it. Finding the new group's Azure object ID From ReadonlyREST settings, we will refer to the newly created group using its associated object ID provided by Azure platform. To discover it, navigate the Azure AD dashboard to: Dashboard > Enterprise applications - All applications > ReadonlyREST Enterprise - Users and groups > [your user] - Groups The object ID of the new group is \"3f8ebed8-f742-42a6-94ba-2d57550fc3cf\", let's take note of this. We will use it in our ACL. Using ReadonlyREST ACL to authorize the group Let's head back to Elasticsearch, and open readonlyrest.yml . Let's now add the authorization. readonlyrest: access_control_rules: - name: \"::KIBANA-SRV::\" auth_key: kibana:kibana - name: \"Azure AD - ReadonlyREST Admins group\" kibana_index: \".kibana_admin_tenancy\" indices: [\".kibana_admin_tenancy\", \"readonlyrest-audit*\"] kibana_access: \"admin\" ror_kbn_auth: roles: [\"3f8ebed8-f742-42a6-94ba-2d57550fc3cf\"] name: \"kbn1\" - name: \"Azure AD - Anyone else\" indices: [\".kibana_generic_tenancy\", \"readonlyrest-audit*\"] kibana_index: \".kibana_generic_tenancy\" kibana_access: \"rw\" kibana_hide_apps: [\"readonlyrest_kbn\"] ror_kbn_auth: name: \"kbn1\" ror_kbn: - name: kbn1 signature_key: \"my_shared_secret_kibana1_(min 256 chars)\" # <- use environmental variables for better security! Now we have two ACL blocks dedicated to Azure AD: one will match for users that belong to \"ReadonlyREST Admins\" (a.k.a object ID 3f8ebed8-f742-42a6-94ba-2d57550fc3cf ), the other will match for Azure AD users that do not belong to the group. The key here is the use of the roles option in the ror_kbn_auth rule, as an extra constraint so that the ACL block is only matched when the user has the \"3f8ebed8-f742-42a6-94ba-2d57550fc3cf\" string in the list of their groups.","title":"Microsoft Azure AD"},{"location":"examples/saml-sso/azure_ad/#microsoft-azure-ad","text":"Azure Active Directory (Azure AD) is Microsoft\u2019s cloud-based identity and access management ( IAM ) service. And it can be used as a SAML Single Sign-On (SSO) [identity provider (IdP)]( https://en.wikipedia.org/wiki/Identity_provider_(SAML )) for a pool of exiting users to sign in and access resources in external service providers like ReadonlyREST Enterprise . With Azure AD, you can graphically manage users, groups, credentials and permissions. ReadonlyREST Enterprise for Kibana will collaborate with Azure AD to authenticate, grant permissions and access to tenancies for users that are entirely managed within Azure AD. In this guide, we are going to see how to configure Elasticsearch and Kibana with ReadonlyREST Enterprise to make use of Azure AD via the SAML protocol. The result will be a multi-user, optionally multi-tenant Kibana instance powered by ReadonlyREST .","title":"Microsoft Azure AD"},{"location":"examples/saml-sso/azure_ad/#install-elasticsearch-and-kibana","text":"Make sure you have a functioning installation of Kibana, backed by an instance of Elasticsearch. You can find the installation guide in Elastic's website.","title":"Install Elasticsearch and Kibana"},{"location":"examples/saml-sso/azure_ad/#set-up-the-readonlyrest-plugins","text":"In order to use ReadonlyREST Enterprise for Kibana, make sure you have installed ReadonlyREST Free for Elasticsearch first. Head to our setup guide to find instructions. Once ReadonlyREST Free plugin is installed, configure an ACL for accepting SAML sessions from ReadonlyREST Enterprise for Kibana. This is also explained in our guide . Remember to choose a very long secret phrase (256+ characters) Now head to the Kibana directory, and install a trial (or full) version of ReadonlyREST Enterprise, which can be freely downloaded from our download page . For installation instructions , see our Kibana plugin guide. Azure AD only speaks with \"https\" websites, so make sure your Kibana web server is configured to serve pages in https. See a guide from Elastic on how to enable SSL","title":"Set up the ReadonlyREST plugins"},{"location":"examples/saml-sso/azure_ad/#conventions-and-assumptions-in-this-guide","text":"This tutorial assumes that Kibana runs in https://localhost:5601 , which is clearly only valid if you are trying this authentication system in your local computer. And it also assumes you used something like mkcert to let your browser trust SSL certificates for localhost URLs. In the real world, when you are configuring Kibana in production, make sure: 1. You have a valid SSL certificate for the Kibana server 2. You replace all the references to localhost:5601 with the publicly reachable host name of your actual Kibana server.","title":"Conventions and assumptions in this guide"},{"location":"examples/saml-sso/azure_ad/#readonlyrest-configuration","text":"Now, on the Elasticsearch side , you should have the $ES_HOME/config/readonlyrest.yml file configured to accept SAML sessions from kibana using the ror_kbn_auth rule. I.e. readonlyrest: access_control_rules: - name: \"::KIBANA-SRV::\" auth_key: kibana:kibana ... all usual blocks of rules... - name: \"ReadonlyREST Enterprise sessions\" ror_kbn_auth: name: \"kbn1\" ror_kbn: - name: kbn1 signature_key: \"my_shared_secret_kibana1_(min 256 chars)\" # <- use environmental variables for better security! On the Kibana side , we will now configure our Kibana plugin to speak with Azure AD. Open your $KBN_HOME/config/kibana.yml , it should look something like: xpack.security.enabled: false elasticsearch.hosts: [\"http://localhost:9200\"] # <-- consider enabling \"https\" using the SSL feature in ReadonlyREST Free! elasticsearch.username: \"kibana\" elasticsearch.password: \"kibana\" # elasticsearch.ssl.verificationMode: none # <-- uncomment if your Elasticsearch uses \"https\" with self signed certificates server.ssl.enabled: true # <-- It's mandatory for Azure AD that we enable SSL in our Kibana server! server.ssl.certificate: '/etc/kibana/ssl_cert/localhost.pem' server.ssl.key: '/etc/kibana/ssl_cert/localhost-key.pem' readonlyrest_kbn: logLevel: debug clearSessionOnEvents: [\"login\"] auth: signature_key: \"my_shared_secret_kibana1_(min 256 chars)\" # <- use environmental variables for better security! saml_azure: buttonName: 'Azure AD SAML SSO' enabled: true type: saml issuer: 'ror' protocol: 'https' cert: '/etc/kibana/config/cert.pem' # <-- will download later from Azure enterprise app dashboard entryPoint: 'https://login.microsoftonline.com/xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx/saml2' kibanaExternalHost: 'localhost:5601' usernameParameter: 'http://schemas.microsoft.com/identity/claims/displayname' groupsParameter: 'http://schemas.microsoft.com/ws/2008/06/identity/claims/groups'","title":"ReadonlyREST Configuration"},{"location":"examples/saml-sso/azure_ad/#notes-about-readonlyrest-kibana-settings","text":"The issuer parameter is important and should be ideantical to what you wrote in the field (1) Basic SAML Configuration - Identifier (Entity ID) in the Azure AD settings. The entryPoint value should be copied from the field (4) Set up ReadonlyREST Enterprise > Login URL in Azure AD settings. The kibanaExternalHost only accepts the browser facing hostname (or IP address) and optionally the port of our Kibana server. Do not put any \"https://\" prefix here. The cert is an absolute path to the base64 version of the certificate ReadonlyREST Enterprise will use to verify the signature of the SAML assertion coming from Azure AD. This file can be downloaded from : (3) SAML Signing Certificate > Certificate (Base64) The groupsParameter and usernameParameter values represent the JSON fields names from the SAML assertion object coming from Azure AD. They represent the field names we take the username and groups information from. An example of SAML assertion object coming from Azure AD after successful authentication looks like so: { \"http://schemas.microsoft.com/claims/authnmethodsreferences\": \"urn:oasis:names:tc:SAML:2.0:ac:classes:PasswordProtectedTransport\", \"http://schemas.microsoft.com/identity/claims/displayname\": \"Simone Scarduzio\", \"http://schemas.microsoft.com/identity/claims/identityprovider\": \"https://sts.windows.net/88af1572-1347-45b6-8f65-xxxxxxxxx/\", \"http://schemas.microsoft.com/identity/claims/objectidentifier\": \"486abf50-a61f-40e9-8a37-3ff6a6eeda26\", \"http://schemas.microsoft.com/identity/claims/tenantid\": \"88af1572-1347-45b6-8f65-xxxxxxxxxxxx\", \"http://schemas.microsoft.com/ws/2008/06/identity/claims/groups\": [ \"00f22de3-0d59-4867-8e1a-xxxxxxxxxxxx\", \"dbe4ff5a-deba-419f-a653-xxxxxxxxxxxx\", \"3c19b288-263c-4dd1-9947-xxxxxxxxxxxx\" ], \"http://schemas.microsoft.com/ws/2008/06/identity/claims/wids\": \"62e90394-69f5-4237-9190-xxxxxxxxxxxx\", \"http://schemas.xmlsoap.org/ws/2005/05/identity/claims/givenname\": \"Simone\", \"http://schemas.xmlsoap.org/ws/2005/05/identity/claims/name\": \"Simone@ror-enterprise-test.com\", \"http://schemas.xmlsoap.org/ws/2005/05/identity/claims/surname\": \"Scarduzio\", \"issuer\": \"https://sts.windows.net/88af1572-1347-45b6-8f65-xxxxxxxxxxxx/\", \"nameID\": \"Simone@ror-enterprise-test.com\", \"nameIDFormat\": \"urn:oasis:names:tc:SAML:1.1:nameid-format:emailAddress\", \"sessionIndex\": \"_97f290ee-2ff6-445f-a0c6-xxxxxxxxxxxx\", \"user\": \"Simone Scarduzio\" }","title":"Notes about ReadonlyREST Kibana settings"},{"location":"examples/saml-sso/azure_ad/#azure-ad-configuration","text":"Login in your Microsoft Azure dashboard, and head to Enterprise Applications. Click on \"Non-gallery application\". Create a new app called \"Readonlyrest Enterprise\". Click \"Single Sign On\" to configure the app for SAML. Insert URLs and data about our Kibana server as shown in the picture. And press SAVE. Download the base64 encoded \"pem\" file, and place it under the absolute path /etc/kibana/config/cert.pem . 7 Make sure this app has at least a test user assigned, and press SAVE. Otherwise the single sign-on will fail.","title":"Azure AD configuration"},{"location":"examples/saml-sso/azure_ad/#testing-if-this-all-works","text":"Now point your browser to your Kibana installation (in the example https://localhost:5601 ). You should now see a new blue button that says \"Azure AD SAML SSO\". Press it, and you should see the Azure AD login page. Place your credentials here, or pick an already authenticated identity to enter Kibana. You will now be redirected to Kibana, logged in as your Azure AD identity. You can now logout from the \"ReadonlyREST SAML SSO\" Azure AD Enterprise app by pressing the exit button right beside the username in the bottom right corner.","title":"Testing if this all works."},{"location":"examples/saml-sso/azure_ad/#authorization-using-azure-ad-groups","text":"Users in Azure AD can belong to groups. The list of group associated to a user is useful information for ReadonlyREST Enterprise for identifying sets of users that we want to authorize to: see certain indices perform certain actions over certain indices belong to a tenancy have read or read/write permission to a tenancy have administrative rights over ReadonlyREST cluster-wide security settings many more things, or even a combination of all these.","title":"Authorization using Azure AD groups"},{"location":"examples/saml-sso/azure_ad/#example-readonlyrest-admins-group","text":"Suppose we would like to authorise the group \"ReadonlyREST Admins\" to access the administrative dashboard that can oversee all the indices, and we want to grant them access to an \"admin\" tenancy that contains dashboards based on the real time ReadonlyREST audit logs indices.","title":"Example: ReadonlyREST Admins group"},{"location":"examples/saml-sso/azure_ad/#creating-and-assigning-the-group-in-azure-ad","text":"Let's go to Azure and make sure the \"ReadonlyREST Admins\" group is created, and one or more users - including ours - belongs to it.","title":"Creating and assigning the group in Azure Ad"},{"location":"examples/saml-sso/azure_ad/#finding-the-new-groups-azure-object-id","text":"From ReadonlyREST settings, we will refer to the newly created group using its associated object ID provided by Azure platform. To discover it, navigate the Azure AD dashboard to: Dashboard > Enterprise applications - All applications > ReadonlyREST Enterprise - Users and groups > [your user] - Groups The object ID of the new group is \"3f8ebed8-f742-42a6-94ba-2d57550fc3cf\", let's take note of this. We will use it in our ACL.","title":"Finding the new group's Azure object ID"},{"location":"examples/saml-sso/azure_ad/#using-readonlyrest-acl-to-authorize-the-group","text":"Let's head back to Elasticsearch, and open readonlyrest.yml . Let's now add the authorization. readonlyrest: access_control_rules: - name: \"::KIBANA-SRV::\" auth_key: kibana:kibana - name: \"Azure AD - ReadonlyREST Admins group\" kibana_index: \".kibana_admin_tenancy\" indices: [\".kibana_admin_tenancy\", \"readonlyrest-audit*\"] kibana_access: \"admin\" ror_kbn_auth: roles: [\"3f8ebed8-f742-42a6-94ba-2d57550fc3cf\"] name: \"kbn1\" - name: \"Azure AD - Anyone else\" indices: [\".kibana_generic_tenancy\", \"readonlyrest-audit*\"] kibana_index: \".kibana_generic_tenancy\" kibana_access: \"rw\" kibana_hide_apps: [\"readonlyrest_kbn\"] ror_kbn_auth: name: \"kbn1\" ror_kbn: - name: kbn1 signature_key: \"my_shared_secret_kibana1_(min 256 chars)\" # <- use environmental variables for better security! Now we have two ACL blocks dedicated to Azure AD: one will match for users that belong to \"ReadonlyREST Admins\" (a.k.a object ID 3f8ebed8-f742-42a6-94ba-2d57550fc3cf ), the other will match for Azure AD users that do not belong to the group. The key here is the use of the roles option in the ror_kbn_auth rule, as an extra constraint so that the ACL block is only matched when the user has the \"3f8ebed8-f742-42a6-94ba-2d57550fc3cf\" string in the list of their groups.","title":"Using ReadonlyREST ACL to authorize the group"},{"location":"examples/saml-sso/keycloak_saml/","text":"Keycloak This document will guide you through the task of setting up an excellent, open source identity provider ( KeyCloak ) to work as an external authenticator and authorizer system for your ELK stack. The scenario is the usual: A centralised, large Elasticsearch cluster A Kibana installation We want one, centralised multi tenant Elasticsearch + Kibana But with some more enterprise requirements: Users need to be able to change their passwords independently Users need to verify their emails Group managers need to be able to add, remove, block (only) their users. Multi factor authentication (MFA) is a requirement. What is Keycloak Keycloak is an advanced authentication server that lets user administer their credentials, and speaks many authentication protocols, Including SAML2.0 SSO. Setup KeyCloak This tutorial was created using KeyCloak 8.0.1. Download the standalone version of Keycloak from their official website Run Keycloak: run bin/standalone.sh or equivalent for your platform. Navigate to http://localhost:8080 and configure the admin user's credentials don't forget to fill the email address! Login as admin Follow the explanation below, or (if your KC version is the same or close enough to this) use the import function to load this configuration file If you imported the JSON file, you should have a \"ror\" realm, and a SAML client called \"ror\" (keep this ID or change the \"issuer\" setting in kibana.yml) in the \"master\" realm. Please now select \"ror\" realm, navigate to \"clients\", click \"ror\" client and double check everything matches with your use case, as this guide assumes both Kibana, Elasticsearch and Keycloak are running on \"localhost\". Configure Keycloak to work with ROR First we want to create a new dedicated \"ror\" realm, so we don't interfere with any other use of this Keycloak installation. Then, let's create a SAML client for this realm: Then, configure the SAML client according to your Kibana URL, in this example, Kibana responds to \" https://localhost:5601/k \" Now that the client is saved, let's observe the \"configure\" tab, here we will extract the two logout and login endpoints that we will use for configuring our SAML connector in \"kibana.yml\". Install ReadonlyREST Enterprise for Kibana Please refer to our documentation on how to obtain and install ReadonlyREST Enterprise for Kibana. Also remember that it relies on the Elasticsearch plugin to be configured as well. Setup the SAML connector Provided that you have ReadonlyREST Enterprise installed configured, you can add the following configuration: kibana.yml # More on how to enable SSL on the official documentation of Kibana server.ssl.enabled: true server.ssl.key: /home/xx/selfsigned_ssl_localhost/localhost.key server.ssl.certificate: /home/xx/selfsigned_ssl_localhost/localhost.crt xpack.security.enabled: false server.basePath: /k # <-- optional, remember to change it in KC elasticsearch: hosts: [\"https://localhost:9200\"] # <-- our Elasticsearch responds to https ssl.verificationMode: none username: kibana password: kibana readonlyrest_kbn: logLevel: debug auth: # this secret string has to be longer than 256 chars, use environmental variables to fill it in maybe. signature_key: \"9yzBfnLaTYLfGPzyKW9es76RKYhUVgmuv6ZtehaScj5msGpBpa5FWpwk295uJYaaffTFnQC5tsknh2AguVDaTrqCLfM5zCTqdE4UGNL73h28Bg4dPrvTAFQyygQqv4xfgnevBED6VZYdfjXAQLc8J8ywaHQQSmprZqYCWGE6sM3vzNUEWWB3kmGrEKa4sGbXhmXZCvL6NDnEJhXPDJAzu9BMQxn8CzVLqrx6BxDgPYF8gZCxtyxMckXwCaYXrxAGbjkYH69F4wYhuAdHSWgRAQCuWwYmWCA6g39j4VPge5pv962XYvxwJpvn23Y5KvNZ5S5c6crdG4f4gTCXnU36x92fKMQzsQV9K4phcuNvMWkpqVB6xMA5aPzUeHcGytD93dG8D52P5BxsgaJJE6QqDrk3Y2vyLw9ZEbJhPRJxbuBKVCBtVx26Ldd46dq5eyyzmNEyQGLrjQ4qd978VtG8TNT5rkn4ETJQEju5HfCBbjm3urGLFVqxhGVawecT4YM9Rry4EqXWkRJGTFQWQRnweUFbKNbVTC9NxcXEp6K5rSPEy9trb5UYLYhhMJ9fWSBMuenGRjNSJxeurMRCaxPpNppBLFnp8qW5ezfHgCBpEjkSNNzP4uXMZFAXmdUfJ8XQdPTWuYfdHYc5TZWnzrdq9wcfFQRDpDB2zX5Myu96krDt9vA7wNKfYwkSczA6qUQV66jA8nV4Cs38cDAKVBXnxz22ddAVrPv8ajpu7hgBtULMURjvLt94Nc5FDKw79CTTQxffWEj9BJCDCpQnTufmT8xenywwVJvtj49yv2MP2mGECrVDRmcGUAYBKR8G6ZnFAYDVC9UhY46FGWDcyVX3HKwgtHeb45Ww7dsW8JdMnZYctaEU585GZmqTJp2LcAWRcQPH25JewnPX8pjzVpJNcy7avfA2bcU86bfASvQBDUCrhjgRmK2ECR6vzPwTsYKRgFrDqb62FeMdrKgJ9vKs435T5ACN7MNtdRXHQ4fj5pNpUMDW26Wd7tt9bkBTqEGf\" saml_kc: # <--- Our SAML connector name, used in the path configured in KC buttonName: \"KeyCloak SAML SSO\" enabled: true type: \"saml\" issuer: \"ror\" # <-- called exactly like the SAML client in KC entryPoint: \"http://localhost:8080/auth/realms/ror/protocol/saml\" # <-- from KC configuration tab! kibanaExternalHost: 'localhost:5601' protocol: \"https\" # <--- our Kibana responds to HTTPS usernameParameter: \"nameID\" groupsParameter: \"Role\" logoutUrl: \"http://localhost:8080/auth/realms/ror/protocol/saml\" # <-- from KC configuration tab! cert: /etc/ror/integration/certs/dag.crt # from KC realm keys tab <-- It can be also provided a string value You can find a public PEM-encoded X.509 signing certificate as a string value by selecting the \"keys\" tab in your newly created realm. After clicking on a cert button, you can copy the value into kibana.yml saml config cert parameter. Don't forget setting up SAML requires some changes to security settings in readonlyrest.yml (on the elasticsearch side). Security settings can also be changed via the ReadonlyREST Kibana app. Setup Elasticsearch with ReadonlyREST Our Elasticsearch needs to be available on https (more detailed info in our documentation ), so we modify the elasticsearch.yml append to elasticsearch.yml xpack.security.enabled: false http.type: ssl_netty4 # <-- needed for ROR SSL Write in readonlyrest.yml readonlyrest: ssl: enable: true keystore_file: \"keystore.jks\" keystore_pass: readonlyrest key_pass: readonlyrest prompt_for_basic_auth: false audit_collector: true access_control_rules: - name: \"::KIBANA-SRV::\" auth_key: kibana:kibana verbosity: error - name: \"ReadonlyREST Enterprise instance #1\" kibana_index: \".kibana_sso\" ror_kbn_auth: name: \"kbn1\" ror_kbn: - name: kbn1 # It has to be the same string as we declared in kibana.yml. signature_key: \"9yzBfnLaTYLfGPzyKW9es76RKYhUVgmuv6ZtehaScj5msGpBpa5FWpwk295uJYaaffTFnQC5tsknh2AguVDaTrqCLfM5zCTqdE4UGNL73h28Bg4dPrvTAFQyygQqv4xfgnevBED6VZYdfjXAQLc8J8ywaHQQSmprZqYCWGE6sM3vzNUEWWB3kmGrEKa4sGbXhmXZCvL6NDnEJhXPDJAzu9BMQxn8CzVLqrx6BxDgPYF8gZCxtyxMckXwCaYXrxAGbjkYH69F4wYhuAdHSWgRAQCuWwYmWCA6g39j4VPge5pv962XYvxwJpvn23Y5KvNZ5S5c6crdG4f4gTCXnU36x92fKMQzsQV9K4phcuNvMWkpqVB6xMA5aPzUeHcGytD93dG8D52P5BxsgaJJE6QqDrk3Y2vyLw9ZEbJhPRJxbuBKVCBtVx26Ldd46dq5eyyzmNEyQGLrjQ4qd978VtG8TNT5rkn4ETJQEju5HfCBbjm3urGLFVqxhGVawecT4YM9Rry4EqXWkRJGTFQWQRnweUFbKNbVTC9NxcXEp6K5rSPEy9trb5UYLYhhMJ9fWSBMuenGRjNSJxeurMRCaxPpNppBLFnp8qW5ezfHgCBpEjkSNNzP4uXMZFAXmdUfJ8XQdPTWuYfdHYc5TZWnzrdq9wcfFQRDpDB2zX5Myu96krDt9vA7wNKfYwkSczA6qUQV66jA8nV4Cs38cDAKVBXnxz22ddAVrPv8ajpu7hgBtULMURjvLt94Nc5FDKw79CTTQxffWEj9BJCDCpQnTufmT8xenywwVJvtj49yv2MP2mGECrVDRmcGUAYBKR8G6ZnFAYDVC9UhY46FGWDcyVX3HKwgtHeb45Ww7dsW8JdMnZYctaEU585GZmqTJp2LcAWRcQPH25JewnPX8pjzVpJNcy7avfA2bcU86bfASvQBDUCrhjgRmK2ECR6vzPwTsYKRgFrDqb62FeMdrKgJ9vKs435T5ACN7MNtdRXHQ4fj5pNpUMDW26Wd7tt9bkBTqEGf\"","title":"Keycloak"},{"location":"examples/saml-sso/keycloak_saml/#keycloak","text":"This document will guide you through the task of setting up an excellent, open source identity provider ( KeyCloak ) to work as an external authenticator and authorizer system for your ELK stack. The scenario is the usual: A centralised, large Elasticsearch cluster A Kibana installation We want one, centralised multi tenant Elasticsearch + Kibana But with some more enterprise requirements: Users need to be able to change their passwords independently Users need to verify their emails Group managers need to be able to add, remove, block (only) their users. Multi factor authentication (MFA) is a requirement.","title":"Keycloak"},{"location":"examples/saml-sso/keycloak_saml/#what-is-keycloak","text":"Keycloak is an advanced authentication server that lets user administer their credentials, and speaks many authentication protocols, Including SAML2.0 SSO.","title":"What is Keycloak"},{"location":"examples/saml-sso/keycloak_saml/#setup-keycloak","text":"This tutorial was created using KeyCloak 8.0.1. Download the standalone version of Keycloak from their official website Run Keycloak: run bin/standalone.sh or equivalent for your platform. Navigate to http://localhost:8080 and configure the admin user's credentials don't forget to fill the email address! Login as admin Follow the explanation below, or (if your KC version is the same or close enough to this) use the import function to load this configuration file If you imported the JSON file, you should have a \"ror\" realm, and a SAML client called \"ror\" (keep this ID or change the \"issuer\" setting in kibana.yml) in the \"master\" realm. Please now select \"ror\" realm, navigate to \"clients\", click \"ror\" client and double check everything matches with your use case, as this guide assumes both Kibana, Elasticsearch and Keycloak are running on \"localhost\".","title":"Setup KeyCloak"},{"location":"examples/saml-sso/keycloak_saml/#configure-keycloak-to-work-with-ror","text":"First we want to create a new dedicated \"ror\" realm, so we don't interfere with any other use of this Keycloak installation. Then, let's create a SAML client for this realm: Then, configure the SAML client according to your Kibana URL, in this example, Kibana responds to \" https://localhost:5601/k \" Now that the client is saved, let's observe the \"configure\" tab, here we will extract the two logout and login endpoints that we will use for configuring our SAML connector in \"kibana.yml\".","title":"Configure Keycloak to work with ROR"},{"location":"examples/saml-sso/keycloak_saml/#install-readonlyrest-enterprise-for-kibana","text":"Please refer to our documentation on how to obtain and install ReadonlyREST Enterprise for Kibana. Also remember that it relies on the Elasticsearch plugin to be configured as well.","title":"Install ReadonlyREST Enterprise for Kibana"},{"location":"examples/saml-sso/keycloak_saml/#setup-the-saml-connector","text":"Provided that you have ReadonlyREST Enterprise installed configured, you can add the following configuration: kibana.yml # More on how to enable SSL on the official documentation of Kibana server.ssl.enabled: true server.ssl.key: /home/xx/selfsigned_ssl_localhost/localhost.key server.ssl.certificate: /home/xx/selfsigned_ssl_localhost/localhost.crt xpack.security.enabled: false server.basePath: /k # <-- optional, remember to change it in KC elasticsearch: hosts: [\"https://localhost:9200\"] # <-- our Elasticsearch responds to https ssl.verificationMode: none username: kibana password: kibana readonlyrest_kbn: logLevel: debug auth: # this secret string has to be longer than 256 chars, use environmental variables to fill it in maybe. signature_key: \"9yzBfnLaTYLfGPzyKW9es76RKYhUVgmuv6ZtehaScj5msGpBpa5FWpwk295uJYaaffTFnQC5tsknh2AguVDaTrqCLfM5zCTqdE4UGNL73h28Bg4dPrvTAFQyygQqv4xfgnevBED6VZYdfjXAQLc8J8ywaHQQSmprZqYCWGE6sM3vzNUEWWB3kmGrEKa4sGbXhmXZCvL6NDnEJhXPDJAzu9BMQxn8CzVLqrx6BxDgPYF8gZCxtyxMckXwCaYXrxAGbjkYH69F4wYhuAdHSWgRAQCuWwYmWCA6g39j4VPge5pv962XYvxwJpvn23Y5KvNZ5S5c6crdG4f4gTCXnU36x92fKMQzsQV9K4phcuNvMWkpqVB6xMA5aPzUeHcGytD93dG8D52P5BxsgaJJE6QqDrk3Y2vyLw9ZEbJhPRJxbuBKVCBtVx26Ldd46dq5eyyzmNEyQGLrjQ4qd978VtG8TNT5rkn4ETJQEju5HfCBbjm3urGLFVqxhGVawecT4YM9Rry4EqXWkRJGTFQWQRnweUFbKNbVTC9NxcXEp6K5rSPEy9trb5UYLYhhMJ9fWSBMuenGRjNSJxeurMRCaxPpNppBLFnp8qW5ezfHgCBpEjkSNNzP4uXMZFAXmdUfJ8XQdPTWuYfdHYc5TZWnzrdq9wcfFQRDpDB2zX5Myu96krDt9vA7wNKfYwkSczA6qUQV66jA8nV4Cs38cDAKVBXnxz22ddAVrPv8ajpu7hgBtULMURjvLt94Nc5FDKw79CTTQxffWEj9BJCDCpQnTufmT8xenywwVJvtj49yv2MP2mGECrVDRmcGUAYBKR8G6ZnFAYDVC9UhY46FGWDcyVX3HKwgtHeb45Ww7dsW8JdMnZYctaEU585GZmqTJp2LcAWRcQPH25JewnPX8pjzVpJNcy7avfA2bcU86bfASvQBDUCrhjgRmK2ECR6vzPwTsYKRgFrDqb62FeMdrKgJ9vKs435T5ACN7MNtdRXHQ4fj5pNpUMDW26Wd7tt9bkBTqEGf\" saml_kc: # <--- Our SAML connector name, used in the path configured in KC buttonName: \"KeyCloak SAML SSO\" enabled: true type: \"saml\" issuer: \"ror\" # <-- called exactly like the SAML client in KC entryPoint: \"http://localhost:8080/auth/realms/ror/protocol/saml\" # <-- from KC configuration tab! kibanaExternalHost: 'localhost:5601' protocol: \"https\" # <--- our Kibana responds to HTTPS usernameParameter: \"nameID\" groupsParameter: \"Role\" logoutUrl: \"http://localhost:8080/auth/realms/ror/protocol/saml\" # <-- from KC configuration tab! cert: /etc/ror/integration/certs/dag.crt # from KC realm keys tab <-- It can be also provided a string value You can find a public PEM-encoded X.509 signing certificate as a string value by selecting the \"keys\" tab in your newly created realm. After clicking on a cert button, you can copy the value into kibana.yml saml config cert parameter. Don't forget setting up SAML requires some changes to security settings in readonlyrest.yml (on the elasticsearch side). Security settings can also be changed via the ReadonlyREST Kibana app.","title":"Setup the SAML connector"},{"location":"examples/saml-sso/keycloak_saml/#setup-elasticsearch-with-readonlyrest","text":"Our Elasticsearch needs to be available on https (more detailed info in our documentation ), so we modify the elasticsearch.yml append to elasticsearch.yml xpack.security.enabled: false http.type: ssl_netty4 # <-- needed for ROR SSL Write in readonlyrest.yml readonlyrest: ssl: enable: true keystore_file: \"keystore.jks\" keystore_pass: readonlyrest key_pass: readonlyrest prompt_for_basic_auth: false audit_collector: true access_control_rules: - name: \"::KIBANA-SRV::\" auth_key: kibana:kibana verbosity: error - name: \"ReadonlyREST Enterprise instance #1\" kibana_index: \".kibana_sso\" ror_kbn_auth: name: \"kbn1\" ror_kbn: - name: kbn1 # It has to be the same string as we declared in kibana.yml. signature_key: \"9yzBfnLaTYLfGPzyKW9es76RKYhUVgmuv6ZtehaScj5msGpBpa5FWpwk295uJYaaffTFnQC5tsknh2AguVDaTrqCLfM5zCTqdE4UGNL73h28Bg4dPrvTAFQyygQqv4xfgnevBED6VZYdfjXAQLc8J8ywaHQQSmprZqYCWGE6sM3vzNUEWWB3kmGrEKa4sGbXhmXZCvL6NDnEJhXPDJAzu9BMQxn8CzVLqrx6BxDgPYF8gZCxtyxMckXwCaYXrxAGbjkYH69F4wYhuAdHSWgRAQCuWwYmWCA6g39j4VPge5pv962XYvxwJpvn23Y5KvNZ5S5c6crdG4f4gTCXnU36x92fKMQzsQV9K4phcuNvMWkpqVB6xMA5aPzUeHcGytD93dG8D52P5BxsgaJJE6QqDrk3Y2vyLw9ZEbJhPRJxbuBKVCBtVx26Ldd46dq5eyyzmNEyQGLrjQ4qd978VtG8TNT5rkn4ETJQEju5HfCBbjm3urGLFVqxhGVawecT4YM9Rry4EqXWkRJGTFQWQRnweUFbKNbVTC9NxcXEp6K5rSPEy9trb5UYLYhhMJ9fWSBMuenGRjNSJxeurMRCaxPpNppBLFnp8qW5ezfHgCBpEjkSNNzP4uXMZFAXmdUfJ8XQdPTWuYfdHYc5TZWnzrdq9wcfFQRDpDB2zX5Myu96krDt9vA7wNKfYwkSczA6qUQV66jA8nV4Cs38cDAKVBXnxz22ddAVrPv8ajpu7hgBtULMURjvLt94Nc5FDKw79CTTQxffWEj9BJCDCpQnTufmT8xenywwVJvtj49yv2MP2mGECrVDRmcGUAYBKR8G6ZnFAYDVC9UhY46FGWDcyVX3HKwgtHeb45Ww7dsW8JdMnZYctaEU585GZmqTJp2LcAWRcQPH25JewnPX8pjzVpJNcy7avfA2bcU86bfASvQBDUCrhjgRmK2ECR6vzPwTsYKRgFrDqb62FeMdrKgJ9vKs435T5ACN7MNtdRXHQ4fj5pNpUMDW26Wd7tt9bkBTqEGf\"","title":"Setup Elasticsearch with ReadonlyREST"},{"location":"examples/saml-sso/multifactor_authentication_with_duo_via_saml/","text":"Duo Security MFA This tutorial is a step by step guide for the integration between DUO multi factor authentication provider and ReadonlyREST Enterprise . The multi factor authentication (MFA) provided by DUO is an additional authorization step for the user after they have inserted the correct credentials. This extra step is mediated by the DUO platform and it is either an SMS, a push notification to their app, or a one time password obtained via their app or google authenticator. For this tutorial you are going to need: A valid installation of ReadonlyREST Enterprise (trial, or official) Kibana plugin. If you haven't got one, get your own trial build here . A valid trial or paid account in DUO website (see pricing , you are going to need the \"Remote Access & Single Sign-On (SSO)\" feature. Duo Access Gateway (DAG) server configuration The access gateway is a piece of software released by DUO that takes care of integrating on premises service providers like ReadonlyREST SAML with arbitrary identity providers (like LDAP) and the multi factor authentication features offered by DUO platform. Installing Duo Gateway Follow the instructions for Duo Gateway ( https://duo.com/docs/dag-linux ). The gateway is a Docker container and it will need the ports 80 and 443 to be available, so you will probably need a dedicated VM or Bare Metal so that Duo Gateway can properly bind to these ports. Configuring Authentication Source Once the Duo Gateway is installed, open a browser and point to its web interface to configure it. When you configure the authentication sources, be sure to set the correct username attribute. Keep in mind this value because it will be mapped directly to whatever has been configured in the actual Duo.com dashboard, under Gateway > Applications (which we are just about to configure). Configure Application in Duo Admin Dashboard In the Duo Administration dashboard, go to Applications. Click Protect an Application , then search for Generic and click Protect this Application button. This will create a generic SAML provider. Set these fields: Service provider name: A name that refers to your ReadonlyREST Enterprise installation EntityID: Set an existing entity name or use the same as Service Provider Name Assertion Consumer Service: The SAML Url assertion found in metadata.xml, the url format is <kibanaExternalHost>/ror_kbn_sso/assert . In SAML Response, set NameID to be the same variable name as configured previously in the authentication source. Leave the default values for the remaining settings. Click Save Application and scroll up and download the configuration file. ReadonlyRest Configuration To configure SAML, both Kibana and Elasticsearch ROR configuration needs to be edited to enable SAML in Duo Gateway. Configuring the Elasticsearch plugin Open your readonlyrest.yml file or login as a local administrator in your ReadonlyREST Enterprise, and add this extra configuration required for SAML authentication. readonlyrest: access_control_rules: # [... all your regular ACL blocks ...] - name: \"ReadonlyREST Enterprise Kibana instance #1\" ror_kbn_auth: name: \"kbn1\" # OPTIONAL FOR SECONDARY KIBANA ### # # - name: \"ReadonlyREST Enterprise Kibana instance #2\" # ror_kbn_auth: # name: \"kbn2\" ror_kbn: - name: kbn1 signature_key: \"shared_secret_kibana1_(256+chars)\" # <- use environmental variables for better security! # OPTIONAL FOR SECONDARY KIBANA ### # - name: kbn2 # signature_key: \"shared_secret_kibana2(256+chars)\" # <- use environmental variables for better security! This authentication and authorization connector represents the secure channel (based on JWT tokens) of signed messages necessary for our Enterprise Kibana plugin to securely pass back to ES the username and groups information coming SAML identity provider. Configuring the Kibana plugin Edit $KIBANA_HOME/conf/kibana.yml configuration and append: readonlyrest_kbn.auth: signature_key: \u201ca very long key (more than 256 characters) goes here \u2026..\u201d # the same signing key added above in ES config saml: enabled: true entryPoint: 'https://duo-gateway.xyz/dag/saml2/idp/SSOService.php?spentityid=demo' kibanaExternalHost: 'ror-deployment.xyz' # <-- public URL used by the Identity Provider to call back Kibana with the \"assertion\" message usernameParameter: 'nameID' groupsParameter: 'memberOf' logoutUrl: 'https://duo-gateway.xyz/dag/saml2/idp/SingleLogoutService.php?ReturnTo=https://duo-gateway.xyz/dag/module.php/duosecurity/logout.php' decryptionCert: certs/dag.crt cert: certs/dag.crt The following fields are mapped to the Duo Gateway Application Metadata: entryPoint: LoginUrl for the SAML Generic Application usernameParameter: Default SAML Generic Application value is nameID logoutUrl: a URL that points to the value found in the screen Metadata > Logout URL decryptionCert: The downloadable certificate in Metadata (absolute path) cert: The downloadable certificate in Metadata (absolute path) signature_key: Signing key string for JWT, must match the same key value in elasticsearch ROR config kibanaExternalHost: The Kibana (with ReadonlyREST Enterprise) instance public hostname protocol: protocol schema (http or https) of the external Kibana host issuer: distinctive name of the identity provider (optional) decryptionPvk: service provider private key (string value) (optional) For more advanced configurations and information, please refer to passport-saml documentation Elasticsearch index in Kibana ROR Dashboard Make sure to update signature_key in ROR Dashboard with the value. Otherwise you will get JWT errors while login with SAML. Login with SAML 2FA enabled Go to ReadonlyREST Login page ( http://ror-deployment.xyz/login ) and click the SAML SSO button. This will redirect to Duo Security Gateway and ask for a two factor code to proceed. Note that the first time it will provision a two factor seed mapped to the user account. Once Duo authenticates, it will redirect you to the private Kibana session powered by ReadonlyREST Enterprise. Logout from SAML from ReadonlyREST Enterprise logout button Click the Logout button from ROR Dashboard. This will redirect you to Duo Gateway logout completion page. Follow the instructions and close the window.","title":"Duo Security MFA"},{"location":"examples/saml-sso/multifactor_authentication_with_duo_via_saml/#duo-security-mfa","text":"This tutorial is a step by step guide for the integration between DUO multi factor authentication provider and ReadonlyREST Enterprise . The multi factor authentication (MFA) provided by DUO is an additional authorization step for the user after they have inserted the correct credentials. This extra step is mediated by the DUO platform and it is either an SMS, a push notification to their app, or a one time password obtained via their app or google authenticator. For this tutorial you are going to need: A valid installation of ReadonlyREST Enterprise (trial, or official) Kibana plugin. If you haven't got one, get your own trial build here . A valid trial or paid account in DUO website (see pricing , you are going to need the \"Remote Access & Single Sign-On (SSO)\" feature.","title":"Duo Security MFA"},{"location":"examples/saml-sso/multifactor_authentication_with_duo_via_saml/#duo-access-gateway-dag-server-configuration","text":"The access gateway is a piece of software released by DUO that takes care of integrating on premises service providers like ReadonlyREST SAML with arbitrary identity providers (like LDAP) and the multi factor authentication features offered by DUO platform.","title":"Duo Access Gateway (DAG) server configuration"},{"location":"examples/saml-sso/multifactor_authentication_with_duo_via_saml/#installing-duo-gateway","text":"Follow the instructions for Duo Gateway ( https://duo.com/docs/dag-linux ). The gateway is a Docker container and it will need the ports 80 and 443 to be available, so you will probably need a dedicated VM or Bare Metal so that Duo Gateway can properly bind to these ports.","title":"Installing Duo Gateway"},{"location":"examples/saml-sso/multifactor_authentication_with_duo_via_saml/#configuring-authentication-source","text":"Once the Duo Gateway is installed, open a browser and point to its web interface to configure it. When you configure the authentication sources, be sure to set the correct username attribute. Keep in mind this value because it will be mapped directly to whatever has been configured in the actual Duo.com dashboard, under Gateway > Applications (which we are just about to configure).","title":"Configuring Authentication Source"},{"location":"examples/saml-sso/multifactor_authentication_with_duo_via_saml/#configure-application-in-duo-admin-dashboard","text":"In the Duo Administration dashboard, go to Applications. Click Protect an Application , then search for Generic and click Protect this Application button. This will create a generic SAML provider. Set these fields: Service provider name: A name that refers to your ReadonlyREST Enterprise installation EntityID: Set an existing entity name or use the same as Service Provider Name Assertion Consumer Service: The SAML Url assertion found in metadata.xml, the url format is <kibanaExternalHost>/ror_kbn_sso/assert . In SAML Response, set NameID to be the same variable name as configured previously in the authentication source. Leave the default values for the remaining settings. Click Save Application and scroll up and download the configuration file.","title":"Configure Application in Duo Admin Dashboard"},{"location":"examples/saml-sso/multifactor_authentication_with_duo_via_saml/#readonlyrest-configuration","text":"To configure SAML, both Kibana and Elasticsearch ROR configuration needs to be edited to enable SAML in Duo Gateway.","title":"ReadonlyRest Configuration"},{"location":"examples/saml-sso/multifactor_authentication_with_duo_via_saml/#configuring-the-elasticsearch-plugin","text":"Open your readonlyrest.yml file or login as a local administrator in your ReadonlyREST Enterprise, and add this extra configuration required for SAML authentication. readonlyrest: access_control_rules: # [... all your regular ACL blocks ...] - name: \"ReadonlyREST Enterprise Kibana instance #1\" ror_kbn_auth: name: \"kbn1\" # OPTIONAL FOR SECONDARY KIBANA ### # # - name: \"ReadonlyREST Enterprise Kibana instance #2\" # ror_kbn_auth: # name: \"kbn2\" ror_kbn: - name: kbn1 signature_key: \"shared_secret_kibana1_(256+chars)\" # <- use environmental variables for better security! # OPTIONAL FOR SECONDARY KIBANA ### # - name: kbn2 # signature_key: \"shared_secret_kibana2(256+chars)\" # <- use environmental variables for better security! This authentication and authorization connector represents the secure channel (based on JWT tokens) of signed messages necessary for our Enterprise Kibana plugin to securely pass back to ES the username and groups information coming SAML identity provider.","title":"Configuring the Elasticsearch plugin"},{"location":"examples/saml-sso/multifactor_authentication_with_duo_via_saml/#configuring-the-kibana-plugin","text":"Edit $KIBANA_HOME/conf/kibana.yml configuration and append: readonlyrest_kbn.auth: signature_key: \u201ca very long key (more than 256 characters) goes here \u2026..\u201d # the same signing key added above in ES config saml: enabled: true entryPoint: 'https://duo-gateway.xyz/dag/saml2/idp/SSOService.php?spentityid=demo' kibanaExternalHost: 'ror-deployment.xyz' # <-- public URL used by the Identity Provider to call back Kibana with the \"assertion\" message usernameParameter: 'nameID' groupsParameter: 'memberOf' logoutUrl: 'https://duo-gateway.xyz/dag/saml2/idp/SingleLogoutService.php?ReturnTo=https://duo-gateway.xyz/dag/module.php/duosecurity/logout.php' decryptionCert: certs/dag.crt cert: certs/dag.crt The following fields are mapped to the Duo Gateway Application Metadata: entryPoint: LoginUrl for the SAML Generic Application usernameParameter: Default SAML Generic Application value is nameID logoutUrl: a URL that points to the value found in the screen Metadata > Logout URL decryptionCert: The downloadable certificate in Metadata (absolute path) cert: The downloadable certificate in Metadata (absolute path) signature_key: Signing key string for JWT, must match the same key value in elasticsearch ROR config kibanaExternalHost: The Kibana (with ReadonlyREST Enterprise) instance public hostname protocol: protocol schema (http or https) of the external Kibana host issuer: distinctive name of the identity provider (optional) decryptionPvk: service provider private key (string value) (optional) For more advanced configurations and information, please refer to passport-saml documentation","title":"Configuring the Kibana plugin"},{"location":"examples/saml-sso/multifactor_authentication_with_duo_via_saml/#elasticsearch-index-in-kibana-ror-dashboard","text":"Make sure to update signature_key in ROR Dashboard with the value. Otherwise you will get JWT errors while login with SAML.","title":"Elasticsearch index in Kibana ROR Dashboard"},{"location":"examples/saml-sso/multifactor_authentication_with_duo_via_saml/#login-with-saml-2fa-enabled","text":"Go to ReadonlyREST Login page ( http://ror-deployment.xyz/login ) and click the SAML SSO button. This will redirect to Duo Security Gateway and ask for a two factor code to proceed. Note that the first time it will provision a two factor seed mapped to the user account. Once Duo authenticates, it will redirect you to the private Kibana session powered by ReadonlyREST Enterprise.","title":"Login with SAML 2FA enabled"},{"location":"examples/saml-sso/multifactor_authentication_with_duo_via_saml/#logout-from-saml-from-readonlyrest-enterprise-logout-button","text":"Click the Logout button from ROR Dashboard. This will redirect you to Duo Gateway logout completion page. Follow the instructions and close the window.","title":"Logout from SAML from ReadonlyREST Enterprise logout button"}]}